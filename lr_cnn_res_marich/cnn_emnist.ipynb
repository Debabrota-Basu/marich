{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1334,"status":"ok","timestamp":1683836960024,"user":{"displayName":"Pratik Karmakar","userId":"12296951678310684387"},"user_tz":-480},"id":"FCNYmftHHMRy","outputId":"009c31bd-00ad-4d2c-91df-010c34943cc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["from utils import marich, dataset\n","from nets import *\n","from tqdm import tqdm\n","import numpy as np\n","import torch\n","import pickle\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7542,"status":"ok","timestamp":1683836967564,"user":{"displayName":"Pratik Karmakar","userId":"12296951678310684387"},"user_tz":-480},"id":"VWTlQi4DHMRy","outputId":"5b22dd97-afbd-43ed-f56a-a4890e234253"},"outputs":[],"source":["# cnn = CNN().cuda()\n","# cnn.load_state_dict(torch.load(\"./targets/cnn_mnist.pt\"))"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# emnist = datasets.EMNIST('./emnist/train/', download=True, train=True, split = \"letters\", transform=transform)\n","# emnist,_ = random_split(emnist, [50000,74800])"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683836221506,"user":{"displayName":"Pratik Karmakar","userId":"12296951678310684387"},"user_tz":-480},"id":"mCQwTA1RHMRz"},"outputs":[],"source":["# unlab_x = []\n","# unlab_y = []\n","# for j,k in emnist:\n","#     j = j.to(device)\n","#     unlab_x.append(j)\n","#     unlab_y.append(torch.argmax(cnn(j.unsqueeze(dim = 0))))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1683836967565,"user":{"displayName":"Pratik Karmakar","userId":"12296951678310684387"},"user_tz":-480},"id":"4dJ2tDfLe9bd"},"outputs":[],"source":["# with open('./imagenet_target/emnist_cnn_x.pkl', 'wb') as f:\n","#   pickle.dump(unlab_x, f)\n","\n","# with open('./imagenet_target/emnist_cnn_y.pkl', 'wb') as f:\n","#   pickle.dump(unlab_y, f)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yt6PfwWae9be"},"outputs":[],"source":["with open('./imagenet_target/emnist_cnn_x.pkl', 'rb') as f:\n","  unlab_x = pickle.load(f)\n","\n","with open('./imagenet_target/emnist_cnn_y.pkl', 'rb') as f:\n","  unlab_y = pickle.load(f)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["class basic_dataset(Dataset):\n","    def __init__(self, X, Y = None, transform = None):\n","        self.X = X\n","        self.Y = Y\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.transform:\n","            x = self.transform(self.X[idx])\n","        else:\n","            x = self.X[idx]\n","        if self.Y != None:\n","            y = self.Y[idx]\n","            return x, y\n","        else:\n","            return x\n","\n","class dataset2(Dataset):\n","    def __init__(self, X, Y = None, transform = None):\n","        self.X = X\n","        self.Y = Y\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.transform:\n","            x = self.transform(self.X[idx])\n","        else:\n","            x = self.X[idx]\n","        if self.Y != None:\n","            y = self.Y[idx]\n","            return x, y\n","        else:\n","            return x\n","    def get_data(self,idx):\n","        if self.transform:\n","            x = self.transform(self.X[idx])\n","        else:\n","            x = self.X[idx]\n","        return x\n","    def get_dataset(self, idx):\n","        x = self.X[idx]\n","        y = torch.tensor(self.Y)[idx]\n","        return basic_dataset(x,y)\n","    def get_label(self,idx):\n","        y = torch.tensor(self.Y)[idx]\n","        return y\n","    def get_data_label_loader(self,idx):\n","        if self.transform:\n","            x = self.transform(self.X[idx])\n","        else:\n","            x = self.X[idx]\n","        y = torch.tensor(self.Y)[idx]\n","        \n","        return_set = basic_dataset(x,y)\n","        return torch.utils.data.DataLoader(return_set, batch_size = 100)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["train_id, val_id = train_test_split(range(50000), test_size = 0.2)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["unlab_dataset_train = dataset2(torch.stack(unlab_x)[train_id], torch.tensor(unlab_y)[train_id])\n","unlab_dataset_val = dataset2(torch.stack(unlab_x)[val_id], torch.tensor(unlab_y)[val_id])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"G42zMl0wHMR0"},"outputs":[],"source":["testset = datasets.MNIST('../mnist/train/', download=True, train=False, transform=transform)\n","# trainset, testset = torch.utils.data.random_split(trainset, [50000, 10000])\n","# valset = datasets.MNIST('../mnist/test/', download=True, train=False, transform=transform)\n","testloader = DataLoader(testset, batch_size = 256)\n","validloader = DataLoader(unlab_dataset_val, batch_size = 256)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def test_accuracy(net, testloader):\n","    correct = 0\n","\n","    # since we're not training, we don't need to calculate the gradients for our outputs\n","    with torch.no_grad():\n","        net.eval()\n","        for images, labels in testloader:\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # calculate outputs by running images through the network\n","            outputs = net(images)\n","\n","            # the class with the highest energy is what we choose as prediction\n","            predicted = torch.max(outputs.data, 1)[1]\n","\n","            correct += (predicted == labels).sum().item()\n","    \n","    return correct / len(testloader.dataset)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":30291,"status":"error","timestamp":1683754979048,"user":{"displayName":"Pratik Karmakar","userId":"12296951678310684387"},"user_tz":-480},"id":"klbgtKOBHMR1","outputId":"7fd122fb-dba0-4755-ded3-5588bb007a55"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n"]},{"name":"stdout","output_type":"stream","text":["Using CUDA\n","Test accuracy:  11.8\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.2965429723262787\n","Validation loss:  2.2916176080703736\n","Epoch time -----  0.9237186908721924  sec\n","Epoch:  2\n","Train loss:  2.2840713560581207\n","Validation loss:  2.279078882932663\n","Epoch time -----  0.9902763366699219  sec\n","Epoch:  3\n","Train loss:  2.272633522748947\n","Validation loss:  2.2693152010440825\n","Epoch time -----  0.9016947746276855  sec\n","Epoch:  4\n","Train loss:  2.2704503536224365\n","Validation loss:  2.261777663230896\n","Epoch time -----  0.9206395149230957  sec\n","Epoch:  5\n","Train loss:  2.2583462297916412\n","Validation loss:  2.2547487199306486\n","Epoch time -----  0.9146749973297119  sec\n","Epoch:  6\n","Train loss:  2.256701111793518\n","Validation loss:  2.248821747303009\n","Epoch time -----  0.9659452438354492  sec\n","Epoch:  7\n","Train loss:  2.2458417117595673\n","Validation loss:  2.243330639600754\n","Epoch time -----  0.9599189758300781  sec\n","Epoch:  8\n","Train loss:  2.2438663840293884\n","Validation loss:  2.238652503490448\n","Epoch time -----  0.9173305034637451  sec\n","Epoch:  9\n","Train loss:  2.246544986963272\n","Validation loss:  2.235515022277832\n","Epoch time -----  0.896247386932373  sec\n","Epoch:  10\n","Train loss:  2.2385059595108032\n","Validation loss:  2.2328173756599425\n","Epoch time -----  0.9162421226501465  sec\n","Test accuracy:  9.82\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  693  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1055\n","Training samples:  1055\n","Training\n","Epoch:  1\n","Train loss:  2.2038466930389404\n","Validation loss:  2.2173593163490297\n","Epoch time -----  1.0088307857513428  sec\n","Epoch:  2\n","Train loss:  2.1668106948628143\n","Validation loss:  2.223580849170685\n","Epoch time -----  0.9526937007904053  sec\n","Epoch:  3\n","Train loss:  2.148924505009371\n","Validation loss:  2.227811348438263\n","Epoch time -----  1.064319372177124  sec\n","Epoch:  4\n","Train loss:  2.1485572422251984\n","Validation loss:  2.2302933275699615\n","Epoch time -----  1.003218173980713  sec\n","Epoch:  5\n","Train loss:  2.136912051369162\n","Validation loss:  2.2255580723285675\n","Epoch time -----  0.9662888050079346  sec\n","Epoch:  6\n","Train loss:  2.134097463944379\n","Validation loss:  2.2252945423126222\n","Epoch time -----  1.16011381149292  sec\n","Epoch:  7\n","Train loss:  2.130646544344285\n","Validation loss:  2.222245919704437\n","Epoch time -----  1.0079822540283203  sec\n","Epoch:  8\n","Train loss:  2.1299227826735554\n","Validation loss:  2.220673179626465\n","Epoch time -----  0.9375734329223633  sec\n","Epoch:  9\n","Train loss:  2.117804295876447\n","Validation loss:  2.220577210187912\n","Epoch time -----  1.004201889038086  sec\n","Epoch:  10\n","Train loss:  2.1243809671962963\n","Validation loss:  2.217746752500534\n","Epoch time -----  0.8370940685272217  sec\n","Testing\n","Test accuracy:  8.92\n","Round:  2\n","Using entropy sampling on  38945  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1617\n","Training samples:  1617\n","Training\n","Epoch:  1\n","Train loss:  2.0425269191081705\n","Validation loss:  2.222916620969772\n","Epoch time -----  1.0791294574737549  sec\n","Epoch:  2\n","Train loss:  1.931121106331165\n","Validation loss:  2.2050678610801695\n","Epoch time -----  1.2093639373779297  sec\n","Epoch:  3\n","Train loss:  1.8571681792919452\n","Validation loss:  2.115158760547638\n","Epoch time -----  1.0678346157073975  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.7957345797465398\n","Validation loss:  2.076326143741608\n","Epoch time -----  1.1109602451324463  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.743353206377763\n","Validation loss:  2.0483358919620516\n","Epoch time -----  1.1173956394195557  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.708205181818742\n","Validation loss:  2.0116655230522156\n","Epoch time -----  1.1223437786102295  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.671847898226518\n","Validation loss:  1.9933605253696443\n","Epoch time -----  1.0329151153564453  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.6441125044455895\n","Validation loss:  1.9791143894195558\n","Epoch time -----  1.0100221633911133  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.6431323977617116\n","Validation loss:  1.9695017069578171\n","Epoch time -----  1.028876543045044  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.6214374945713923\n","Validation loss:  1.9440575659275054\n","Epoch time -----  1.0934398174285889  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  25.0\n","Round:  3\n","Using entropy sampling on  38383  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n"]},{"name":"stdout","output_type":"stream","text":["Using loss sampling on  709  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2185\n","Training samples:  2185\n","Training\n","Epoch:  1\n","Train loss:  1.7359079020363943\n","Validation loss:  1.9558971673250198\n","Epoch time -----  1.1037862300872803  sec\n","Epoch:  2\n","Train loss:  1.6719459090914046\n","Validation loss:  1.8747358441352844\n","Epoch time -----  1.1497128009796143  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.6125755752835955\n","Validation loss:  1.8271882951259613\n","Epoch time -----  1.0405328273773193  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.571390918322972\n","Validation loss:  1.7927141547203065\n","Epoch time -----  1.0461540222167969  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5397935220173427\n","Validation loss:  1.7483236968517304\n","Epoch time -----  1.2267413139343262  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.5282256807599748\n","Validation loss:  1.7361961781978608\n","Epoch time -----  1.0888252258300781  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4994614498955863\n","Validation loss:  1.734305700659752\n","Epoch time -----  1.1407592296600342  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4829413311822073\n","Validation loss:  1.6795133382081986\n","Epoch time -----  1.288682222366333  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.457496053831918\n","Validation loss:  1.7011977970600127\n","Epoch time -----  1.1005876064300537  sec\n","Epoch:  10\n","Train loss:  1.4480293239865984\n","Validation loss:  1.6642154902219772\n","Epoch time -----  1.122406244277954  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  33.78\n","Round:  4\n","Using entropy sampling on  37815  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2759\n","Training samples:  2759\n","Training\n","Epoch:  1\n","Train loss:  1.5930297130888158\n","Validation loss:  1.741071981191635\n","Epoch time -----  1.2237606048583984  sec\n","Epoch:  2\n","Train loss:  1.5597447603940964\n","Validation loss:  1.7200053453445434\n","Epoch time -----  1.4188520908355713  sec\n","Epoch:  3\n","Train loss:  1.5383032939650796\n","Validation loss:  1.6161324590444566\n","Epoch time -----  1.202148199081421  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.5099763436750933\n","Validation loss:  1.6628248244524002\n","Epoch time -----  1.2867181301116943  sec\n","Epoch:  5\n","Train loss:  1.4985446279699153\n","Validation loss:  1.584407091140747\n","Epoch time -----  1.2738420963287354  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4612818956375122\n","Validation loss:  1.5521496683359146\n","Epoch time -----  1.3432202339172363  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4529474580829793\n","Validation loss:  1.5469455987215042\n","Epoch time -----  1.327016830444336  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.454658175056631\n","Validation loss:  1.5381340265274048\n","Epoch time -----  1.2536790370941162  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4410569071769714\n","Validation loss:  1.5589761048555375\n","Epoch time -----  1.2871830463409424  sec\n","Epoch:  10\n","Train loss:  1.4575771228833632\n","Validation loss:  1.5315442562103272\n","Epoch time -----  1.263927936553955  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  39.92\n","Round:  5\n","Using entropy sampling on  37241  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  726  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3343\n","Training samples:  3343\n","Training\n","Epoch:  1\n","Train loss:  1.575556919259845\n","Validation loss:  1.524317842721939\n","Epoch time -----  1.348877191543579  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.5320313044314116\n","Validation loss:  1.520586958527565\n","Epoch time -----  1.129845380783081  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.5094217106981098\n","Validation loss:  1.560266062617302\n","Epoch time -----  1.1196250915527344  sec\n","Epoch:  4\n","Train loss:  1.4951427230295145\n","Validation loss:  1.4770033717155457\n","Epoch time -----  1.4072506427764893  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.487712005399308\n","Validation loss:  1.5058085948228837\n","Epoch time -----  1.3390998840332031  sec\n","Epoch:  6\n","Train loss:  1.4766668013806612\n","Validation loss:  1.4753776013851165\n","Epoch time -----  1.4636156558990479  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4523028900038522\n","Validation loss:  1.462278699874878\n","Epoch time -----  1.6253979206085205  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4548982854159374\n","Validation loss:  1.4474633246660233\n","Epoch time -----  1.6068990230560303  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4487494972516906\n","Validation loss:  1.4602082401514054\n","Epoch time -----  1.48403000831604  sec\n","Epoch:  10\n","Train loss:  1.424723913084786\n","Validation loss:  1.4469848155975342\n","Epoch time -----  1.3818202018737793  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4292500828796963\n","Validation loss:  1.4385167241096497\n","Epoch time -----  1.5371806621551514  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  50.17\n","Round:  6\n","Using entropy sampling on  36657  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  730  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3927\n","Training samples:  3927\n","Training\n","Epoch:  1\n","Train loss:  1.5251909321354282\n","Validation loss:  1.4744697898626327\n","Epoch time -----  1.6745755672454834  sec\n","Epoch:  2\n","Train loss:  1.5186160879750406\n","Validation loss:  1.4494457378983499\n","Epoch time -----  1.707801342010498  sec\n","Epoch:  3\n","Train loss:  1.4788845450647417\n","Validation loss:  1.448991346359253\n","Epoch time -----  1.6178979873657227  sec\n","Epoch:  4\n","Train loss:  1.4650832952991608\n","Validation loss:  1.4179654181003571\n","Epoch time -----  1.7437858581542969  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4538218609748348\n","Validation loss:  1.3931585118174552\n","Epoch time -----  1.7077932357788086  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4410526637108094\n","Validation loss:  1.3914944753050804\n","Epoch time -----  1.621063232421875  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4217655427994267\n","Validation loss:  1.3755739599466323\n","Epoch time -----  1.8526713848114014  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4184880025925175\n","Validation loss:  1.3932240664958955\n","Epoch time -----  1.5981030464172363  sec\n","Epoch:  9\n","Train loss:  1.4119610863347207\n","Validation loss:  1.3694358140230178\n","Epoch time -----  1.6027491092681885  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.402254041164152\n","Validation loss:  1.3653300657868386\n","Epoch time -----  1.642993450164795  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3935610882697567\n","Validation loss:  1.361036939918995\n","Epoch time -----  1.2765469551086426  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  57.67\n","Round:  7\n","Using entropy sampling on  36073  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  736  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4517\n","Training samples:  4517\n","Training\n","Epoch:  1\n","Train loss:  1.5083765127289464\n","Validation loss:  1.3916810259222985\n","Epoch time -----  1.775550365447998  sec\n","Epoch:  2\n","Train loss:  1.4761259807667262\n","Validation loss:  1.3832462102174758\n","Epoch time -----  1.702409029006958  sec\n","Epoch:  3\n","Train loss:  1.455794997618232\n","Validation loss:  1.3421109646558762\n","Epoch time -----  1.5900697708129883  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4275943762819532\n","Validation loss:  1.354433822631836\n","Epoch time -----  1.7780635356903076  sec\n","Epoch:  5\n","Train loss:  1.4114173398890966\n","Validation loss:  1.3270000085234641\n","Epoch time -----  1.841216802597046  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4123895168304443\n","Validation loss:  1.3150204449892045\n","Epoch time -----  1.7228426933288574  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3844775532332945\n","Validation loss:  1.304085759818554\n","Epoch time -----  1.5002152919769287  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.378417454974752\n","Validation loss:  1.3101986840367317\n","Epoch time -----  1.5429136753082275  sec\n","Epoch:  9\n","Train loss:  1.369274268687611\n","Validation loss:  1.3023018389940262\n","Epoch time -----  1.364889144897461  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3647904261736803\n","Validation loss:  1.3000011548399926\n","Epoch time -----  1.5076627731323242  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3697195707912175\n","Validation loss:  1.2955364644527436\n","Epoch time -----  1.8581740856170654  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  66.47\n","Round:  8\n","Using entropy sampling on  35483  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5115\n","Training samples:  5115\n","Training\n","Epoch:  1\n","Train loss:  1.4579771399497985\n","Validation loss:  1.3099260121583938\n","Epoch time -----  2.18330454826355  sec\n","Epoch:  2\n","Train loss:  1.4260488241910934\n","Validation loss:  1.311880099773407\n","Epoch time -----  2.0639889240264893  sec\n","Epoch:  3\n","Train loss:  1.4043567210435868\n","Validation loss:  1.2845383822917937\n","Epoch time -----  2.0543081760406494  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3909458681941032\n","Validation loss:  1.254359321296215\n","Epoch time -----  1.9538755416870117  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3637254118919373\n","Validation loss:  1.2485323309898377\n","Epoch time -----  2.230654239654541  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3612302735447883\n","Validation loss:  1.2621866017580032\n","Epoch time -----  1.700819969177246  sec\n","Epoch:  7\n","Train loss:  1.3529839605093001\n","Validation loss:  1.2492204442620278\n","Epoch time -----  2.2248759269714355  sec\n","Epoch:  8\n","Train loss:  1.3369513526558876\n","Validation loss:  1.2387071803212166\n","Epoch time -----  1.8751842975616455  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.32726439088583\n","Validation loss:  1.235223826766014\n","Epoch time -----  1.9501159191131592  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3193603724241256\n","Validation loss:  1.23727697879076\n","Epoch time -----  2.0224404335021973  sec\n","Epoch:  11\n","Train loss:  1.317484264075756\n","Validation loss:  1.240103942155838\n","Epoch time -----  2.005650281906128  sec\n","Testing\n","Test accuracy:  76.06\n","Round:  9\n","Using entropy sampling on  34885  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5717\n","Training samples:  5717\n","Training\n","Epoch:  1\n","Train loss:  1.4047422316339282\n","Validation loss:  1.2967929020524025\n","Epoch time -----  2.277240037918091  sec\n","Epoch:  2\n","Train loss:  1.370194332467185\n","Validation loss:  1.263210554420948\n","Epoch time -----  2.0552518367767334  sec\n","Epoch:  3\n","Train loss:  1.3624577628241645\n","Validation loss:  1.2436635568737984\n","Epoch time -----  1.8256776332855225  sec\n","Epoch:  4\n","Train loss:  1.3463618066575793\n","Validation loss:  1.2612935692071914\n","Epoch time -----  1.8132719993591309  sec\n","Epoch:  5\n","Train loss:  1.3276011149088542\n","Validation loss:  1.2613387808203698\n","Epoch time -----  2.2508444786071777  sec\n","Epoch:  6\n","Train loss:  1.3088458127445646\n","Validation loss:  1.2076113551855088\n","Epoch time -----  2.304595470428467  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.2959887637032403\n","Validation loss:  1.217245800793171\n","Epoch time -----  2.2679712772369385  sec\n","Epoch:  8\n","Train loss:  1.2947002940707737\n","Validation loss:  1.198099473118782\n","Epoch time -----  2.1263551712036133  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2844366709391275\n","Validation loss:  1.2008176550269127\n","Epoch time -----  2.2874438762664795  sec\n","Epoch:  10\n","Train loss:  1.2793188664648267\n","Validation loss:  1.1936848506331443\n","Epoch time -----  2.052981376647949  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2712123519844478\n","Validation loss:  1.1854714274406433\n","Epoch time -----  2.169295072555542  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  80.72\n","Round:  10\n","Using entropy sampling on  34283  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  759  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6325\n","Training samples:  6325\n","Training\n","Epoch:  1\n","Train loss:  1.3855073283417056\n","Validation loss:  1.245759728550911\n","Epoch time -----  2.592115879058838  sec\n","Epoch:  2\n","Train loss:  1.3412555347789417\n","Validation loss:  1.1824051767587662\n","Epoch time -----  2.3460068702697754  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3236577679412533\n","Validation loss:  1.1843089655041694\n","Epoch time -----  2.4523861408233643  sec\n","Epoch:  4\n","Train loss:  1.3117898425670584\n","Validation loss:  1.176045048236847\n","Epoch time -----  2.279698133468628  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.2941545705602626\n","Validation loss:  1.1743920311331748\n","Epoch time -----  2.3342061042785645  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.2766320572959051\n","Validation loss:  1.1680665493011475\n","Epoch time -----  1.8433291912078857  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.2759510483404604\n","Validation loss:  1.1720048800110816\n","Epoch time -----  1.882157325744629  sec\n","Epoch:  8\n","Train loss:  1.2540382279290094\n","Validation loss:  1.1770711421966553\n","Epoch time -----  2.222073554992676  sec\n","Epoch:  9\n","Train loss:  1.257350677191609\n","Validation loss:  1.1666462570428848\n","Epoch time -----  2.474393129348755  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.248978817101681\n","Validation loss:  1.1666272476315498\n","Epoch time -----  2.497452735900879  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.242943778784588\n","Validation loss:  1.161719097197056\n","Epoch time -----  2.4178192615509033  sec\n","validation loss minimum, saving model\n","Epoch:  12\n","Train loss:  1.2440866900212837\n","Validation loss:  1.1588897734880448\n","Epoch time -----  2.3104569911956787  sec\n","validation loss minimum, saving model\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 10%|â–ˆ         | 1/10 [05:12<46:51, 312.35s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  85.14\n","Using CUDA\n","Test accuracy:  5.19\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.2801960706710815\n","Validation loss:  2.2550147652626036\n","Epoch time -----  0.8642034530639648  sec\n","Epoch:  2\n","Train loss:  2.2561569213867188\n","Validation loss:  2.2386997640132904\n","Epoch time -----  0.8250291347503662  sec\n","Epoch:  3\n","Train loss:  2.2337963581085205\n","Validation loss:  2.225237691402435\n","Epoch time -----  0.8499026298522949  sec\n","Epoch:  4\n","Train loss:  2.2216115593910217\n","Validation loss:  2.2154533922672273\n","Epoch time -----  0.9403278827667236  sec\n","Epoch:  5\n","Train loss:  2.208740234375\n","Validation loss:  2.2082537531852724\n","Epoch time -----  0.9135630130767822  sec\n","Epoch:  6\n","Train loss:  2.2038854360580444\n","Validation loss:  2.203630667924881\n","Epoch time -----  0.9028453826904297  sec\n","Epoch:  7\n","Train loss:  2.2001518309116364\n","Validation loss:  2.20084553360939\n","Epoch time -----  0.9022397994995117  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  2.1969528198242188\n","Validation loss:  2.198327159881592\n","Epoch time -----  1.0090727806091309  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  2.1865351498126984\n","Validation loss:  2.1963241577148436\n","Epoch time -----  0.9392561912536621  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  2.1893148124217987\n","Validation loss:  2.1949350237846375\n","Epoch time -----  0.9437804222106934  sec\n","validation loss minimum, saving model\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  694  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1056\n","Training samples:  1056\n","Training\n","Epoch:  1\n","Train loss:  2.201194174149457\n","Validation loss:  2.183691757917404\n","Epoch time -----  1.0134153366088867  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  2.1852636056787826\n","Validation loss:  2.178791457414627\n","Epoch time -----  1.0400490760803223  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  2.163538280655356\n","Validation loss:  2.1757639348506927\n","Epoch time -----  1.0635995864868164  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  2.16139274484971\n","Validation loss:  2.170911556482315\n","Epoch time -----  1.0375442504882812  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  2.1535841016208424\n","Validation loss:  2.1648819386959075\n","Epoch time -----  1.145155668258667  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  2.15193107548882\n","Validation loss:  2.161474871635437\n","Epoch time -----  1.053436040878296  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  2.1351339115816006\n","Validation loss:  2.15671364068985\n","Epoch time -----  1.1252772808074951  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  2.1239874362945557\n","Validation loss:  2.151213902235031\n","Epoch time -----  1.03621506690979  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  2.1244849457460293\n","Validation loss:  2.1479216814041138\n","Epoch time -----  1.0649924278259277  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  2.1202525461421295\n","Validation loss:  2.143634259700775\n","Epoch time -----  1.0643293857574463  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  9.74\n","Round:  2\n","Using entropy sampling on  38944  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n"]},{"name":"stdout","output_type":"stream","text":["Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1616\n","Training samples:  1616\n","Training\n","Epoch:  1\n","Train loss:  2.1191763281822205\n","Validation loss:  2.1706156015396116\n","Epoch time -----  1.1517179012298584  sec\n","Epoch:  2\n","Train loss:  2.0522063007721534\n","Validation loss:  2.109854203462601\n","Epoch time -----  1.077918529510498  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.9882575823710515\n","Validation loss:  2.0389519333839417\n","Epoch time -----  1.0931484699249268  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.9120680598112254\n","Validation loss:  2.0132398456335068\n","Epoch time -----  1.2672398090362549  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.8650391972981966\n","Validation loss:  1.935064160823822\n","Epoch time -----  1.0677788257598877  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.7974582589589632\n","Validation loss:  1.9013551592826843\n","Epoch time -----  1.137558937072754  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.7421744970174937\n","Validation loss:  1.8948135048151016\n","Epoch time -----  1.2369499206542969  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.7140880181239202\n","Validation loss:  1.8331093072891236\n","Epoch time -----  1.2452147006988525  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.6771661914311922\n","Validation loss:  1.832091835141182\n","Epoch time -----  1.2378740310668945  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.6799564086473906\n","Validation loss:  1.810064008831978\n","Epoch time -----  1.286604642868042  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  25.7\n","Round:  3\n","Using entropy sampling on  38384  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  711  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2186\n","Training samples:  2186\n","Training\n","Epoch:  1\n","Train loss:  1.770715182168143\n","Validation loss:  1.8020199358463287\n","Epoch time -----  1.3974905014038086  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.720596126147679\n","Validation loss:  1.7945158213377\n","Epoch time -----  1.402705430984497  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.6811094215938023\n","Validation loss:  1.6781822949647904\n","Epoch time -----  1.3813388347625732  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.6176293509347097\n","Validation loss:  1.689805167913437\n","Epoch time -----  1.3001768589019775  sec\n","Epoch:  5\n","Train loss:  1.5983798265457154\n","Validation loss:  1.6997378885746002\n","Epoch time -----  1.2563514709472656  sec\n","Epoch:  6\n","Train loss:  1.5861246483666556\n","Validation loss:  1.6660263389348984\n","Epoch time -----  1.3025689125061035  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.552289526803153\n","Validation loss:  1.5947667837142945\n","Epoch time -----  1.2755889892578125  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5350975138800484\n","Validation loss:  1.5835063129663467\n","Epoch time -----  1.245335578918457  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.5233223029545375\n","Validation loss:  1.5947199523448945\n","Epoch time -----  1.112234354019165  sec\n","Epoch:  10\n","Train loss:  1.5104880605425153\n","Validation loss:  1.5686851263046264\n","Epoch time -----  1.2231290340423584  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  29.87\n","Round:  4\n","Using entropy sampling on  37814  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2759\n","Training samples:  2759\n","Training\n","Epoch:  1\n","Train loss:  1.6400109068913893\n","Validation loss:  2.3277727246284483\n","Epoch time -----  1.279033899307251  sec\n","Epoch:  2\n","Train loss:  1.6022402915087612\n","Validation loss:  1.8705810070037843\n","Epoch time -----  1.626335620880127  sec\n","Epoch:  3\n","Train loss:  1.5639167021621356\n","Validation loss:  1.5796525448560714\n","Epoch time -----  1.465238094329834  sec\n","Epoch:  4\n","Train loss:  1.547331064939499\n","Validation loss:  1.5070474803447724\n","Epoch time -----  1.4295036792755127  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.536930187181993\n","Validation loss:  1.6751978605985642\n","Epoch time -----  1.3470726013183594  sec\n","Epoch:  6\n","Train loss:  1.5225339829921722\n","Validation loss:  1.500791135430336\n","Epoch time -----  1.3452491760253906  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.494891567663713\n","Validation loss:  1.5363444298505784\n","Epoch time -----  1.4881443977355957  sec\n","Epoch:  8\n","Train loss:  1.4906800795685162\n","Validation loss:  1.497211068868637\n","Epoch time -----  1.440138578414917  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4690090932629325\n","Validation loss:  1.4646841049194337\n","Epoch time -----  1.3873329162597656  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.464518201622096\n","Validation loss:  1.4760360032320023\n","Epoch time -----  1.4579493999481201  sec\n","Testing\n","Test accuracy:  38.9\n","Round:  5\n","Using entropy sampling on  37241  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  724  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3341\n","Training samples:  3341\n","Training\n","Epoch:  1\n","Train loss:  1.588093730638612\n","Validation loss:  1.5602203160524368\n","Epoch time -----  1.4162318706512451  sec\n","Epoch:  2\n","Train loss:  1.5588194401759021\n","Validation loss:  1.4883514136075973\n","Epoch time -----  1.6290080547332764  sec\n","Epoch:  3\n","Train loss:  1.5320876859269053\n","Validation loss:  1.450356099009514\n","Epoch time -----  1.3864490985870361  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.508206234787995\n","Validation loss:  1.4288378357887268\n","Epoch time -----  1.5496494770050049  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.49843301188271\n","Validation loss:  1.427317076921463\n","Epoch time -----  1.719118356704712  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4676816351008866\n","Validation loss:  1.4316697776317597\n","Epoch time -----  1.5676357746124268  sec\n","Epoch:  7\n","Train loss:  1.475120429722768\n","Validation loss:  1.4290556252002715\n","Epoch time -----  1.7082042694091797  sec\n","Epoch:  8\n","Train loss:  1.4606885325233891\n","Validation loss:  1.4124243289232254\n","Epoch time -----  1.5611310005187988  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.452350818885947\n","Validation loss:  1.3943696469068527\n","Epoch time -----  1.4685895442962646  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4386762920415626\n","Validation loss:  1.3949286967515946\n","Epoch time -----  1.5290591716766357  sec\n","Epoch:  11\n","Train loss:  1.4260338139983844\n","Validation loss:  1.3891648799180984\n","Epoch time -----  1.5745010375976562  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  48.04\n","Round:  6\n","Using entropy sampling on  36659  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  732  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3927\n","Training samples:  3927\n","Training\n","Epoch:  1\n","Train loss:  1.5514253704778609\n","Validation loss:  1.4217189222574234\n","Epoch time -----  1.8378522396087646  sec\n","Epoch:  2\n","Train loss:  1.5154657171618553\n","Validation loss:  1.4752021133899689\n","Epoch time -----  1.7478446960449219  sec\n","Epoch:  3\n","Train loss:  1.485713952972043\n","Validation loss:  1.4000775575637818\n","Epoch time -----  1.8279671669006348  sec\n","Epoch:  4\n","Train loss:  1.4672613163148203\n","Validation loss:  1.3689223319292068\n","Epoch time -----  1.787968635559082  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4472712509093746\n","Validation loss:  1.3465962260961533\n","Epoch time -----  1.6294174194335938  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4459857440763904\n","Validation loss:  1.3453769564628602\n","Epoch time -----  1.5927081108093262  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4178208304989723\n","Validation loss:  1.3612116813659667\n","Epoch time -----  1.7574026584625244  sec\n","Epoch:  8\n","Train loss:  1.4143680641728062\n","Validation loss:  1.3231889963150025\n","Epoch time -----  1.7258329391479492  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4032535149205116\n","Validation loss:  1.3263881862163545\n","Epoch time -----  1.7249031066894531  sec\n","Epoch:  10\n","Train loss:  1.3909206967200003\n","Validation loss:  1.3189851969480515\n","Epoch time -----  1.6665198802947998  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.385783928055917\n","Validation loss:  1.3186089426279068\n","Epoch time -----  1.8347830772399902  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  61.25\n","Round:  7\n","Using entropy sampling on  36073  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  738  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4519\n","Training samples:  4519\n","Training\n","Epoch:  1\n","Train loss:  1.494514675207541\n","Validation loss:  1.3968576237559318\n","Epoch time -----  1.8876888751983643  sec\n","Epoch:  2\n","Train loss:  1.460698878261405\n","Validation loss:  1.305509266257286\n","Epoch time -----  1.7103240489959717  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.4448230770272268\n","Validation loss:  1.3202877819538117\n","Epoch time -----  1.8401458263397217  sec\n","Epoch:  4\n","Train loss:  1.4274592382807127\n","Validation loss:  1.2781474515795708\n","Epoch time -----  1.9666814804077148  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.397689592670387\n","Validation loss:  1.259510326385498\n","Epoch time -----  1.8942766189575195  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3930039691253446\n","Validation loss:  1.2807122051715851\n","Epoch time -----  1.8527247905731201  sec\n","Epoch:  7\n","Train loss:  1.366611361503601\n","Validation loss:  1.248191924393177\n","Epoch time -----  1.9813477993011475  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3559528740359024\n","Validation loss:  1.2631041377782821\n","Epoch time -----  1.947007417678833  sec\n","Epoch:  9\n","Train loss:  1.3548211698800745\n","Validation loss:  1.2445069700479507\n","Epoch time -----  1.7631275653839111  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3442855099557152\n","Validation loss:  1.2525234669446945\n","Epoch time -----  1.8705768585205078  sec\n","Epoch:  11\n","Train loss:  1.3209828020821155\n","Validation loss:  1.248611357808113\n","Epoch time -----  1.8894784450531006  sec\n","Testing\n","Test accuracy:  72.26\n","Round:  8\n","Using entropy sampling on  35481  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5119\n","Training samples:  5119\n","Training\n","Epoch:  1\n","Train loss:  1.4401184558868407\n","Validation loss:  1.2480817884206772\n","Epoch time -----  2.0586788654327393  sec\n","Epoch:  2\n","Train loss:  1.4106206476688385\n","Validation loss:  1.2256109476089478\n","Epoch time -----  2.1464157104492188  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3785903856158257\n","Validation loss:  1.2535085812211038\n","Epoch time -----  2.2263338565826416  sec\n","Epoch:  4\n","Train loss:  1.358178573846817\n","Validation loss:  1.2442191988229752\n","Epoch time -----  2.0261054039001465  sec\n","Epoch:  5\n","Train loss:  1.3546001434326171\n","Validation loss:  1.2227048009634018\n","Epoch time -----  1.962465763092041  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.337487530708313\n","Validation loss:  1.217055682837963\n","Epoch time -----  1.9811716079711914  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3226444333791734\n","Validation loss:  1.215870887041092\n","Epoch time -----  2.2306981086730957  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.315380023419857\n","Validation loss:  1.2164955973625182\n","Epoch time -----  1.8700013160705566  sec\n","Epoch:  9\n","Train loss:  1.2941785424947738\n","Validation loss:  1.2028758391737937\n","Epoch time -----  2.3191776275634766  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2880955651402473\n","Validation loss:  1.203289358317852\n","Epoch time -----  2.333662509918213  sec\n","Epoch:  11\n","Train loss:  1.2819198846817017\n","Validation loss:  1.210016119480133\n","Epoch time -----  1.9275233745574951  sec\n","Testing\n","Test accuracy:  78.71\n","Round:  9\n","Using entropy sampling on  34881  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5722\n","Training samples:  5722\n","Training\n","Epoch:  1\n","Train loss:  1.3948421359062195\n","Validation loss:  1.2533494532108307\n","Epoch time -----  2.3421645164489746  sec\n","Epoch:  2\n","Train loss:  1.3789998120731777\n","Validation loss:  1.2190451577305794\n","Epoch time -----  2.3782830238342285  sec\n","Epoch:  3\n","Train loss:  1.359114870760176\n","Validation loss:  1.2224884733557702\n","Epoch time -----  2.274153709411621  sec\n","Epoch:  4\n","Train loss:  1.3303612854745652\n","Validation loss:  1.2313763037323953\n","Epoch time -----  2.4799821376800537  sec\n","Epoch:  5\n","Train loss:  1.3133736782603793\n","Validation loss:  1.19347782433033\n","Epoch time -----  2.6769955158233643  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.2977492233117423\n","Validation loss:  1.1813830509781837\n","Epoch time -----  2.5429327487945557  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.2875579880343544\n","Validation loss:  1.1777393341064453\n","Epoch time -----  2.2356059551239014  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2790654367870755\n","Validation loss:  1.1770380973815917\n","Epoch time -----  2.000317335128784  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2685339940918816\n","Validation loss:  1.1661537408828735\n","Epoch time -----  2.3983607292175293  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2553269399536982\n","Validation loss:  1.1774274051189422\n","Epoch time -----  2.3803200721740723  sec\n","Epoch:  11\n","Train loss:  1.253661855061849\n","Validation loss:  1.166168536245823\n","Epoch time -----  2.128304958343506  sec\n","Testing\n","Test accuracy:  84.43\n","Round:  10\n","Using entropy sampling on  34278  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  760  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6333\n","Training samples:  6333\n","Training\n","Epoch:  1\n","Train loss:  1.3635792587742661\n","Validation loss:  1.1915567725896836\n","Epoch time -----  2.4153707027435303  sec\n","Epoch:  2\n","Train loss:  1.3325617891369443\n","Validation loss:  1.172234085202217\n","Epoch time -----  2.3822991847991943  sec\n","Epoch:  3\n","Train loss:  1.304067850112915\n","Validation loss:  1.1685583993792534\n","Epoch time -----  2.493088722229004  sec\n","Epoch:  4\n","Train loss:  1.2927542250565809\n","Validation loss:  1.157519742846489\n","Epoch time -----  2.3277156352996826  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.270222858949141\n","Validation loss:  1.171148343384266\n","Epoch time -----  2.4184987545013428  sec\n","Epoch:  6\n","Train loss:  1.2634551886356238\n","Validation loss:  1.1587319865822792\n","Epoch time -----  2.3706302642822266  sec\n","Epoch:  7\n","Train loss:  1.2474381255381035\n","Validation loss:  1.156315302848816\n","Epoch time -----  2.2521486282348633  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.239211016231113\n","Validation loss:  1.1538060978055\n","Epoch time -----  2.339836359024048  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2349824887333494\n","Validation loss:  1.1656303852796555\n","Epoch time -----  2.4502928256988525  sec\n","Epoch:  10\n","Train loss:  1.2244030935595733\n","Validation loss:  1.1607721418142318\n","Epoch time -----  2.3441269397735596  sec\n","Epoch:  11\n","Train loss:  1.2099055954904268\n","Validation loss:  1.1662748232483864\n","Epoch time -----  2.3665506839752197  sec\n","Epoch:  12\n","Train loss:  1.202811279682198\n","Validation loss:  1.1572021827101708\n","Epoch time -----  2.4049036502838135  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 20%|â–ˆâ–ˆ        | 2/10 [10:32<42:14, 316.87s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  87.37\n","Using CUDA\n","Test accuracy:  10.23\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.3107657432556152\n","Validation loss:  2.2845195174217223\n","Epoch time -----  0.877964973449707  sec\n","Epoch:  2\n","Train loss:  2.271396279335022\n","Validation loss:  2.2596258580684663\n","Epoch time -----  0.9350423812866211  sec\n","Epoch:  3\n","Train loss:  2.26408788561821\n","Validation loss:  2.247281330823898\n","Epoch time -----  0.9932258129119873  sec\n","Epoch:  4\n","Train loss:  2.254670023918152\n","Validation loss:  2.2381049752235413\n","Epoch time -----  0.954766035079956  sec\n","Epoch:  5\n","Train loss:  2.2407099306583405\n","Validation loss:  2.2296258985996245\n","Epoch time -----  0.9764053821563721  sec\n","Epoch:  6\n","Train loss:  2.234812378883362\n","Validation loss:  2.22291961312294\n","Epoch time -----  0.9711182117462158  sec\n","Epoch:  7\n","Train loss:  2.2231242954730988\n","Validation loss:  2.2172911047935484\n","Epoch time -----  0.9772403240203857  sec\n","Epoch:  8\n","Train loss:  2.225753366947174\n","Validation loss:  2.2135006546974183\n","Epoch time -----  1.0483183860778809  sec\n","Epoch:  9\n","Train loss:  2.2199533581733704\n","Validation loss:  2.210303944349289\n","Epoch time -----  0.9512128829956055  sec\n","Epoch:  10\n","Train loss:  2.2144402265548706\n","Validation loss:  2.207791942358017\n","Epoch time -----  0.9442675113677979  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  693  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1055\n","Training samples:  1055\n","Training\n","Epoch:  1\n","Train loss:  2.1566246537601246\n","Validation loss:  2.2033206939697267\n","Epoch time -----  1.0591211318969727  sec\n","Epoch:  2\n","Train loss:  2.078580793212442\n","Validation loss:  2.250645524263382\n","Epoch time -----  1.149026870727539  sec\n","Epoch:  3\n","Train loss:  2.051556012209724\n","Validation loss:  2.2594234228134153\n","Epoch time -----  1.1319830417633057  sec\n","Epoch:  4\n","Train loss:  2.0451860007117775\n","Validation loss:  2.2348037719726563\n","Epoch time -----  1.133852243423462  sec\n","Epoch:  5\n","Train loss:  2.054889110957875\n","Validation loss:  2.232124787569046\n","Epoch time -----  1.138641357421875  sec\n","Epoch:  6\n","Train loss:  2.035061710021075\n","Validation loss:  2.2387645483016967\n","Epoch time -----  1.166752815246582  sec\n","Epoch:  7\n","Train loss:  2.020085131420809\n","Validation loss:  2.233191245794296\n","Epoch time -----  1.1187145709991455  sec\n","Epoch:  8\n","Train loss:  2.0292769880855785\n","Validation loss:  2.229144334793091\n","Epoch time -----  1.107506513595581  sec\n","Epoch:  9\n","Train loss:  2.0259236097335815\n","Validation loss:  2.2311772286891935\n","Epoch time -----  1.0585484504699707  sec\n","Epoch:  10\n","Train loss:  2.016638622564428\n","Validation loss:  2.227424842119217\n","Epoch time -----  1.0668249130249023  sec\n","Testing\n","Test accuracy:  16.18\n","Round:  2\n","Using entropy sampling on  38945  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1615\n","Training samples:  1615\n","Training\n","Epoch:  1\n","Train loss:  2.0383351628596964\n","Validation loss:  2.1764406681060793\n","Epoch time -----  1.2199125289916992  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.9596967376195467\n","Validation loss:  2.149793100357056\n","Epoch time -----  1.1781883239746094  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.8644992479911218\n","Validation loss:  2.1139147162437437\n","Epoch time -----  1.2216613292694092  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.8179724354010363\n","Validation loss:  2.0367318361997606\n","Epoch time -----  1.14695143699646  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.7512711057296166\n","Validation loss:  2.0307992100715637\n","Epoch time -----  1.1230566501617432  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.7130710941094618\n","Validation loss:  1.9871735543012619\n","Epoch time -----  1.0564537048339844  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.6910845316373384\n","Validation loss:  1.976772066950798\n","Epoch time -----  1.1006433963775635  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.6732874191724336\n","Validation loss:  1.952159184217453\n","Epoch time -----  1.1956841945648193  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.6429077203457172\n","Validation loss:  1.9338223397731782\n","Epoch time -----  1.2200927734375  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.637617996105781\n","Validation loss:  1.9273667722940444\n","Epoch time -----  1.119882583618164  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  16.33\n","Round:  3\n","Using entropy sampling on  38385  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  708  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2183\n","Training samples:  2183\n","Training\n","Epoch:  1\n","Train loss:  1.7674580880573818\n","Validation loss:  1.9719363301992416\n","Epoch time -----  1.2741873264312744  sec\n","Epoch:  2\n","Train loss:  1.7187144824436733\n","Validation loss:  1.9962837278842926\n","Epoch time -----  1.3730578422546387  sec\n","Epoch:  3\n","Train loss:  1.660740726334708\n","Validation loss:  1.827061766386032\n","Epoch time -----  1.41927170753479  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.6201944828033448\n","Validation loss:  1.8058695167303085\n","Epoch time -----  1.2020325660705566  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5803232976368495\n","Validation loss:  1.8123166888952256\n","Epoch time -----  1.2713000774383545  sec\n","Epoch:  6\n","Train loss:  1.5664698192051478\n","Validation loss:  1.7593059241771698\n","Epoch time -----  1.448768138885498  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.5667103222438268\n","Validation loss:  1.7329323440790176\n","Epoch time -----  1.4310932159423828  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5316340173993792\n","Validation loss:  1.6741579353809357\n","Epoch time -----  1.4711201190948486  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.499413057735988\n","Validation loss:  1.690117174386978\n","Epoch time -----  1.2290728092193604  sec\n","Epoch:  10\n","Train loss:  1.5004468781607492\n","Validation loss:  1.6728726357221604\n","Epoch time -----  1.3211183547973633  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  26.9\n","Round:  4\n","Using entropy sampling on  37817  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2755\n","Training samples:  2755\n","Training\n","Epoch:  1\n","Train loss:  1.63749420913783\n","Validation loss:  1.800434336066246\n","Epoch time -----  1.3750889301300049  sec\n","Epoch:  2\n","Train loss:  1.6039904085072605\n","Validation loss:  1.908067712187767\n","Epoch time -----  1.4176974296569824  sec\n","Epoch:  3\n","Train loss:  1.5979763892563907\n","Validation loss:  1.8335496187210083\n","Epoch time -----  1.525456190109253  sec\n","Epoch:  4\n","Train loss:  1.5664810727943073\n","Validation loss:  1.8377652913331985\n","Epoch time -----  1.593529462814331  sec\n","Epoch:  5\n","Train loss:  1.5587462403557517\n","Validation loss:  1.8240151345729827\n","Epoch time -----  1.5801479816436768  sec\n","Epoch:  6\n","Train loss:  1.5412948456677524\n","Validation loss:  1.6374002248048782\n","Epoch time -----  1.6968610286712646  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.5217271826483987\n","Validation loss:  1.6269762635231018\n","Epoch time -----  1.4443814754486084  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5029655667868527\n","Validation loss:  1.5583312332630157\n","Epoch time -----  1.5986676216125488  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.5123000172051517\n","Validation loss:  1.5618396520614624\n","Epoch time -----  1.3651478290557861  sec\n","Epoch:  10\n","Train loss:  1.500656466592442\n","Validation loss:  1.5923299461603164\n","Epoch time -----  1.2654354572296143  sec\n","Testing\n","Test accuracy:  39.16\n","Round:  5\n","Using entropy sampling on  37245  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  723  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3334\n","Training samples:  3334\n","Training\n","Epoch:  1\n","Train loss:  1.5774186647163246\n","Validation loss:  1.6870132297277451\n","Epoch time -----  1.7553811073303223  sec\n","Epoch:  2\n","Train loss:  1.5485978733818486\n","Validation loss:  1.5917308062314988\n","Epoch time -----  1.775209903717041  sec\n","Epoch:  3\n","Train loss:  1.5500544714477826\n","Validation loss:  1.6060846626758576\n","Epoch time -----  1.4987449645996094  sec\n","Epoch:  4\n","Train loss:  1.5195303548057124\n","Validation loss:  1.5949161618947982\n","Epoch time -----  1.7127220630645752  sec\n","Epoch:  5\n","Train loss:  1.522174542804934\n","Validation loss:  1.545661348104477\n","Epoch time -----  1.5449421405792236  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4970192077024929\n","Validation loss:  1.549056825041771\n","Epoch time -----  1.6573121547698975  sec\n","Epoch:  7\n","Train loss:  1.4913570678459023\n","Validation loss:  1.4625496715307236\n","Epoch time -----  1.614603042602539  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4832901032465808\n","Validation loss:  1.4597725689411163\n","Epoch time -----  1.6689658164978027  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4699676756588917\n","Validation loss:  1.4886013358831405\n","Epoch time -----  1.6246898174285889  sec\n","Epoch:  10\n","Train loss:  1.4613159782481644\n","Validation loss:  1.4927677810192108\n","Epoch time -----  1.7751502990722656  sec\n","Epoch:  11\n","Train loss:  1.4710516029933713\n","Validation loss:  1.4608578979969025\n","Epoch time -----  1.5991184711456299  sec\n","Testing\n","Test accuracy:  45.67\n","Round:  6\n","Using entropy sampling on  36666  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  730  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3918\n","Training samples:  3918\n","Training\n","Epoch:  1\n","Train loss:  1.570774011073574\n","Validation loss:  1.5732188075780869\n","Epoch time -----  1.5696008205413818  sec\n","Epoch:  2\n","Train loss:  1.53407702138347\n","Validation loss:  1.4627428740262984\n","Epoch time -----  1.7236530780792236  sec\n","Epoch:  3\n","Train loss:  1.5217437071184958\n","Validation loss:  1.587721186876297\n","Epoch time -----  1.7901332378387451  sec\n","Epoch:  4\n","Train loss:  1.502377248579456\n","Validation loss:  1.449128645658493\n","Epoch time -----  1.9434230327606201  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.489211630436682\n","Validation loss:  1.4724436342716216\n","Epoch time -----  1.897449254989624  sec\n","Epoch:  6\n","Train loss:  1.4837257746727235\n","Validation loss:  1.395933026075363\n","Epoch time -----  1.9747841358184814  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4627517865550133\n","Validation loss:  1.403852206468582\n","Epoch time -----  1.9618542194366455  sec\n","Epoch:  8\n","Train loss:  1.4623042152773948\n","Validation loss:  1.3977927654981612\n","Epoch time -----  1.5186667442321777  sec\n","Epoch:  9\n","Train loss:  1.4430708500646776\n","Validation loss:  1.4036778211593628\n","Epoch time -----  1.607964038848877  sec\n","Epoch:  10\n","Train loss:  1.4407434732683244\n","Validation loss:  1.3766811192035675\n","Epoch time -----  1.8280150890350342  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4489994452845665\n","Validation loss:  1.3931276381015778\n","Epoch time -----  1.8503408432006836  sec\n","Testing\n","Test accuracy:  54.82\n","Round:  7\n","Using entropy sampling on  36082  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  736  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4509\n","Training samples:  4509\n","Training\n","Epoch:  1\n","Train loss:  1.5289065804280026\n","Validation loss:  1.3927679151296615\n","Epoch time -----  1.7505207061767578  sec\n","Epoch:  2\n","Train loss:  1.5046674802269735\n","Validation loss:  1.3660964906215667\n","Epoch time -----  1.7511484622955322  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.4805327838575337\n","Validation loss:  1.3514911592006684\n","Epoch time -----  1.7743477821350098  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.472912612095685\n","Validation loss:  1.345516738295555\n","Epoch time -----  2.0245280265808105  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4625190294964212\n","Validation loss:  1.3363961547613143\n","Epoch time -----  2.079678773880005  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4470617670408437\n","Validation loss:  1.3403998583555221\n","Epoch time -----  2.2040679454803467  sec\n","Epoch:  7\n","Train loss:  1.4271908293307667\n","Validation loss:  1.3330032020807265\n","Epoch time -----  1.678253412246704  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4280229420729087\n","Validation loss:  1.3239978969097137\n","Epoch time -----  1.967317819595337  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3974802695529562\n","Validation loss:  1.3169354856014253\n","Epoch time -----  1.6005816459655762  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4011184145027482\n","Validation loss:  1.3127520501613616\n","Epoch time -----  2.193937301635742  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4029610711084286\n","Validation loss:  1.3171611607074738\n","Epoch time -----  2.0044374465942383  sec\n","Testing\n","Test accuracy:  64.85\n","Round:  8\n","Using entropy sampling on  35491  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5105\n","Training samples:  5105\n","Training\n","Epoch:  1\n","Train loss:  1.4803998231887818\n","Validation loss:  1.2986232846975327\n","Epoch time -----  2.065455913543701  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.4625105395913125\n","Validation loss:  1.3248351782560348\n","Epoch time -----  2.259305477142334  sec\n","Epoch:  3\n","Train loss:  1.4476246953010559\n","Validation loss:  1.290219721198082\n","Epoch time -----  2.1714181900024414  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4190258622169494\n","Validation loss:  1.3277357518672943\n","Epoch time -----  1.9464411735534668  sec\n","Epoch:  5\n","Train loss:  1.4033277064561844\n","Validation loss:  1.2728178024291992\n","Epoch time -----  2.2261435985565186  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3900756374001504\n","Validation loss:  1.2755192697048188\n","Epoch time -----  2.2673487663269043  sec\n","Epoch:  7\n","Train loss:  1.3761371672153473\n","Validation loss:  1.2585553228855133\n","Epoch time -----  2.2113912105560303  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3742120206356048\n","Validation loss:  1.2585475653409959\n","Epoch time -----  2.0724284648895264  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3515502631664276\n","Validation loss:  1.2519581764936447\n","Epoch time -----  2.1062328815460205  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3579888984560966\n","Validation loss:  1.257610222697258\n","Epoch time -----  1.753657341003418  sec\n","Epoch:  11\n","Train loss:  1.3517265364527702\n","Validation loss:  1.2528887063264846\n","Epoch time -----  1.9939179420471191  sec\n","Testing\n","Test accuracy:  72.76\n","Round:  9\n","Using entropy sampling on  34895  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  752  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5707\n","Training samples:  5707\n","Training\n","Epoch:  1\n","Train loss:  1.4473467336760626\n","Validation loss:  1.3539592564105987\n","Epoch time -----  2.0080738067626953  sec\n","Epoch:  2\n","Train loss:  1.4177402642038133\n","Validation loss:  1.3125377297401428\n","Epoch time -----  2.1410634517669678  sec\n","Epoch:  3\n","Train loss:  1.4033861226505704\n","Validation loss:  1.2837946563959122\n","Epoch time -----  2.382709503173828  sec\n","Epoch:  4\n","Train loss:  1.3732121136453417\n","Validation loss:  1.2747457325458527\n","Epoch time -----  2.421659231185913  sec\n","Epoch:  5\n","Train loss:  1.367180675930447\n","Validation loss:  1.2425481021404265\n","Epoch time -----  2.4764556884765625  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3447753694322375\n","Validation loss:  1.2085228234529495\n","Epoch time -----  2.2427423000335693  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3236130370034112\n","Validation loss:  1.2105062156915665\n","Epoch time -----  2.0139658451080322  sec\n","Epoch:  8\n","Train loss:  1.3194108658366732\n","Validation loss:  1.2014576643705368\n","Epoch time -----  2.3920373916625977  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3182745456695557\n","Validation loss:  1.2092208579182624\n","Epoch time -----  2.3929595947265625  sec\n","Epoch:  10\n","Train loss:  1.3063215878274705\n","Validation loss:  1.19648068100214\n","Epoch time -----  2.374105215072632  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3042504449685415\n","Validation loss:  1.2069485679268837\n","Epoch time -----  2.3617186546325684  sec\n","Testing\n","Test accuracy:  77.97\n","Round:  10\n","Using entropy sampling on  34293  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  759  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6315\n","Training samples:  6315\n","Training\n","Epoch:  1\n","Train loss:  1.394971824655629\n","Validation loss:  1.2315508708357812\n","Epoch time -----  2.0916826725006104  sec\n","Epoch:  2\n","Train loss:  1.3745688946560175\n","Validation loss:  1.187788200378418\n","Epoch time -----  2.537780284881592  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3492475555400656\n","Validation loss:  1.1804418876767158\n","Epoch time -----  2.2999439239501953  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.324110533251907\n","Validation loss:  1.173046787083149\n","Epoch time -----  2.462022304534912  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3168701920846495\n","Validation loss:  1.1981953233480453\n","Epoch time -----  2.484799385070801  sec\n","Epoch:  6\n","Train loss:  1.3003250793977217\n","Validation loss:  1.1615720435976982\n","Epoch time -----  2.5097808837890625  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.289252883256084\n","Validation loss:  1.163019908964634\n","Epoch time -----  2.4080915451049805  sec\n","Epoch:  8\n","Train loss:  1.2886313549195878\n","Validation loss:  1.162332944571972\n","Epoch time -----  2.5499141216278076  sec\n","Epoch:  9\n","Train loss:  1.2749430422831063\n","Validation loss:  1.1765834212303161\n","Epoch time -----  2.474832773208618  sec\n","Epoch:  10\n","Train loss:  1.2633166361336756\n","Validation loss:  1.1674961134791375\n","Epoch time -----  2.5091030597686768  sec\n","Epoch:  11\n","Train loss:  1.2578992554635713\n","Validation loss:  1.159726843237877\n","Epoch time -----  2.505362033843994  sec\n","validation loss minimum, saving model\n","Epoch:  12\n","Train loss:  1.2537907235550159\n","Validation loss:  1.1649106055498124\n","Epoch time -----  2.274841785430908  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [16:05<37:50, 324.32s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  85.27\n","Using CUDA\n","Test accuracy:  11.72\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.3209023475646973\n","Validation loss:  2.3079549789428713\n","Epoch time -----  1.068878412246704  sec\n","Epoch:  2\n","Train loss:  2.305514693260193\n","Validation loss:  2.2961997628211974\n","Epoch time -----  1.100799798965454  sec\n","Epoch:  3\n","Train loss:  2.2928656339645386\n","Validation loss:  2.2848623514175417\n","Epoch time -----  1.184237003326416  sec\n","Epoch:  4\n","Train loss:  2.283745288848877\n","Validation loss:  2.274672472476959\n","Epoch time -----  1.0634117126464844  sec\n","Epoch:  5\n","Train loss:  2.2711574733257294\n","Validation loss:  2.2648635864257813\n","Epoch time -----  1.1220753192901611  sec\n","Epoch:  6\n","Train loss:  2.260603815317154\n","Validation loss:  2.255221837759018\n","Epoch time -----  1.0869879722595215  sec\n","Epoch:  7\n","Train loss:  2.2467877566814423\n","Validation loss:  2.2460338711738586\n","Epoch time -----  1.0802934169769287  sec\n","Epoch:  8\n","Train loss:  2.2449029088020325\n","Validation loss:  2.2386438071727754\n","Epoch time -----  1.0956122875213623  sec\n","Epoch:  9\n","Train loss:  2.2309361398220062\n","Validation loss:  2.2319862842559814\n","Epoch time -----  1.1252574920654297  sec\n","Epoch:  10\n","Train loss:  2.2344928979873657\n","Validation loss:  2.2275982201099396\n","Epoch time -----  1.1547327041625977  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  694  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1056\n","Training samples:  1056\n","Training\n","Epoch:  1\n","Train loss:  2.1898021697998047\n","Validation loss:  2.2069625556468964\n","Epoch time -----  1.25431489944458  sec\n","Epoch:  2\n","Train loss:  2.1266732496373795\n","Validation loss:  2.222256654500961\n","Epoch time -----  1.2115116119384766  sec\n","Epoch:  3\n","Train loss:  2.095562864752377\n","Validation loss:  2.2400401532649994\n","Epoch time -----  1.0980596542358398  sec\n","Epoch:  4\n","Train loss:  2.09035483528586\n","Validation loss:  2.239286106824875\n","Epoch time -----  1.1020770072937012  sec\n","Epoch:  5\n","Train loss:  2.0849872757406795\n","Validation loss:  2.2319905757904053\n","Epoch time -----  1.1469197273254395  sec\n","Epoch:  6\n","Train loss:  2.07755007463343\n","Validation loss:  2.2294098138809204\n","Epoch time -----  1.1143808364868164  sec\n","Epoch:  7\n","Train loss:  2.0784187457140755\n","Validation loss:  2.227086639404297\n","Epoch time -----  1.1742725372314453  sec\n","Epoch:  8\n","Train loss:  2.06400569747476\n","Validation loss:  2.224133664369583\n","Epoch time -----  1.1128017902374268  sec\n","Epoch:  9\n","Train loss:  2.059861484695883\n","Validation loss:  2.2247502982616423\n","Epoch time -----  1.0874404907226562  sec\n","Epoch:  10\n","Train loss:  2.05722213492674\n","Validation loss:  2.2218714892864226\n","Epoch time -----  1.150871992111206  sec\n","Testing\n","Test accuracy:  15.34\n","Round:  2\n","Using entropy sampling on  38944  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1616\n","Training samples:  1616\n","Training\n","Epoch:  1\n","Train loss:  2.0196934204835157\n","Validation loss:  2.1899450361728667\n","Epoch time -----  1.2061798572540283  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.9373648441754854\n","Validation loss:  2.1622601807117463\n","Epoch time -----  1.1670193672180176  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.8551992223812983\n","Validation loss:  2.1613453686237336\n","Epoch time -----  1.2063827514648438  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.8077733058195848\n","Validation loss:  2.0745630294084547\n","Epoch time -----  1.382077693939209  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.761920227454259\n","Validation loss:  2.0491199612617494\n","Epoch time -----  1.2283265590667725  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.71963304739732\n","Validation loss:  2.020370614528656\n","Epoch time -----  1.1776578426361084  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.6861701745253344\n","Validation loss:  2.000725966691971\n","Epoch time -----  1.2182362079620361  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.6730425953865051\n","Validation loss:  1.9771844357252122\n","Epoch time -----  1.2331993579864502  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.654924974991725\n","Validation loss:  1.9729257881641389\n","Epoch time -----  1.2267780303955078  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.6213397567088788\n","Validation loss:  1.9555255204439164\n","Epoch time -----  1.3178696632385254  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  28.71\n","Round:  3\n","Using entropy sampling on  38384  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  712  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2186\n","Training samples:  2186\n","Training\n","Epoch:  1\n","Train loss:  1.7634433473859514\n","Validation loss:  1.8852149844169617\n","Epoch time -----  1.344972848892212  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.7087231022971017\n","Validation loss:  1.8454510807991027\n","Epoch time -----  1.3459734916687012  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.6606028727122715\n","Validation loss:  1.8059572398662567\n","Epoch time -----  1.260232925415039  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.6082769462040492\n","Validation loss:  1.7489628612995147\n","Epoch time -----  1.40653395652771  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5997460194996425\n","Validation loss:  1.7354539781808853\n","Epoch time -----  1.3316352367401123  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.5685463156018937\n","Validation loss:  1.7145243793725968\n","Epoch time -----  1.3747732639312744  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.5389932938984463\n","Validation loss:  1.6893962770700455\n","Epoch time -----  1.3461341857910156  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5394008670534407\n","Validation loss:  1.6653482884168624\n","Epoch time -----  1.3308064937591553  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.5093230281557355\n","Validation loss:  1.6543729901313782\n","Epoch time -----  1.3411755561828613  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.5012542418071202\n","Validation loss:  1.638188973069191\n","Epoch time -----  1.313338041305542  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  40.14\n","Round:  4\n","Using entropy sampling on  37814  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2758\n","Training samples:  2758\n","Training\n","Epoch:  1\n","Train loss:  1.633775220675902\n","Validation loss:  1.6965363502502442\n","Epoch time -----  1.5369927883148193  sec\n","Epoch:  2\n","Train loss:  1.5774882029403339\n","Validation loss:  1.6481878876686096\n","Epoch time -----  1.4809165000915527  sec\n","Epoch:  3\n","Train loss:  1.5470561114224521\n","Validation loss:  1.6016084730625153\n","Epoch time -----  1.4979994297027588  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.5290130403908817\n","Validation loss:  1.6419641971588135\n","Epoch time -----  1.398850679397583  sec\n","Epoch:  5\n","Train loss:  1.502181356603449\n","Validation loss:  1.6807817608118056\n","Epoch time -----  1.3743653297424316  sec\n","Epoch:  6\n","Train loss:  1.4705586595968767\n","Validation loss:  1.523166674375534\n","Epoch time -----  1.389479398727417  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4576910734176636\n","Validation loss:  1.558874261379242\n","Epoch time -----  1.563377857208252  sec\n","Epoch:  8\n","Train loss:  1.4603216621008785\n","Validation loss:  1.528047126531601\n","Epoch time -----  1.479149580001831  sec\n","Epoch:  9\n","Train loss:  1.4356319579211148\n","Validation loss:  1.5353798985481262\n","Epoch time -----  1.4300200939178467  sec\n","Epoch:  10\n","Train loss:  1.4401099248365923\n","Validation loss:  1.5079666733741761\n","Epoch time -----  1.4842448234558105  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  46.98\n","Round:  5\n","Using entropy sampling on  37242  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  722  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3336\n","Training samples:  3336\n","Training\n","Epoch:  1\n","Train loss:  1.5447307217795894\n","Validation loss:  1.59609856903553\n","Epoch time -----  1.5275368690490723  sec\n","Epoch:  2\n","Train loss:  1.534227065320285\n","Validation loss:  1.5889478772878647\n","Epoch time -----  1.5258851051330566  sec\n","Epoch:  3\n","Train loss:  1.5160141261118762\n","Validation loss:  1.5928583890199661\n","Epoch time -----  1.5281803607940674  sec\n","Epoch:  4\n","Train loss:  1.4865531269109473\n","Validation loss:  1.470468556880951\n","Epoch time -----  1.6790614128112793  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4822150131441512\n","Validation loss:  1.5256476312875749\n","Epoch time -----  1.534233808517456  sec\n","Epoch:  6\n","Train loss:  1.4753956007507611\n","Validation loss:  1.4703290849924087\n","Epoch time -----  1.6416230201721191  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4499376472437158\n","Validation loss:  1.452923634648323\n","Epoch time -----  1.7115371227264404  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.444454382050712\n","Validation loss:  1.4303741216659547\n","Epoch time -----  1.5321018695831299  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4427019717558376\n","Validation loss:  1.4294988989830018\n","Epoch time -----  1.5617380142211914  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.430891990661621\n","Validation loss:  1.430968901515007\n","Epoch time -----  1.611642837524414  sec\n","Epoch:  11\n","Train loss:  1.436190056350996\n","Validation loss:  1.4360720485448837\n","Epoch time -----  1.5168614387512207  sec\n","Testing\n","Test accuracy:  52.01\n","Round:  6\n","Using entropy sampling on  36664  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  729  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3920\n","Training samples:  3920\n","Training\n","Epoch:  1\n","Train loss:  1.5295472221989785\n","Validation loss:  1.5073305308818816\n","Epoch time -----  1.7628729343414307  sec\n","Epoch:  2\n","Train loss:  1.5262467553538661\n","Validation loss:  1.5026518434286118\n","Epoch time -----  1.6441140174865723  sec\n","Epoch:  3\n","Train loss:  1.488742349609252\n","Validation loss:  1.4852509438991546\n","Epoch time -----  1.7203314304351807  sec\n","Epoch:  4\n","Train loss:  1.4628341332558663\n","Validation loss:  1.3722028195858003\n","Epoch time -----  1.6647849082946777  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4482325892294607\n","Validation loss:  1.378322559595108\n","Epoch time -----  1.6838974952697754  sec\n","Epoch:  6\n","Train loss:  1.426614313356338\n","Validation loss:  1.4004362106323243\n","Epoch time -----  1.6981074810028076  sec\n","Epoch:  7\n","Train loss:  1.4257572947009918\n","Validation loss:  1.3567523539066315\n","Epoch time -----  1.7247486114501953  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4251480121766367\n","Validation loss:  1.349317228794098\n","Epoch time -----  1.7781312465667725  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3902795410925342\n","Validation loss:  1.3532996326684952\n","Epoch time -----  1.6819050312042236  sec\n","Epoch:  10\n","Train loss:  1.4036942220503283\n","Validation loss:  1.3586795598268508\n","Epoch time -----  1.655491828918457  sec\n","Epoch:  11\n","Train loss:  1.3950602815997215\n","Validation loss:  1.3373976737260818\n","Epoch time -----  1.5125365257263184  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  67.6\n","Round:  7\n","Using entropy sampling on  36080  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  736  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4509\n","Training samples:  4509\n","Training\n","Epoch:  1\n","Train loss:  1.5016297706415955\n","Validation loss:  1.3851021736860276\n","Epoch time -----  1.589534044265747  sec\n","Epoch:  2\n","Train loss:  1.469204306602478\n","Validation loss:  1.343504971265793\n","Epoch time -----  1.8151330947875977  sec\n","Epoch:  3\n","Train loss:  1.4412020931781178\n","Validation loss:  1.3324598401784897\n","Epoch time -----  1.8203489780426025  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4295719526183437\n","Validation loss:  1.31141397356987\n","Epoch time -----  1.959223747253418  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.404818852182845\n","Validation loss:  1.2947441190481186\n","Epoch time -----  1.7632381916046143  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3851464315199515\n","Validation loss:  1.306097835302353\n","Epoch time -----  1.7387712001800537  sec\n","Epoch:  7\n","Train loss:  1.3814232601246363\n","Validation loss:  1.2848630994558334\n","Epoch time -----  1.937446117401123  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3597921418472074\n","Validation loss:  1.2949707627296447\n","Epoch time -----  2.0686051845550537  sec\n","Epoch:  9\n","Train loss:  1.3589360579638414\n","Validation loss:  1.2715025633573531\n","Epoch time -----  1.8259356021881104  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3544880235698862\n","Validation loss:  1.267839789390564\n","Epoch time -----  1.712141752243042  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3446129459730336\n","Validation loss:  1.2724423170089723\n","Epoch time -----  1.8685753345489502  sec\n","Testing\n","Test accuracy:  74.78\n","Round:  8\n","Using entropy sampling on  35491  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  744  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5105\n","Training samples:  5105\n","Training\n","Epoch:  1\n","Train loss:  1.4415699154138566\n","Validation loss:  1.3502089887857438\n","Epoch time -----  1.948582410812378  sec\n","Epoch:  2\n","Train loss:  1.4136062428355216\n","Validation loss:  1.2645824790000915\n","Epoch time -----  1.9774603843688965  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.388821515440941\n","Validation loss:  1.2772568136453628\n","Epoch time -----  2.0964736938476562  sec\n","Epoch:  4\n","Train loss:  1.3793118342757225\n","Validation loss:  1.2354433059692382\n","Epoch time -----  1.8835220336914062  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.356100921332836\n","Validation loss:  1.2423316955566406\n","Epoch time -----  1.973771572113037  sec\n","Epoch:  6\n","Train loss:  1.3446926847100258\n","Validation loss:  1.229760730266571\n","Epoch time -----  1.975754976272583  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3318752720952034\n","Validation loss:  1.2242115437984467\n","Epoch time -----  1.9063739776611328  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3291501842439175\n","Validation loss:  1.2209019362926483\n","Epoch time -----  1.838285207748413  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3159810289740563\n","Validation loss:  1.2122396379709244\n","Epoch time -----  1.948958158493042  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2998749680817128\n","Validation loss:  1.2157951280474664\n","Epoch time -----  1.9194543361663818  sec\n","Epoch:  11\n","Train loss:  1.2986825466156007\n","Validation loss:  1.2102085024118423\n","Epoch time -----  1.7661004066467285  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  81.22\n","Round:  9\n","Using entropy sampling on  34895  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5707\n","Training samples:  5707\n","Training\n","Epoch:  1\n","Train loss:  1.4005923165215386\n","Validation loss:  1.3301130920648574\n","Epoch time -----  1.9327313899993896  sec\n","Epoch:  2\n","Train loss:  1.3735407749811808\n","Validation loss:  1.3272088438272476\n","Epoch time -----  2.057767868041992  sec\n","Epoch:  3\n","Train loss:  1.35777315431171\n","Validation loss:  1.2638186722993852\n","Epoch time -----  1.8774547576904297  sec\n","Epoch:  4\n","Train loss:  1.3427736216121249\n","Validation loss:  1.199290508031845\n","Epoch time -----  1.9306142330169678  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3168167842759027\n","Validation loss:  1.1915394186973571\n","Epoch time -----  2.0469272136688232  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3101020071241591\n","Validation loss:  1.1940515488386154\n","Epoch time -----  2.2604756355285645  sec\n","Epoch:  7\n","Train loss:  1.2950887123743693\n","Validation loss:  1.1881266087293625\n","Epoch time -----  2.140758991241455  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.29122035768297\n","Validation loss:  1.1785890340805054\n","Epoch time -----  2.048271894454956  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2870458364486694\n","Validation loss:  1.2005423784255982\n","Epoch time -----  1.8410160541534424  sec\n","Epoch:  10\n","Train loss:  1.2779402547412448\n","Validation loss:  1.1740943968296051\n","Epoch time -----  1.6964998245239258  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2696333746115367\n","Validation loss:  1.172410562634468\n","Epoch time -----  1.8098738193511963  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  86.11\n","Round:  10\n","Using entropy sampling on  34293  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  760  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6316\n","Training samples:  6316\n","Training\n","Epoch:  1\n","Train loss:  1.372641960779826\n","Validation loss:  1.182600635290146\n","Epoch time -----  1.8550186157226562  sec\n","Epoch:  2\n","Train loss:  1.3538002462098093\n","Validation loss:  1.182615515589714\n","Epoch time -----  2.278770685195923  sec\n","Epoch:  3\n","Train loss:  1.33219554568782\n","Validation loss:  1.1721470713615418\n","Epoch time -----  1.9875872135162354  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.308496938811408\n","Validation loss:  1.1829294249415399\n","Epoch time -----  1.9156529903411865  sec\n","Epoch:  5\n","Train loss:  1.2958032693525758\n","Validation loss:  1.1692993760108947\n","Epoch time -----  1.937413215637207  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.2833913095069653\n","Validation loss:  1.158618089556694\n","Epoch time -----  1.727116346359253  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.2723284122919796\n","Validation loss:  1.148679506778717\n","Epoch time -----  1.6409058570861816  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2663654787371856\n","Validation loss:  1.1614293977618217\n","Epoch time -----  2.278359889984131  sec\n","Epoch:  9\n","Train loss:  1.2623635355872338\n","Validation loss:  1.1498526528477668\n","Epoch time -----  1.8840999603271484  sec\n","Epoch:  10\n","Train loss:  1.2423904706733395\n","Validation loss:  1.1558539152145386\n","Epoch time -----  1.8416016101837158  sec\n","Epoch:  11\n","Train loss:  1.2474522367872374\n","Validation loss:  1.152087676525116\n","Epoch time -----  1.9624249935150146  sec\n","Epoch:  12\n","Train loss:  1.2398445082433296\n","Validation loss:  1.1512798577547074\n","Epoch time -----  1.9710652828216553  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [21:38<32:45, 327.54s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  88.0\n","Using CUDA\n","Test accuracy:  11.14\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.2711310386657715\n","Validation loss:  2.255973792076111\n","Epoch time -----  0.8915634155273438  sec\n","Epoch:  2\n","Train loss:  2.2423819601535797\n","Validation loss:  2.2353452682495116\n","Epoch time -----  0.8483002185821533  sec\n","Epoch:  3\n","Train loss:  2.232905000448227\n","Validation loss:  2.222914695739746\n","Epoch time -----  0.822211742401123  sec\n","Epoch:  4\n","Train loss:  2.224547654390335\n","Validation loss:  2.215835613012314\n","Epoch time -----  0.8072695732116699  sec\n","Epoch:  5\n","Train loss:  2.2233303487300873\n","Validation loss:  2.209930968284607\n","Epoch time -----  0.8833646774291992  sec\n","Epoch:  6\n","Train loss:  2.214503735303879\n","Validation loss:  2.2057712078094482\n","Epoch time -----  0.6969504356384277  sec\n","Epoch:  7\n","Train loss:  2.210469126701355\n","Validation loss:  2.202915757894516\n","Epoch time -----  0.6996762752532959  sec\n","Epoch:  8\n","Train loss:  2.213886111974716\n","Validation loss:  2.2011525452136995\n","Epoch time -----  0.7469861507415771  sec\n","Epoch:  9\n","Train loss:  2.2001605927944183\n","Validation loss:  2.1988720655441285\n","Epoch time -----  0.7918546199798584  sec\n","Epoch:  10\n","Train loss:  2.2063351571559906\n","Validation loss:  2.197748827934265\n","Epoch time -----  0.8964626789093018  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  694  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1058\n","Training samples:  1058\n","Training\n","Epoch:  1\n","Train loss:  2.2077732226427864\n","Validation loss:  2.201526916027069\n","Epoch time -----  1.1571340560913086  sec\n","Epoch:  2\n","Train loss:  2.184342216042911\n","Validation loss:  2.1929275035858153\n","Epoch time -----  0.8869667053222656  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  2.1697989772347843\n","Validation loss:  2.183272784948349\n","Epoch time -----  0.8091332912445068  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  2.1520650947795197\n","Validation loss:  2.1823901414871214\n","Epoch time -----  0.8831868171691895  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  2.14823018803316\n","Validation loss:  2.1691821992397307\n","Epoch time -----  0.988100528717041  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  2.1420150925131405\n","Validation loss:  2.1642328977584837\n","Epoch time -----  0.8657190799713135  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  2.1313049232258514\n","Validation loss:  2.160461890697479\n","Epoch time -----  0.8264775276184082  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  2.1251656588386085\n","Validation loss:  2.156914359331131\n","Epoch time -----  1.038038730621338  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  2.113862963283763\n","Validation loss:  2.1524184346199036\n","Epoch time -----  1.0069379806518555  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  2.101008148754344\n","Validation loss:  2.1486848175525664\n","Epoch time -----  0.9391741752624512  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  9.92\n","Round:  2\n","Using entropy sampling on  38942  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  702  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1620\n","Training samples:  1620\n","Training\n","Epoch:  1\n","Train loss:  2.1266994109520545\n","Validation loss:  2.1083920896053314\n","Epoch time -----  0.9834384918212891  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  2.074098935494056\n","Validation loss:  2.0622262954711914\n","Epoch time -----  1.049067735671997  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  2.023433323089893\n","Validation loss:  2.021294203400612\n","Epoch time -----  1.0702416896820068  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.9597540772878206\n","Validation loss:  1.9683296889066697\n","Epoch time -----  1.1550936698913574  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.908363232245812\n","Validation loss:  1.9405299335718156\n","Epoch time -----  1.1858797073364258  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.844024896621704\n","Validation loss:  1.899595484137535\n","Epoch time -----  1.0574231147766113  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.8053082411105816\n","Validation loss:  1.85561483502388\n","Epoch time -----  1.1525189876556396  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.7768311821497405\n","Validation loss:  1.8223535031080247\n","Epoch time -----  1.1376760005950928  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.7656131661855257\n","Validation loss:  1.811592960357666\n","Epoch time -----  1.1867716312408447  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.7298319248052745\n","Validation loss:  1.7978138595819473\n","Epoch time -----  1.1980993747711182  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  25.23\n","Round:  3\n","Using entropy sampling on  38380  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  708  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2187\n","Training samples:  2187\n","Training\n","Epoch:  1\n","Train loss:  1.822590514591762\n","Validation loss:  2.0805453956127167\n","Epoch time -----  1.14097261428833  sec\n","Epoch:  2\n","Train loss:  1.764182107789176\n","Validation loss:  2.056899183988571\n","Epoch time -----  1.3011457920074463  sec\n","Epoch:  3\n","Train loss:  1.6947517497198923\n","Validation loss:  1.796147781610489\n","Epoch time -----  1.244321346282959  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.6326654876981463\n","Validation loss:  1.671834483742714\n","Epoch time -----  1.2802009582519531  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5841515404837472\n","Validation loss:  1.7102332264184952\n","Epoch time -----  1.3298988342285156  sec\n","Epoch:  6\n","Train loss:  1.571703474862235\n","Validation loss:  1.7995695650577546\n","Epoch time -----  1.2837374210357666  sec\n","Epoch:  7\n","Train loss:  1.5437555381229946\n","Validation loss:  1.6337649345397949\n","Epoch time -----  1.2211410999298096  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5248222589492797\n","Validation loss:  1.6281544417142868\n","Epoch time -----  1.3176815509796143  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4900174413408551\n","Validation loss:  1.5907666295766831\n","Epoch time -----  1.2735846042633057  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4911983047212873\n","Validation loss:  1.5714179873466492\n","Epoch time -----  1.3042733669281006  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  44.11\n","Round:  4\n","Using entropy sampling on  37813  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  717  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2761\n","Training samples:  2761\n","Training\n","Epoch:  1\n","Train loss:  1.653749335895885\n","Validation loss:  1.856942680478096\n","Epoch time -----  1.2122046947479248  sec\n","Epoch:  2\n","Train loss:  1.5997779884121635\n","Validation loss:  1.708156594634056\n","Epoch time -----  1.1735384464263916  sec\n","Epoch:  3\n","Train loss:  1.5878804271871394\n","Validation loss:  1.8665140688419342\n","Epoch time -----  1.389251470565796  sec\n","Epoch:  4\n","Train loss:  1.5487000969323246\n","Validation loss:  1.5352201551198958\n","Epoch time -----  1.5152111053466797  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5003860674121163\n","Validation loss:  1.5294272035360337\n","Epoch time -----  1.3585984706878662  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4974374906583265\n","Validation loss:  1.5337148755788803\n","Epoch time -----  1.439789056777954  sec\n","Epoch:  7\n","Train loss:  1.4652408740737222\n","Validation loss:  1.5073642402887344\n","Epoch time -----  1.39231276512146  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.467108748175881\n","Validation loss:  1.5077325344085692\n","Epoch time -----  1.2174952030181885  sec\n","Epoch:  9\n","Train loss:  1.4508100883527235\n","Validation loss:  1.4556949049234391\n","Epoch time -----  1.1826093196868896  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.447367012500763\n","Validation loss:  1.4528496086597442\n","Epoch time -----  1.264493465423584  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  60.98\n","Round:  5\n","Using entropy sampling on  37239  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  725  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3341\n","Training samples:  3341\n","Training\n","Epoch:  1\n","Train loss:  1.55162291706733\n","Validation loss:  1.7058459520339966\n","Epoch time -----  1.3126881122589111  sec\n","Epoch:  2\n","Train loss:  1.5428500467876218\n","Validation loss:  1.5614493489265442\n","Epoch time -----  1.4023640155792236  sec\n","Epoch:  3\n","Train loss:  1.51320304060882\n","Validation loss:  1.5240330308675767\n","Epoch time -----  1.4622759819030762  sec\n","Epoch:  4\n","Train loss:  1.4883638148037892\n","Validation loss:  1.4217246145009994\n","Epoch time -----  1.4872136116027832  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4743736734930075\n","Validation loss:  1.5041092097759248\n","Epoch time -----  1.478135585784912  sec\n","Epoch:  6\n","Train loss:  1.465929852341706\n","Validation loss:  1.3915206730365752\n","Epoch time -----  1.519399881362915  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4474265350485749\n","Validation loss:  1.3910664409399032\n","Epoch time -----  1.395991325378418  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4322380839653734\n","Validation loss:  1.3679228365421294\n","Epoch time -----  1.525580644607544  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4188420862521764\n","Validation loss:  1.3635641008615493\n","Epoch time -----  1.6240856647491455  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3971704154644373\n","Validation loss:  1.340581902861595\n","Epoch time -----  1.301365852355957  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4011691966146793\n","Validation loss:  1.347499179840088\n","Epoch time -----  1.2419853210449219  sec\n","Testing\n","Test accuracy:  62.6\n","Round:  6\n","Using entropy sampling on  36659  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  733  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3928\n","Training samples:  3928\n","Training\n","Epoch:  1\n","Train loss:  1.5316559691582956\n","Validation loss:  1.3639411926269531\n","Epoch time -----  1.427069902420044  sec\n","Epoch:  2\n","Train loss:  1.495285322589259\n","Validation loss:  1.4402587860822678\n","Epoch time -----  1.6869001388549805  sec\n","Epoch:  3\n","Train loss:  1.4743922372018137\n","Validation loss:  1.3772862181067467\n","Epoch time -----  1.4949736595153809  sec\n","Epoch:  4\n","Train loss:  1.4521705892778212\n","Validation loss:  1.311006435751915\n","Epoch time -----  1.7022161483764648  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4409180956502115\n","Validation loss:  1.31759222894907\n","Epoch time -----  1.4645466804504395  sec\n","Epoch:  6\n","Train loss:  1.4197658281172476\n","Validation loss:  1.298586258292198\n","Epoch time -----  1.4308712482452393  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4068317355648163\n","Validation loss:  1.2989005401730538\n","Epoch time -----  1.5493762493133545  sec\n","Epoch:  8\n","Train loss:  1.4133522299028212\n","Validation loss:  1.2796210587024688\n","Epoch time -----  1.6327221393585205  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3808520830446673\n","Validation loss:  1.2775943145155906\n","Epoch time -----  1.4901480674743652  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.377411413577295\n","Validation loss:  1.271307635307312\n","Epoch time -----  1.7458133697509766  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3785395487662284\n","Validation loss:  1.2665523648262025\n","Epoch time -----  1.6460330486297607  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  74.2\n","Round:  7\n","Using entropy sampling on  36072  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  737  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4520\n","Training samples:  4520\n","Training\n","Epoch:  1\n","Train loss:  1.4797945156903334\n","Validation loss:  1.286868080496788\n","Epoch time -----  1.514237880706787  sec\n","Epoch:  2\n","Train loss:  1.4652856940954504\n","Validation loss:  1.2625154703855515\n","Epoch time -----  1.771028757095337  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.4365417453604685\n","Validation loss:  1.264045488834381\n","Epoch time -----  1.6378846168518066  sec\n","Epoch:  4\n","Train loss:  1.4065276115712986\n","Validation loss:  1.2348945036530494\n","Epoch time -----  1.7605490684509277  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.388180992972683\n","Validation loss:  1.2262828648090363\n","Epoch time -----  1.6067631244659424  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3805028754220883\n","Validation loss:  1.223048809170723\n","Epoch time -----  1.8607993125915527  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3645049585423\n","Validation loss:  1.222187201678753\n","Epoch time -----  1.6937828063964844  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.363589241471089\n","Validation loss:  1.2273343339562417\n","Epoch time -----  1.590165615081787  sec\n","Epoch:  9\n","Train loss:  1.3499005529242503\n","Validation loss:  1.2132869243621827\n","Epoch time -----  1.5434699058532715  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.334937701762562\n","Validation loss:  1.211739231646061\n","Epoch time -----  1.9033949375152588  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3329581139792859\n","Validation loss:  1.2038699880242347\n","Epoch time -----  1.6339046955108643  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  83.95\n","Round:  8\n","Using entropy sampling on  35480  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  744  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5116\n","Training samples:  5116\n","Training\n","Epoch:  1\n","Train loss:  1.419772633910179\n","Validation loss:  1.2588152050971986\n","Epoch time -----  1.4271628856658936  sec\n","Epoch:  2\n","Train loss:  1.4084446907043457\n","Validation loss:  1.2228870242834091\n","Epoch time -----  1.392077922821045  sec\n","Epoch:  3\n","Train loss:  1.393530012667179\n","Validation loss:  1.1919861346483231\n","Epoch time -----  1.5076372623443604  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3692439019680023\n","Validation loss:  1.1910084903240203\n","Epoch time -----  1.5382273197174072  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3513229668140412\n","Validation loss:  1.1882561415433883\n","Epoch time -----  1.4920499324798584  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.338176640868187\n","Validation loss:  1.1810354799032212\n","Epoch time -----  1.791391134262085  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3347280219197273\n","Validation loss:  1.1776426985859871\n","Epoch time -----  1.9820942878723145  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3075403198599815\n","Validation loss:  1.1729468360543251\n","Epoch time -----  1.46376633644104  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3147245943546295\n","Validation loss:  1.176729354262352\n","Epoch time -----  1.6326863765716553  sec\n","Epoch:  10\n","Train loss:  1.3017281517386436\n","Validation loss:  1.1704029008746146\n","Epoch time -----  1.7370519638061523  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2987529292702675\n","Validation loss:  1.170210288465023\n","Epoch time -----  1.6778333187103271  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  85.87\n","Round:  9\n","Using entropy sampling on  34884  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  752  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5718\n","Training samples:  5718\n","Training\n","Epoch:  1\n","Train loss:  1.3964199635717605\n","Validation loss:  1.1993401125073433\n","Epoch time -----  2.107560396194458  sec\n","Epoch:  2\n","Train loss:  1.373023353682624\n","Validation loss:  1.1696104645729064\n","Epoch time -----  2.4182097911834717  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3536364992459615\n","Validation loss:  1.226411259174347\n","Epoch time -----  1.7698915004730225  sec\n","Epoch:  4\n","Train loss:  1.3325444890393152\n","Validation loss:  1.186056835949421\n","Epoch time -----  1.726611852645874  sec\n","Epoch:  5\n","Train loss:  1.3213598661952548\n","Validation loss:  1.1727542743086814\n","Epoch time -----  1.575899362564087  sec\n","Epoch:  6\n","Train loss:  1.3034056809213426\n","Validation loss:  1.1792870625853538\n","Epoch time -----  1.6890449523925781  sec\n","Epoch:  7\n","Train loss:  1.3100322604179382\n","Validation loss:  1.1649270236492157\n","Epoch time -----  1.7753400802612305  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2948350734180873\n","Validation loss:  1.1696291998028756\n","Epoch time -----  2.2587363719940186  sec\n","Epoch:  9\n","Train loss:  1.2773710383309258\n","Validation loss:  1.1628237932920455\n","Epoch time -----  2.117680788040161  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2722670012050206\n","Validation loss:  1.1468505814671517\n","Epoch time -----  2.194307804107666  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2768497890896267\n","Validation loss:  1.1609079495072365\n","Epoch time -----  2.176004648208618  sec\n","Testing\n","Test accuracy:  87.7\n","Round:  10\n","Using entropy sampling on  34282  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  760  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6326\n","Training samples:  6326\n","Training\n","Epoch:  1\n","Train loss:  1.3688333106763435\n","Validation loss:  1.1532719314098359\n","Epoch time -----  2.0856895446777344  sec\n","Epoch:  2\n","Train loss:  1.352314009810939\n","Validation loss:  1.175683782994747\n","Epoch time -----  1.7003605365753174  sec\n","Epoch:  3\n","Train loss:  1.3149203351049712\n","Validation loss:  1.1608461424708367\n","Epoch time -----  1.8582332134246826  sec\n","Epoch:  4\n","Train loss:  1.3110880899910975\n","Validation loss:  1.15247283577919\n","Epoch time -----  2.23136043548584  sec\n","Epoch:  5\n","Train loss:  1.3040390243433944\n","Validation loss:  1.1485051780939102\n","Epoch time -----  2.0470850467681885  sec\n","Epoch:  6\n","Train loss:  1.2870658419348977\n","Validation loss:  1.1504762664437294\n","Epoch time -----  1.811633825302124  sec\n","Epoch:  7\n","Train loss:  1.2700491854638765\n","Validation loss:  1.1394181683659554\n","Epoch time -----  1.7682111263275146  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2656854210477886\n","Validation loss:  1.1413253784179687\n","Epoch time -----  2.023360252380371  sec\n","Epoch:  9\n","Train loss:  1.2476957705285814\n","Validation loss:  1.1352843731641769\n","Epoch time -----  2.2802813053131104  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2417615790559788\n","Validation loss:  1.136742113530636\n","Epoch time -----  2.4940245151519775  sec\n","Epoch:  11\n","Train loss:  1.2385578504716508\n","Validation loss:  1.1407844990491867\n","Epoch time -----  2.241283416748047  sec\n","Epoch:  12\n","Train loss:  1.236365962510157\n","Validation loss:  1.1372208058834077\n","Epoch time -----  2.288285255432129  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [26:42<26:36, 319.26s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  89.0\n","Using CUDA\n","Test accuracy:  9.42\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.26721528172493\n","Validation loss:  2.2453200578689576\n","Epoch time -----  0.9660978317260742  sec\n","Epoch:  2\n","Train loss:  2.223652571439743\n","Validation loss:  2.2230160176753997\n","Epoch time -----  0.8983578681945801  sec\n","Epoch:  3\n","Train loss:  2.2092669010162354\n","Validation loss:  2.2158860683441164\n","Epoch time -----  0.925123929977417  sec\n","Epoch:  4\n","Train loss:  2.199504166841507\n","Validation loss:  2.213506829738617\n","Epoch time -----  0.957322359085083  sec\n","Epoch:  5\n","Train loss:  2.1888276040554047\n","Validation loss:  2.210009568929672\n","Epoch time -----  0.9164774417877197  sec\n","Epoch:  6\n","Train loss:  2.191258192062378\n","Validation loss:  2.2072061777114866\n","Epoch time -----  0.8522415161132812  sec\n","Epoch:  7\n","Train loss:  2.1979228854179382\n","Validation loss:  2.204607993364334\n","Epoch time -----  0.732414722442627  sec\n","Epoch:  8\n","Train loss:  2.184093177318573\n","Validation loss:  2.2034334242343903\n","Epoch time -----  0.8243832588195801  sec\n","Epoch:  9\n","Train loss:  2.186490088701248\n","Validation loss:  2.2024911999702455\n","Epoch time -----  0.8228960037231445  sec\n","Epoch:  10\n","Train loss:  2.173529088497162\n","Validation loss:  2.2009187996387483\n","Epoch time -----  0.821098804473877  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  693  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1055\n","Training samples:  1055\n","Training\n","Epoch:  1\n","Train loss:  2.1794323640711166\n","Validation loss:  2.223822224140167\n","Epoch time -----  0.9924306869506836  sec\n","Epoch:  2\n","Train loss:  2.14877127198612\n","Validation loss:  2.2272700488567354\n","Epoch time -----  0.8798015117645264  sec\n","Epoch:  3\n","Train loss:  2.138345956802368\n","Validation loss:  2.236035829782486\n","Epoch time -----  0.9366099834442139  sec\n","Epoch:  4\n","Train loss:  2.119798954795389\n","Validation loss:  2.218827110528946\n","Epoch time -----  1.0102260112762451  sec\n","Epoch:  5\n","Train loss:  2.1120490116231583\n","Validation loss:  2.2181926667690277\n","Epoch time -----  1.0669031143188477  sec\n","Epoch:  6\n","Train loss:  2.0977641344070435\n","Validation loss:  2.211726027727127\n","Epoch time -----  0.993039608001709  sec\n","Epoch:  7\n","Train loss:  2.0932309767779183\n","Validation loss:  2.2020365834236144\n","Epoch time -----  0.9791727066040039  sec\n","Epoch:  8\n","Train loss:  2.086606025695801\n","Validation loss:  2.1906007409095762\n","Epoch time -----  1.030379295349121  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  2.0866528539096607\n","Validation loss:  2.18976543545723\n","Epoch time -----  0.8469278812408447  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  2.07262165406171\n","Validation loss:  2.1830415427684784\n","Epoch time -----  0.8381831645965576  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  18.36\n","Round:  2\n","Using entropy sampling on  38945  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  701  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1616\n","Training samples:  1616\n","Training\n","Epoch:  1\n","Train loss:  2.085433359329517\n","Validation loss:  2.152206265926361\n","Epoch time -----  1.5779094696044922  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  2.0074824140622067\n","Validation loss:  2.0758824408054353\n","Epoch time -----  1.2192537784576416  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.9061589470276465\n","Validation loss:  2.0054817289113998\n","Epoch time -----  1.1492831707000732  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.8278332260938792\n","Validation loss:  2.090358793735504\n","Epoch time -----  1.0501961708068848  sec\n","Epoch:  5\n","Train loss:  1.7894027416522686\n","Validation loss:  1.9341170966625214\n","Epoch time -----  1.223398208618164  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.7633897616313055\n","Validation loss:  1.9418184578418731\n","Epoch time -----  1.1234121322631836  sec\n","Epoch:  7\n","Train loss:  1.723159487430866\n","Validation loss:  1.9261794686317444\n","Epoch time -----  1.1353826522827148  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.7074538010817308\n","Validation loss:  1.848685085773468\n","Epoch time -----  1.1821269989013672  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.6801462540259728\n","Validation loss:  1.8225265204906465\n","Epoch time -----  1.2322466373443604  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.6664533569262578\n","Validation loss:  1.8325586438179016\n","Epoch time -----  1.0784437656402588  sec\n","Testing\n","Test accuracy:  21.23\n","Round:  3\n","Using entropy sampling on  38384  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  710  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2185\n","Training samples:  2185\n","Training\n","Epoch:  1\n","Train loss:  1.8044097014835903\n","Validation loss:  1.9347203254699707\n","Epoch time -----  1.1189172267913818  sec\n","Epoch:  2\n","Train loss:  1.7420873982565743\n","Validation loss:  2.3865273714065554\n","Epoch time -----  1.130885124206543  sec\n","Epoch:  3\n","Train loss:  1.7387841258730208\n","Validation loss:  2.166958951950073\n","Epoch time -----  1.1121859550476074  sec\n","Epoch:  4\n","Train loss:  1.69714766229902\n","Validation loss:  1.7648721843957902\n","Epoch time -----  1.2495198249816895  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.6416191577911377\n","Validation loss:  1.8298024356365203\n","Epoch time -----  1.191929817199707  sec\n","Epoch:  6\n","Train loss:  1.6170276709965297\n","Validation loss:  1.6735492944717407\n","Epoch time -----  1.0984032154083252  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.595309373310634\n","Validation loss:  1.7231851905584334\n","Epoch time -----  1.1982097625732422  sec\n","Epoch:  8\n","Train loss:  1.5790548358644758\n","Validation loss:  1.7039126187562943\n","Epoch time -----  1.1055657863616943  sec\n","Epoch:  9\n","Train loss:  1.577504505429949\n","Validation loss:  1.6119430184364318\n","Epoch time -----  1.0035574436187744  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.5680791446140834\n","Validation loss:  1.6125900089740752\n","Epoch time -----  1.0654678344726562  sec\n","Testing\n","Test accuracy:  32.34\n","Round:  4\n","Using entropy sampling on  37815  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  717  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2759\n","Training samples:  2759\n","Training\n","Epoch:  1\n","Train loss:  1.7025637193159624\n","Validation loss:  2.084250783920288\n","Epoch time -----  1.3101398944854736  sec\n","Epoch:  2\n","Train loss:  1.642752926458012\n","Validation loss:  1.7160850137472152\n","Epoch time -----  1.2194633483886719  sec\n","Epoch:  3\n","Train loss:  1.5858618942174045\n","Validation loss:  1.6094941675662995\n","Epoch time -----  1.496821641921997  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.5727048299529336\n","Validation loss:  1.629604732990265\n","Epoch time -----  1.5901081562042236  sec\n","Epoch:  5\n","Train loss:  1.527502723715522\n","Validation loss:  1.5990774124860763\n","Epoch time -----  1.3169362545013428  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.5300633636387913\n","Validation loss:  1.575921246409416\n","Epoch time -----  1.3703303337097168  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4990861876444384\n","Validation loss:  1.5244063407182693\n","Epoch time -----  1.3648252487182617  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4983988864855333\n","Validation loss:  1.4976056903600692\n","Epoch time -----  1.2702722549438477  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4986428780989214\n","Validation loss:  1.5187736809253694\n","Epoch time -----  1.183861494064331  sec\n","Epoch:  10\n","Train loss:  1.468908586285331\n","Validation loss:  1.4766945391893387\n","Epoch time -----  1.059685468673706  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  43.3\n","Round:  5\n","Using entropy sampling on  37241  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  723  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3338\n","Training samples:  3338\n","Training\n","Epoch:  1\n","Train loss:  1.5899191914864306\n","Validation loss:  1.5682513684034347\n","Epoch time -----  1.5798096656799316  sec\n","Epoch:  2\n","Train loss:  1.5689756690331225\n","Validation loss:  1.576610666513443\n","Epoch time -----  1.5600008964538574  sec\n","Epoch:  3\n","Train loss:  1.5426025975425288\n","Validation loss:  1.4869288474321365\n","Epoch time -----  1.5661160945892334  sec\n","Epoch:  4\n","Train loss:  1.5073164723954111\n","Validation loss:  1.4415730506181716\n","Epoch time -----  1.5399281978607178  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4911684135221086\n","Validation loss:  1.473048985004425\n","Epoch time -----  1.40085768699646  sec\n","Epoch:  6\n","Train loss:  1.4789807908939865\n","Validation loss:  1.422722041606903\n","Epoch time -----  1.4862017631530762  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4859297095604662\n","Validation loss:  1.4118840098381042\n","Epoch time -----  1.3359410762786865  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4621026628422287\n","Validation loss:  1.4089231967926026\n","Epoch time -----  1.571187973022461  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.468484174530461\n","Validation loss:  1.4029451310634613\n","Epoch time -----  1.3756721019744873  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4463691194102448\n","Validation loss:  1.387384334206581\n","Epoch time -----  1.4041757583618164  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4335989524733346\n","Validation loss:  1.3850343614816665\n","Epoch time -----  1.4440948963165283  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  52.69\n","Round:  6\n","Using entropy sampling on  36662  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  730  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3922\n","Training samples:  3922\n","Training\n","Epoch:  1\n","Train loss:  1.5470121560558197\n","Validation loss:  1.4052525341510773\n","Epoch time -----  1.626749038696289  sec\n","Epoch:  2\n","Train loss:  1.5191152134249288\n","Validation loss:  1.454257532954216\n","Epoch time -----  1.5921735763549805  sec\n","Epoch:  3\n","Train loss:  1.5026498436927795\n","Validation loss:  1.3609731644392014\n","Epoch time -----  1.5734963417053223  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4737884229229343\n","Validation loss:  1.3431262224912643\n","Epoch time -----  1.6147377490997314  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4484862742885467\n","Validation loss:  1.328929340839386\n","Epoch time -----  1.5205483436584473  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4461524025086434\n","Validation loss:  1.3313494622707367\n","Epoch time -----  1.667001485824585  sec\n","Epoch:  7\n","Train loss:  1.4160180957086625\n","Validation loss:  1.3516201078891754\n","Epoch time -----  1.5805554389953613  sec\n","Epoch:  8\n","Train loss:  1.4122372404221566\n","Validation loss:  1.3188409626483917\n","Epoch time -----  1.4287447929382324  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4021340416323753\n","Validation loss:  1.3138625502586365\n","Epoch time -----  1.7065355777740479  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4041890021293395\n","Validation loss:  1.30610471367836\n","Epoch time -----  1.5201027393341064  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3825193970434126\n","Validation loss:  1.3119628012180329\n","Epoch time -----  1.8900177478790283  sec\n","Testing\n","Test accuracy:  59.6\n","Round:  7\n","Using entropy sampling on  36078  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  736  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4512\n","Training samples:  4512\n","Training\n","Epoch:  1\n","Train loss:  1.5017727697399301\n","Validation loss:  1.3682356834411622\n","Epoch time -----  1.6306695938110352  sec\n","Epoch:  2\n","Train loss:  1.4656702683005534\n","Validation loss:  1.331882894039154\n","Epoch time -----  1.7356979846954346  sec\n","Epoch:  3\n","Train loss:  1.4371935683236996\n","Validation loss:  1.2945612162351607\n","Epoch time -----  1.8574776649475098  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.418080643868782\n","Validation loss:  1.2565658241510391\n","Epoch time -----  1.8395209312438965  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4116697949422916\n","Validation loss:  1.2569800570607186\n","Epoch time -----  1.6628031730651855  sec\n","Epoch:  6\n","Train loss:  1.3856683583326743\n","Validation loss:  1.2736312329769135\n","Epoch time -----  1.7471678256988525  sec\n","Epoch:  7\n","Train loss:  1.37135889160801\n","Validation loss:  1.2383272111415864\n","Epoch time -----  1.612412452697754  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3708625125213407\n","Validation loss:  1.230171637237072\n","Epoch time -----  1.3245360851287842  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3501060563074032\n","Validation loss:  1.2523240193724632\n","Epoch time -----  1.355132818222046  sec\n","Epoch:  10\n","Train loss:  1.338569293559437\n","Validation loss:  1.249247707426548\n","Epoch time -----  1.3849058151245117  sec\n","Epoch:  11\n","Train loss:  1.3389375914990063\n","Validation loss:  1.2298522859811782\n","Epoch time -----  1.2597949504852295  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  75.14\n","Round:  8\n","Using entropy sampling on  35488  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5109\n","Training samples:  5109\n","Training\n","Epoch:  1\n","Train loss:  1.4383119955658912\n","Validation loss:  1.2823330760002136\n","Epoch time -----  1.9373302459716797  sec\n","Epoch:  2\n","Train loss:  1.4122584506869316\n","Validation loss:  1.2446767151355744\n","Epoch time -----  2.251274347305298  sec\n","Epoch:  3\n","Train loss:  1.4011767998337745\n","Validation loss:  1.1962770476937294\n","Epoch time -----  1.9578020572662354  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3709155708551406\n","Validation loss:  1.1961973965168\n","Epoch time -----  1.8370959758758545  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3653263807296754\n","Validation loss:  1.204597581923008\n","Epoch time -----  1.840033769607544  sec\n","Epoch:  6\n","Train loss:  1.3375627934932708\n","Validation loss:  1.1837788864970207\n","Epoch time -----  1.734795331954956  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3289816483855248\n","Validation loss:  1.1918625235557556\n","Epoch time -----  1.9541268348693848  sec\n","Epoch:  8\n","Train loss:  1.306909514963627\n","Validation loss:  1.179765510559082\n","Epoch time -----  1.7859485149383545  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3034401714801789\n","Validation loss:  1.1908810764551163\n","Epoch time -----  2.1288695335388184  sec\n","Epoch:  10\n","Train loss:  1.3031530261039734\n","Validation loss:  1.1785975635051726\n","Epoch time -----  1.6763861179351807  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2928857937455178\n","Validation loss:  1.1763763427734375\n","Epoch time -----  1.4803118705749512  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  81.72\n","Round:  9\n","Using entropy sampling on  34891  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5710\n","Training samples:  5710\n","Training\n","Epoch:  1\n","Train loss:  1.4175766746203105\n","Validation loss:  1.2365089327096939\n","Epoch time -----  1.881176233291626  sec\n","Epoch:  2\n","Train loss:  1.3965337263213264\n","Validation loss:  1.1971581339836121\n","Epoch time -----  1.9944555759429932  sec\n","Epoch:  3\n","Train loss:  1.3686304132143656\n","Validation loss:  1.3803236037492752\n","Epoch time -----  2.2392289638519287  sec\n","Epoch:  4\n","Train loss:  1.3439311888482837\n","Validation loss:  1.1634467840194702\n","Epoch time -----  1.9310381412506104  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.340026397175259\n","Validation loss:  1.2282360538840293\n","Epoch time -----  1.9763453006744385  sec\n","Epoch:  6\n","Train loss:  1.3126644955741034\n","Validation loss:  1.1983774930238724\n","Epoch time -----  2.0116312503814697  sec\n","Epoch:  7\n","Train loss:  1.3011693292193942\n","Validation loss:  1.1526243835687637\n","Epoch time -----  1.6962997913360596  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2930955317285326\n","Validation loss:  1.2041034564375876\n","Epoch time -----  1.923671007156372  sec\n","Epoch:  9\n","Train loss:  1.2863747000694274\n","Validation loss:  1.1727560132741928\n","Epoch time -----  2.9793362617492676  sec\n","Epoch:  10\n","Train loss:  1.2729955037434897\n","Validation loss:  1.153136958181858\n","Epoch time -----  2.0101702213287354  sec\n","Epoch:  11\n","Train loss:  1.2644998192787171\n","Validation loss:  1.1600219875574111\n","Epoch time -----  1.7342822551727295  sec\n","Testing\n","Test accuracy:  84.54\n","Round:  10\n","Using entropy sampling on  34290  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  759  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6318\n","Training samples:  6318\n","Training\n","Epoch:  1\n","Train loss:  1.3798384883187034\n","Validation loss:  1.1555062055587768\n","Epoch time -----  2.4832282066345215  sec\n","Epoch:  2\n","Train loss:  1.3568049500686954\n","Validation loss:  1.1515945106744767\n","Epoch time -----  1.9367847442626953  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3341075278291799\n","Validation loss:  1.2107730746269225\n","Epoch time -----  1.8917889595031738  sec\n","Epoch:  4\n","Train loss:  1.3168532812234126\n","Validation loss:  1.1385405465960503\n","Epoch time -----  1.8606984615325928  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.2986596136382131\n","Validation loss:  1.1444748014211654\n","Epoch time -----  2.384089708328247  sec\n","Epoch:  6\n","Train loss:  1.289768033557468\n","Validation loss:  1.1672637075185777\n","Epoch time -----  2.1343867778778076  sec\n","Epoch:  7\n","Train loss:  1.279308152319205\n","Validation loss:  1.1437358021736146\n","Epoch time -----  1.9538421630859375  sec\n","Epoch:  8\n","Train loss:  1.269928236200352\n","Validation loss:  1.1299717605113984\n","Epoch time -----  1.6999671459197998  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2544107563567883\n","Validation loss:  1.1397522523999215\n","Epoch time -----  2.3027610778808594  sec\n","Epoch:  10\n","Train loss:  1.2488914403048428\n","Validation loss:  1.1329090550541878\n","Epoch time -----  2.053680896759033  sec\n","Epoch:  11\n","Train loss:  1.2322097330382376\n","Validation loss:  1.139556822180748\n","Epoch time -----  2.2848994731903076  sec\n","Epoch:  12\n","Train loss:  1.2351062165366278\n","Validation loss:  1.1406596556305886\n","Epoch time -----  2.3125803470611572  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [31:49<21:00, 315.01s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  85.78\n","Using CUDA\n","Test accuracy:  9.0\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.2942841053009033\n","Validation loss:  2.263720601797104\n","Epoch time -----  0.8548851013183594  sec\n","Epoch:  2\n","Train loss:  2.2306919991970062\n","Validation loss:  2.2257838249206543\n","Epoch time -----  0.809584379196167  sec\n","Epoch:  3\n","Train loss:  2.2112973630428314\n","Validation loss:  2.2105603396892546\n","Epoch time -----  0.8382132053375244  sec\n","Epoch:  4\n","Train loss:  2.1967291831970215\n","Validation loss:  2.203823137283325\n","Epoch time -----  0.75583815574646  sec\n","Epoch:  5\n","Train loss:  2.1875267922878265\n","Validation loss:  2.199952870607376\n","Epoch time -----  0.781334400177002  sec\n","Epoch:  6\n","Train loss:  2.1844177842140198\n","Validation loss:  2.1978510499000548\n","Epoch time -----  0.8848068714141846  sec\n","Epoch:  7\n","Train loss:  2.16903355717659\n","Validation loss:  2.1967675566673277\n","Epoch time -----  0.8632180690765381  sec\n","Epoch:  8\n","Train loss:  2.1839407980442047\n","Validation loss:  2.195231294631958\n","Epoch time -----  0.8317768573760986  sec\n","Epoch:  9\n","Train loss:  2.182229369878769\n","Validation loss:  2.1938790500164034\n","Epoch time -----  0.8259057998657227  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  2.172843724489212\n","Validation loss:  2.192851883172989\n","Epoch time -----  1.2127900123596191  sec\n","validation loss minimum, saving model\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  694  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1056\n","Training samples:  1056\n","Training\n","Epoch:  1\n","Train loss:  2.1255366381476906\n","Validation loss:  2.221595197916031\n","Epoch time -----  1.0669491291046143  sec\n","Epoch:  2\n","Train loss:  2.08431778234594\n","Validation loss:  2.2427074313163757\n","Epoch time -----  0.9774987697601318  sec\n","Epoch:  3\n","Train loss:  2.079080806058996\n","Validation loss:  2.225195699930191\n","Epoch time -----  1.1278150081634521  sec\n","Epoch:  4\n","Train loss:  2.045064119731679\n","Validation loss:  2.2276833057403564\n","Epoch time -----  1.0439832210540771  sec\n","Epoch:  5\n","Train loss:  2.049705280977137\n","Validation loss:  2.2141226053237917\n","Epoch time -----  1.0618107318878174  sec\n","Epoch:  6\n","Train loss:  2.0547886105144726\n","Validation loss:  2.2011552810668946\n","Epoch time -----  0.9339032173156738  sec\n","Epoch:  7\n","Train loss:  2.0310593633090748\n","Validation loss:  2.2077657282352448\n","Epoch time -----  0.8851385116577148  sec\n","Epoch:  8\n","Train loss:  2.0210629210752598\n","Validation loss:  2.2092008888721466\n","Epoch time -----  0.8433732986450195  sec\n","Epoch:  9\n","Train loss:  2.0228290417615105\n","Validation loss:  2.195147007703781\n","Epoch time -----  1.0004301071166992  sec\n","Epoch:  10\n","Train loss:  2.0258895018521477\n","Validation loss:  2.1879967033863066\n","Epoch time -----  1.0854911804199219  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  14.95\n","Round:  2\n","Using entropy sampling on  38944  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  701  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1618\n","Training samples:  1618\n","Training\n","Epoch:  1\n","Train loss:  1.925401861851032\n","Validation loss:  2.1463242411613463\n","Epoch time -----  0.9148557186126709  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.8196746936211219\n","Validation loss:  2.096596971154213\n","Epoch time -----  1.084963083267212  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.7373638153076172\n","Validation loss:  2.0701366007328033\n","Epoch time -----  1.8510973453521729  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.6804470924230723\n","Validation loss:  1.979943984746933\n","Epoch time -----  1.8266749382019043  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.642394524354201\n","Validation loss:  1.9593322813510894\n","Epoch time -----  1.0835895538330078  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.6186645947969878\n","Validation loss:  1.96330386698246\n","Epoch time -----  1.0964386463165283  sec\n","Epoch:  7\n","Train loss:  1.5805521790797894\n","Validation loss:  1.9252822935581206\n","Epoch time -----  1.105875015258789  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5981009235748878\n","Validation loss:  1.9163019120693208\n","Epoch time -----  1.6329772472381592  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.5803293815025916\n","Validation loss:  1.9016148269176483\n","Epoch time -----  1.0348639488220215  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.560239397562467\n","Validation loss:  1.8890201807022096\n","Epoch time -----  1.0896580219268799  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  23.05\n","Round:  3\n","Using entropy sampling on  38382  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  709  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2186\n","Training samples:  2186\n","Training\n","Epoch:  1\n","Train loss:  1.7066643851143972\n","Validation loss:  1.9525581926107407\n","Epoch time -----  1.0451312065124512  sec\n","Epoch:  2\n","Train loss:  1.6519514969417026\n","Validation loss:  1.8158437013626099\n","Epoch time -----  1.5288043022155762  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.5899633066994803\n","Validation loss:  1.8669526517391204\n","Epoch time -----  1.023094892501831  sec\n","Epoch:  4\n","Train loss:  1.5495810781206403\n","Validation loss:  1.801001611351967\n","Epoch time -----  1.7731349468231201  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.507403598512922\n","Validation loss:  1.7242352545261384\n","Epoch time -----  1.1978263854980469  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4913730451038905\n","Validation loss:  1.692035698890686\n","Epoch time -----  1.5168497562408447  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4623312984194075\n","Validation loss:  1.6735692650079728\n","Epoch time -----  1.2855734825134277  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4493619986942836\n","Validation loss:  1.6766214817762375\n","Epoch time -----  1.2361361980438232  sec\n","Epoch:  9\n","Train loss:  1.4308391434805734\n","Validation loss:  1.6410432398319243\n","Epoch time -----  1.2369904518127441  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4227954489844186\n","Validation loss:  1.6226748645305633\n","Epoch time -----  1.2439353466033936  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  35.75\n","Round:  4\n","Using entropy sampling on  37814  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  717  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2760\n","Training samples:  2760\n","Training\n","Epoch:  1\n","Train loss:  1.591539434411309\n","Validation loss:  1.779586210846901\n","Epoch time -----  1.2898321151733398  sec\n","Epoch:  2\n","Train loss:  1.5391297123648904\n","Validation loss:  1.697787195444107\n","Epoch time -----  1.397233247756958  sec\n","Epoch:  3\n","Train loss:  1.5028793622146954\n","Validation loss:  1.6851897090673447\n","Epoch time -----  1.3495094776153564  sec\n","Epoch:  4\n","Train loss:  1.4704758362336592\n","Validation loss:  1.6846482098102569\n","Epoch time -----  1.265606164932251  sec\n","Epoch:  5\n","Train loss:  1.4392770257863132\n","Validation loss:  1.5493555158376693\n","Epoch time -----  1.3523375988006592  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.436155392365022\n","Validation loss:  1.562974500656128\n","Epoch time -----  1.2601490020751953  sec\n","Epoch:  7\n","Train loss:  1.4117112349380145\n","Validation loss:  1.619402241706848\n","Epoch time -----  1.28902268409729  sec\n","Epoch:  8\n","Train loss:  1.4032601714134216\n","Validation loss:  1.524243351817131\n","Epoch time -----  1.3929479122161865  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3669422268867493\n","Validation loss:  1.508052060008049\n","Epoch time -----  1.4195353984832764  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3724128062074834\n","Validation loss:  1.4919366598129273\n","Epoch time -----  1.2074849605560303  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  43.17\n","Round:  5\n","Using entropy sampling on  37240  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  726  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3341\n","Training samples:  3341\n","Training\n","Epoch:  1\n","Train loss:  1.4995392156097125\n","Validation loss:  1.7748683929443358\n","Epoch time -----  1.5120735168457031  sec\n","Epoch:  2\n","Train loss:  1.4693231323979936\n","Validation loss:  1.5319910287857055\n","Epoch time -----  1.4194612503051758  sec\n","Epoch:  3\n","Train loss:  1.444136673549436\n","Validation loss:  1.4646342813968658\n","Epoch time -----  1.4113662242889404  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4163382660667851\n","Validation loss:  1.4391188383102418\n","Epoch time -----  1.357184886932373  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3836953707461088\n","Validation loss:  1.454691192507744\n","Epoch time -----  1.5115220546722412  sec\n","Epoch:  6\n","Train loss:  1.3766851481401696\n","Validation loss:  1.4162425130605698\n","Epoch time -----  1.835719108581543  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3916166391012803\n","Validation loss:  1.4608164608478547\n","Epoch time -----  1.421424150466919  sec\n","Epoch:  8\n","Train loss:  1.3539192024266944\n","Validation loss:  1.4222383975982666\n","Epoch time -----  1.521268606185913  sec\n","Epoch:  9\n","Train loss:  1.3475209204655774\n","Validation loss:  1.4091638296842575\n","Epoch time -----  1.5331401824951172  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3548476448598898\n","Validation loss:  1.4086078107357025\n","Epoch time -----  1.7588114738464355  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3369676077140953\n","Validation loss:  1.4044632077217103\n","Epoch time -----  1.4361255168914795  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  46.96\n","Round:  6\n","Using entropy sampling on  36659  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  729  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3925\n","Training samples:  3925\n","Training\n","Epoch:  1\n","Train loss:  1.4562052911327732\n","Validation loss:  1.4559290319681168\n","Epoch time -----  1.3782804012298584  sec\n","Epoch:  2\n","Train loss:  1.4322045099350713\n","Validation loss:  1.4488378793001175\n","Epoch time -----  1.439168930053711  sec\n","Epoch:  3\n","Train loss:  1.4171647737103124\n","Validation loss:  1.3905398339033126\n","Epoch time -----  1.5164556503295898  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3872692373491102\n","Validation loss:  1.3815068274736404\n","Epoch time -----  1.3970954418182373  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3690857752676933\n","Validation loss:  1.4108688712120057\n","Epoch time -----  1.614044427871704  sec\n","Epoch:  6\n","Train loss:  1.367790772068885\n","Validation loss:  1.3642312645912171\n","Epoch time -----  1.781123399734497  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3523658302522474\n","Validation loss:  1.3517772406339645\n","Epoch time -----  1.4906365871429443  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3423868648467525\n","Validation loss:  1.3631519317626952\n","Epoch time -----  1.276684045791626  sec\n","Epoch:  9\n","Train loss:  1.3253547222383562\n","Validation loss:  1.3348726496100425\n","Epoch time -----  1.3705155849456787  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3215596598963584\n","Validation loss:  1.3407419949769974\n","Epoch time -----  1.3893122673034668  sec\n","Epoch:  11\n","Train loss:  1.3130571476874813\n","Validation loss:  1.3439093291759492\n","Epoch time -----  1.3504648208618164  sec\n","Testing\n","Test accuracy:  52.47\n","Round:  7\n","Using entropy sampling on  36075  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  738  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4518\n","Training samples:  4518\n","Training\n","Epoch:  1\n","Train loss:  1.422737138372072\n","Validation loss:  1.326818984746933\n","Epoch time -----  1.4790141582489014  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.407995902316671\n","Validation loss:  1.3446790874004364\n","Epoch time -----  1.6055693626403809  sec\n","Epoch:  3\n","Train loss:  1.3837323339892105\n","Validation loss:  1.3152395769953729\n","Epoch time -----  1.5547327995300293  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3654068305458822\n","Validation loss:  1.3088692873716354\n","Epoch time -----  1.5035874843597412  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3351432294912742\n","Validation loss:  1.2904532998800278\n","Epoch time -----  1.5330326557159424  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3384752626150427\n","Validation loss:  1.2856944099068641\n","Epoch time -----  1.3202085494995117  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.329657730921893\n","Validation loss:  1.2841231882572175\n","Epoch time -----  1.2825093269348145  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.314754929341061\n","Validation loss:  1.2900751307606697\n","Epoch time -----  1.3743281364440918  sec\n","Epoch:  9\n","Train loss:  1.3022912942187888\n","Validation loss:  1.269567461311817\n","Epoch time -----  1.1991677284240723  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3035120359608825\n","Validation loss:  1.2763226434588433\n","Epoch time -----  1.1762909889221191  sec\n","Epoch:  11\n","Train loss:  1.2922933806835766\n","Validation loss:  1.2726864352822305\n","Epoch time -----  1.5621955394744873  sec\n","Testing\n","Test accuracy:  70.76\n","Round:  8\n","Using entropy sampling on  35482  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5115\n","Training samples:  5115\n","Training\n","Epoch:  1\n","Train loss:  1.4101553484797478\n","Validation loss:  1.3027462273836137\n","Epoch time -----  1.729257345199585  sec\n","Epoch:  2\n","Train loss:  1.3824579074978829\n","Validation loss:  1.2497775435447693\n","Epoch time -----  1.935476541519165  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.369471800327301\n","Validation loss:  1.258352392911911\n","Epoch time -----  1.8127591609954834  sec\n","Epoch:  4\n","Train loss:  1.336758977174759\n","Validation loss:  1.2434647992253303\n","Epoch time -----  1.5853471755981445  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3123612567782401\n","Validation loss:  1.2298505842685699\n","Epoch time -----  1.6382660865783691  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3068243958055974\n","Validation loss:  1.2384662002325058\n","Epoch time -----  1.4192073345184326  sec\n","Epoch:  7\n","Train loss:  1.2995930179953574\n","Validation loss:  1.2214166820049286\n","Epoch time -----  1.8688011169433594  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2872352614998817\n","Validation loss:  1.2248128697276115\n","Epoch time -----  1.936305284500122  sec\n","Epoch:  9\n","Train loss:  1.2895848855376244\n","Validation loss:  1.22829822152853\n","Epoch time -----  1.7019603252410889  sec\n","Epoch:  10\n","Train loss:  1.2710557386279107\n","Validation loss:  1.223186455667019\n","Epoch time -----  1.704145908355713  sec\n","Epoch:  11\n","Train loss:  1.267518150806427\n","Validation loss:  1.2302872225642205\n","Epoch time -----  1.5825958251953125  sec\n","Testing\n","Test accuracy:  78.19\n","Round:  9\n","Using entropy sampling on  34885  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5716\n","Training samples:  5716\n","Training\n","Epoch:  1\n","Train loss:  1.3680890056822035\n","Validation loss:  1.3182004243135452\n","Epoch time -----  1.8264763355255127  sec\n","Epoch:  2\n","Train loss:  1.336022953192393\n","Validation loss:  1.2085723713040353\n","Epoch time -----  1.8026068210601807  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3171662025981479\n","Validation loss:  1.2052138134837151\n","Epoch time -----  2.2284369468688965  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3023185941908095\n","Validation loss:  1.201187400519848\n","Epoch time -----  2.193829298019409  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.287879275613361\n","Validation loss:  1.2144727796316146\n","Epoch time -----  2.084803581237793  sec\n","Epoch:  6\n","Train loss:  1.2688510305351681\n","Validation loss:  1.2146768808364867\n","Epoch time -----  2.27046275138855  sec\n","Epoch:  7\n","Train loss:  1.2571879519356621\n","Validation loss:  1.1892367884516717\n","Epoch time -----  2.3574256896972656  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2513660238848792\n","Validation loss:  1.2033701598644257\n","Epoch time -----  1.8038344383239746  sec\n","Epoch:  9\n","Train loss:  1.2453533245457544\n","Validation loss:  1.1960979297757148\n","Epoch time -----  1.8950307369232178  sec\n","Epoch:  10\n","Train loss:  1.2357196079360113\n","Validation loss:  1.1849886894226074\n","Epoch time -----  2.1621055603027344  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2358990384472741\n","Validation loss:  1.1996229946613313\n","Epoch time -----  2.1850991249084473  sec\n","Testing\n","Test accuracy:  83.38\n","Round:  10\n","Using entropy sampling on  34284  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  759  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6324\n","Training samples:  6324\n","Training\n","Epoch:  1\n","Train loss:  1.3357313317481918\n","Validation loss:  1.2011339038610458\n","Epoch time -----  2.2337234020233154  sec\n","Epoch:  2\n","Train loss:  1.3196446534359094\n","Validation loss:  1.1736629337072373\n","Epoch time -----  2.1384003162384033  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.2988034005116935\n","Validation loss:  1.1959890857338906\n","Epoch time -----  2.4442241191864014  sec\n","Epoch:  4\n","Train loss:  1.2862591153443461\n","Validation loss:  1.1727606683969498\n","Epoch time -----  2.000439167022705  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.2754640157776649\n","Validation loss:  1.1849354535341263\n","Epoch time -----  2.3310036659240723  sec\n","Epoch:  6\n","Train loss:  1.2639431441673126\n","Validation loss:  1.1929477155208588\n","Epoch time -----  2.292022228240967  sec\n","Epoch:  7\n","Train loss:  1.23389995941008\n","Validation loss:  1.1881512075662612\n","Epoch time -----  2.2543210983276367  sec\n","Epoch:  8\n","Train loss:  1.229611171014381\n","Validation loss:  1.1711465492844582\n","Epoch time -----  1.9192767143249512  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2194201193674645\n","Validation loss:  1.1695225805044174\n","Epoch time -----  2.313939332962036  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2193084040073434\n","Validation loss:  1.1637050926685333\n","Epoch time -----  2.290478229522705  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2060663633876376\n","Validation loss:  1.1647315159440041\n","Epoch time -----  2.4084293842315674  sec\n","Epoch:  12\n","Train loss:  1.2066348574378274\n","Validation loss:  1.1611466765403748\n","Epoch time -----  2.5915544033050537  sec\n","validation loss minimum, saving model\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [36:47<15:28, 309.47s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  86.1\n","Using CUDA\n","Test accuracy:  10.86\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.2939987778663635\n","Validation loss:  2.285733997821808\n","Epoch time -----  0.8977935314178467  sec\n","Epoch:  2\n","Train loss:  2.2811675667762756\n","Validation loss:  2.277180129289627\n","Epoch time -----  0.9384424686431885  sec\n","Epoch:  3\n","Train loss:  2.2669454216957092\n","Validation loss:  2.269185000658035\n","Epoch time -----  1.087153434753418  sec\n","Epoch:  4\n","Train loss:  2.26167568564415\n","Validation loss:  2.2624534547328947\n","Epoch time -----  0.8753767013549805  sec\n","Epoch:  5\n","Train loss:  2.254860997200012\n","Validation loss:  2.256621319055557\n","Epoch time -----  1.0288496017456055  sec\n","Epoch:  6\n","Train loss:  2.2465471625328064\n","Validation loss:  2.2511462330818177\n","Epoch time -----  0.9501025676727295  sec\n","Epoch:  7\n","Train loss:  2.2431970834732056\n","Validation loss:  2.2461215436458586\n","Epoch time -----  0.9374995231628418  sec\n","Epoch:  8\n","Train loss:  2.238011062145233\n","Validation loss:  2.2417598724365235\n","Epoch time -----  0.8979005813598633  sec\n","Epoch:  9\n","Train loss:  2.236123651266098\n","Validation loss:  2.2378820955753325\n","Epoch time -----  0.8875775337219238  sec\n","Epoch:  10\n","Train loss:  2.2303879261016846\n","Validation loss:  2.23428897857666\n","Epoch time -----  1.0070748329162598  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  693  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1055\n","Training samples:  1055\n","Training\n","Epoch:  1\n","Train loss:  2.2004190893734203\n","Validation loss:  2.2013816118240355\n","Epoch time -----  1.1564552783966064  sec\n","Epoch:  2\n","Train loss:  2.1480230022879208\n","Validation loss:  2.184817099571228\n","Epoch time -----  1.0524795055389404  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  2.110073685646057\n","Validation loss:  2.1837479531764985\n","Epoch time -----  1.177595615386963  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  2.0790409831439747\n","Validation loss:  2.177106040716171\n","Epoch time -----  1.030801773071289  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  2.0531647275475895\n","Validation loss:  2.173290711641312\n","Epoch time -----  1.0928502082824707  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  2.044629391501932\n","Validation loss:  2.167795592546463\n","Epoch time -----  1.1035490036010742  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  2.0293244263705086\n","Validation loss:  2.158538168668747\n","Epoch time -----  1.054678201675415  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  2.014125536469852\n","Validation loss:  2.1495401203632354\n","Epoch time -----  1.1199426651000977  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.9971708690418917\n","Validation loss:  2.1428876340389253\n","Epoch time -----  1.1596477031707764  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.9784618475857902\n","Validation loss:  2.134124591946602\n","Epoch time -----  1.1133995056152344  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  10.88\n","Round:  2\n","Using entropy sampling on  38945  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1615\n","Training samples:  1615\n","Training\n","Epoch:  1\n","Train loss:  2.004546046257019\n","Validation loss:  2.0845699667930604\n","Epoch time -----  1.224177598953247  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.8822925044940069\n","Validation loss:  2.0440895199775695\n","Epoch time -----  1.2055280208587646  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.7758935414827788\n","Validation loss:  1.9400132834911346\n","Epoch time -----  1.1128098964691162  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.6938449098513677\n","Validation loss:  1.9158966898918153\n","Epoch time -----  1.02152419090271  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.6508985849527211\n","Validation loss:  1.8598949402570724\n","Epoch time -----  1.0635733604431152  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.587255372450902\n","Validation loss:  1.8339213103055954\n","Epoch time -----  1.1872968673706055  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.5676145278490508\n","Validation loss:  1.805451238155365\n","Epoch time -----  1.2163567543029785  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.5442940363517175\n","Validation loss:  1.7829234302043915\n","Epoch time -----  1.1530423164367676  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.5257833370795617\n","Validation loss:  1.7814606219530105\n","Epoch time -----  1.2292659282684326  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.505618040378277\n","Validation loss:  1.7654435187578201\n","Epoch time -----  1.2582030296325684  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  34.15\n","Round:  3\n","Using entropy sampling on  38385  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  708  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2183\n","Training samples:  2183\n","Training\n","Epoch:  1\n","Train loss:  1.6656214714050293\n","Validation loss:  1.7409777611494064\n","Epoch time -----  1.3476994037628174  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.5939797776085989\n","Validation loss:  1.659016740322113\n","Epoch time -----  1.3618316650390625  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.5292736462184362\n","Validation loss:  1.7700910180807115\n","Epoch time -----  1.2770051956176758  sec\n","Epoch:  4\n","Train loss:  1.528372083391462\n","Validation loss:  1.6856538027524948\n","Epoch time -----  1.2917466163635254  sec\n","Epoch:  5\n","Train loss:  1.495304240499224\n","Validation loss:  1.593954786658287\n","Epoch time -----  1.3683278560638428  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4717713253838676\n","Validation loss:  1.611585396528244\n","Epoch time -----  1.4346320629119873  sec\n","Epoch:  7\n","Train loss:  1.4645050730024065\n","Validation loss:  1.597505474090576\n","Epoch time -----  1.2768824100494385  sec\n","Epoch:  8\n","Train loss:  1.4409488337380545\n","Validation loss:  1.568982607126236\n","Epoch time -----  1.4410336017608643  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4212369884763445\n","Validation loss:  1.5657559096813203\n","Epoch time -----  1.4699594974517822  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.434638319696699\n","Validation loss:  1.568306314945221\n","Epoch time -----  1.354598045349121  sec\n","Testing\n","Test accuracy:  47.59\n","Round:  4\n","Using entropy sampling on  37817  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2755\n","Training samples:  2755\n","Training\n","Epoch:  1\n","Train loss:  1.5606514405120502\n","Validation loss:  1.7089007794857025\n","Epoch time -----  1.2484760284423828  sec\n","Epoch:  2\n","Train loss:  1.5240513763644479\n","Validation loss:  1.7847485810518264\n","Epoch time -----  1.3144428730010986  sec\n","Epoch:  3\n","Train loss:  1.5140098848126151\n","Validation loss:  1.6645520895719528\n","Epoch time -----  1.5038971900939941  sec\n","Epoch:  4\n","Train loss:  1.5035460076548837\n","Validation loss:  1.6289251029491425\n","Epoch time -----  1.5430936813354492  sec\n","Epoch:  5\n","Train loss:  1.468589254400947\n","Validation loss:  1.5477204114198684\n","Epoch time -----  1.5228323936462402  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4688507264310664\n","Validation loss:  1.5470770597457886\n","Epoch time -----  1.6012239456176758  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4551113193685359\n","Validation loss:  1.5046704202890395\n","Epoch time -----  1.4430320262908936  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4099290817975998\n","Validation loss:  1.5144037067890168\n","Epoch time -----  1.4434611797332764  sec\n","Epoch:  9\n","Train loss:  1.4245446297255429\n","Validation loss:  1.4846993744373322\n","Epoch time -----  1.4252912998199463  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4312992990016937\n","Validation loss:  1.5043354332447052\n","Epoch time -----  1.4657447338104248  sec\n","Testing\n","Test accuracy:  51.38\n","Round:  5\n","Using entropy sampling on  37245  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  724  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3336\n","Training samples:  3336\n","Training\n","Epoch:  1\n","Train loss:  1.5294191724849198\n","Validation loss:  1.627337509393692\n","Epoch time -----  1.7852656841278076  sec\n","Epoch:  2\n","Train loss:  1.5276412828913275\n","Validation loss:  1.5381967157125473\n","Epoch time -----  1.6617958545684814  sec\n","Epoch:  3\n","Train loss:  1.4993811890764057\n","Validation loss:  1.4823763817548752\n","Epoch time -----  1.7314519882202148  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4867080427565664\n","Validation loss:  1.5208347022533417\n","Epoch time -----  1.6981267929077148  sec\n","Epoch:  5\n","Train loss:  1.4610263986407586\n","Validation loss:  1.5261651784181596\n","Epoch time -----  1.495171070098877  sec\n","Epoch:  6\n","Train loss:  1.442607379184579\n","Validation loss:  1.4401785999536514\n","Epoch time -----  1.6632704734802246  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4452991822980485\n","Validation loss:  1.4749187380075455\n","Epoch time -----  1.7019548416137695  sec\n","Epoch:  8\n","Train loss:  1.4378480708824013\n","Validation loss:  1.450840499997139\n","Epoch time -----  1.4683222770690918  sec\n","Epoch:  9\n","Train loss:  1.4219041050605055\n","Validation loss:  1.4239742457866669\n","Epoch time -----  1.6017045974731445  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.415396715110203\n","Validation loss:  1.4293634057044984\n","Epoch time -----  1.757781744003296  sec\n","Epoch:  11\n","Train loss:  1.426831508582493\n","Validation loss:  1.4247109919786454\n","Epoch time -----  1.5343189239501953  sec\n","Testing\n","Test accuracy:  58.02\n","Round:  6\n","Using entropy sampling on  36664  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  729  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3921\n","Training samples:  3921\n","Training\n","Epoch:  1\n","Train loss:  1.5166532762588993\n","Validation loss:  1.4957502037286758\n","Epoch time -----  1.7212307453155518  sec\n","Epoch:  2\n","Train loss:  1.4843921026875895\n","Validation loss:  1.4192274779081344\n","Epoch time -----  1.8656580448150635  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.463785009999429\n","Validation loss:  1.4565983295440674\n","Epoch time -----  1.7691574096679688  sec\n","Epoch:  4\n","Train loss:  1.4508708004028565\n","Validation loss:  1.3680293262004852\n","Epoch time -----  1.5195362567901611  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4358717760732096\n","Validation loss:  1.4009602069854736\n","Epoch time -----  1.8833575248718262  sec\n","Epoch:  6\n","Train loss:  1.418010792424602\n","Validation loss:  1.3580413550138473\n","Epoch time -----  1.969409704208374  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4077992054723925\n","Validation loss:  1.3627977073192596\n","Epoch time -----  1.9646918773651123  sec\n","Epoch:  8\n","Train loss:  1.3969294217325026\n","Validation loss:  1.3606425046920776\n","Epoch time -----  1.966907024383545  sec\n","Epoch:  9\n","Train loss:  1.3926750825297447\n","Validation loss:  1.3505404159426688\n","Epoch time -----  1.6280317306518555  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.386244568132585\n","Validation loss:  1.3701101303100587\n","Epoch time -----  1.7594985961914062  sec\n","Epoch:  11\n","Train loss:  1.3778327568884818\n","Validation loss:  1.348132738471031\n","Epoch time -----  1.9777987003326416  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  63.58\n","Round:  7\n","Using entropy sampling on  36079  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  736  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4512\n","Training samples:  4512\n","Training\n","Epoch:  1\n","Train loss:  1.4841220160605202\n","Validation loss:  1.3658530041575432\n","Epoch time -----  1.6274116039276123  sec\n","Epoch:  2\n","Train loss:  1.460215321728881\n","Validation loss:  1.3581227958202362\n","Epoch time -----  1.9149634838104248  sec\n","Epoch:  3\n","Train loss:  1.4269565226326526\n","Validation loss:  1.3525335103273393\n","Epoch time -----  1.8079030513763428  sec\n","Epoch:  4\n","Train loss:  1.4043512831271534\n","Validation loss:  1.3144262343645097\n","Epoch time -----  2.0113890171051025  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4070196269263684\n","Validation loss:  1.324458046257496\n","Epoch time -----  1.6771671772003174  sec\n","Epoch:  6\n","Train loss:  1.3807547361078396\n","Validation loss:  1.3001463174819947\n","Epoch time -----  1.4314136505126953  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3740203330214595\n","Validation loss:  1.2837772101163865\n","Epoch time -----  1.6770730018615723  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3617403557602787\n","Validation loss:  1.2872180804610251\n","Epoch time -----  2.1625008583068848  sec\n","Epoch:  9\n","Train loss:  1.3518304757668937\n","Validation loss:  1.2902861326932906\n","Epoch time -----  2.2296862602233887  sec\n","Epoch:  10\n","Train loss:  1.356362223625183\n","Validation loss:  1.2762716695666314\n","Epoch time -----  1.8836908340454102  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3428694815702842\n","Validation loss:  1.278081813454628\n","Epoch time -----  1.7807643413543701  sec\n","Testing\n","Test accuracy:  69.29\n","Round:  8\n","Using entropy sampling on  35488  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5108\n","Training samples:  5108\n","Training\n","Epoch:  1\n","Train loss:  1.436125671863556\n","Validation loss:  1.2807599574327468\n","Epoch time -----  1.9340500831604004  sec\n","Epoch:  2\n","Train loss:  1.4199696868658065\n","Validation loss:  1.260734026134014\n","Epoch time -----  2.0640289783477783  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3995423898100854\n","Validation loss:  1.2504163295030595\n","Epoch time -----  1.832632303237915  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3789458841085434\n","Validation loss:  1.24408361017704\n","Epoch time -----  2.089757204055786  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3757597088813782\n","Validation loss:  1.2524478048086167\n","Epoch time -----  1.9395573139190674  sec\n","Epoch:  6\n","Train loss:  1.3497638553380966\n","Validation loss:  1.2422429859638213\n","Epoch time -----  2.2286269664764404  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3384197235107422\n","Validation loss:  1.2318124756217004\n","Epoch time -----  1.912210464477539  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3238545969128608\n","Validation loss:  1.2226967707276344\n","Epoch time -----  1.8117103576660156  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3156869739294053\n","Validation loss:  1.23040971159935\n","Epoch time -----  2.370001792907715  sec\n","Epoch:  10\n","Train loss:  1.3102517507970333\n","Validation loss:  1.2220682054758072\n","Epoch time -----  2.1788547039031982  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3118358105421066\n","Validation loss:  1.221422702074051\n","Epoch time -----  2.3019890785217285  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  77.02\n","Round:  9\n","Using entropy sampling on  34892  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5709\n","Training samples:  5709\n","Training\n","Epoch:  1\n","Train loss:  1.408235846625434\n","Validation loss:  1.2412118896842004\n","Epoch time -----  2.8443703651428223  sec\n","Epoch:  2\n","Train loss:  1.3854482412338256\n","Validation loss:  1.2450739935040473\n","Epoch time -----  1.845357894897461  sec\n","Epoch:  3\n","Train loss:  1.3656264715724522\n","Validation loss:  1.223248580098152\n","Epoch time -----  2.239511251449585  sec\n","Epoch:  4\n","Train loss:  1.3529270132382711\n","Validation loss:  1.2165742576122285\n","Epoch time -----  2.225498676300049  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3309230049451193\n","Validation loss:  1.231561180949211\n","Epoch time -----  2.2161471843719482  sec\n","Epoch:  6\n","Train loss:  1.3118084947268167\n","Validation loss:  1.173663741350174\n","Epoch time -----  2.114783763885498  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.3039438592063055\n","Validation loss:  1.1849607586860658\n","Epoch time -----  2.2889370918273926  sec\n","Epoch:  8\n","Train loss:  1.2995468801922267\n","Validation loss:  1.174133586883545\n","Epoch time -----  2.33614182472229  sec\n","Epoch:  9\n","Train loss:  1.283086230357488\n","Validation loss:  1.176402062177658\n","Epoch time -----  2.4102835655212402  sec\n","Epoch:  10\n","Train loss:  1.2800778004858229\n","Validation loss:  1.175675556063652\n","Epoch time -----  2.2879090309143066  sec\n","Epoch:  11\n","Train loss:  1.28516555958324\n","Validation loss:  1.1756383299827575\n","Epoch time -----  2.232551097869873  sec\n","Testing\n","Test accuracy:  81.08\n","Round:  10\n","Using entropy sampling on  34291  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  760  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6319\n","Training samples:  6319\n","Training\n","Epoch:  1\n","Train loss:  1.372730214186389\n","Validation loss:  1.1757185205817222\n","Epoch time -----  2.5230822563171387  sec\n","Epoch:  2\n","Train loss:  1.364066897016583\n","Validation loss:  1.1788530603051186\n","Epoch time -----  2.433403491973877  sec\n","Epoch:  3\n","Train loss:  1.3431413631246547\n","Validation loss:  1.1712736561894417\n","Epoch time -----  2.43214750289917  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3164140275030425\n","Validation loss:  1.1497618228197097\n","Epoch time -----  2.455414295196533  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3095441948283801\n","Validation loss:  1.1488911166787148\n","Epoch time -----  2.361348867416382  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3005502982573076\n","Validation loss:  1.1544950008392334\n","Epoch time -----  1.9802470207214355  sec\n","Epoch:  7\n","Train loss:  1.294378936892808\n","Validation loss:  1.1461127996444702\n","Epoch time -----  2.4228503704071045  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2814740412163013\n","Validation loss:  1.1522633582353592\n","Epoch time -----  2.612011194229126  sec\n","Epoch:  9\n","Train loss:  1.2680584192276\n","Validation loss:  1.141739623248577\n","Epoch time -----  2.365180730819702  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.2615787531390334\n","Validation loss:  1.137879776954651\n","Epoch time -----  2.4738714694976807  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.247786901213906\n","Validation loss:  1.1390554487705231\n","Epoch time -----  2.4944968223571777  sec\n","Epoch:  12\n","Train loss:  1.2652186636972909\n","Validation loss:  1.138772051036358\n","Epoch time -----  2.124878168106079  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [42:06<10:24, 312.38s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  84.79\n","Using CUDA\n","Test accuracy:  9.97\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.2909334897994995\n","Validation loss:  2.273049163818359\n","Epoch time -----  0.8836290836334229  sec\n","Epoch:  2\n","Train loss:  2.2595556378364563\n","Validation loss:  2.2529503226280214\n","Epoch time -----  0.9735527038574219  sec\n","Epoch:  3\n","Train loss:  2.2371023893356323\n","Validation loss:  2.236226189136505\n","Epoch time -----  0.9205231666564941  sec\n","Epoch:  4\n","Train loss:  2.2215361297130585\n","Validation loss:  2.224478131532669\n","Epoch time -----  0.900233268737793  sec\n","Epoch:  5\n","Train loss:  2.2103640735149384\n","Validation loss:  2.2160379946231843\n","Epoch time -----  0.8584606647491455  sec\n","Epoch:  6\n","Train loss:  2.2019442915916443\n","Validation loss:  2.2100865244865417\n","Epoch time -----  0.8663673400878906  sec\n","Epoch:  7\n","Train loss:  2.197247564792633\n","Validation loss:  2.2058009803295135\n","Epoch time -----  0.8792667388916016  sec\n","Epoch:  8\n","Train loss:  2.185296416282654\n","Validation loss:  2.202540773153305\n","Epoch time -----  0.961320161819458  sec\n","Epoch:  9\n","Train loss:  2.1898806989192963\n","Validation loss:  2.200378829240799\n","Epoch time -----  0.9161522388458252  sec\n","Epoch:  10\n","Train loss:  2.1842538118362427\n","Validation loss:  2.198474460840225\n","Epoch time -----  0.8730392456054688  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  693  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1055\n","Training samples:  1055\n","Training\n","Epoch:  1\n","Train loss:  2.2492863570942596\n","Validation loss:  2.1984053790569305\n","Epoch time -----  1.02152419090271  sec\n","Epoch:  2\n","Train loss:  2.2191269397735596\n","Validation loss:  2.198507863283157\n","Epoch time -----  2.053630828857422  sec\n","Epoch:  3\n","Train loss:  2.2108411648694206\n","Validation loss:  2.201570135354996\n","Epoch time -----  1.002758264541626  sec\n","Epoch:  4\n","Train loss:  2.201162198010613\n","Validation loss:  2.200488495826721\n","Epoch time -----  1.0676939487457275  sec\n","Epoch:  5\n","Train loss:  2.1972958480610565\n","Validation loss:  2.199172395467758\n","Epoch time -----  0.9994900226593018  sec\n","Epoch:  6\n","Train loss:  2.1938747377956616\n","Validation loss:  2.199238288402557\n","Epoch time -----  0.9920127391815186  sec\n","Epoch:  7\n","Train loss:  2.1930079039405372\n","Validation loss:  2.194000613689423\n","Epoch time -----  0.9930000305175781  sec\n","Epoch:  8\n","Train loss:  2.18437403791091\n","Validation loss:  2.191896402835846\n","Epoch time -----  0.9884042739868164  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  2.17874252094942\n","Validation loss:  2.1897814512252807\n","Epoch time -----  0.9996612071990967  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  2.1748649513020233\n","Validation loss:  2.187367445230484\n","Epoch time -----  1.0682134628295898  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  9.76\n","Round:  2\n","Using entropy sampling on  38945  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1615\n","Training samples:  1615\n","Training\n","Epoch:  1\n","Train loss:  2.1796081341229954\n","Validation loss:  2.167531114816666\n","Epoch time -----  1.1989474296569824  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  2.1426495680442224\n","Validation loss:  2.1492355823516847\n","Epoch time -----  1.173262119293213  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  2.1218142050963182\n","Validation loss:  2.132415211200714\n","Epoch time -----  1.0641071796417236  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  2.10340887766618\n","Validation loss:  2.0891311407089233\n","Epoch time -----  1.1240215301513672  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  2.0699400168198805\n","Validation loss:  2.066974049806595\n","Epoch time -----  1.220001220703125  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  2.0325163144331713\n","Validation loss:  2.043676868081093\n","Epoch time -----  1.1360859870910645  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  2.02587642119481\n","Validation loss:  2.0181526631116866\n","Epoch time -----  1.0568127632141113  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  2.0037465462317834\n","Validation loss:  1.9953026622533798\n","Epoch time -----  1.0585856437683105  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.9891719405467694\n","Validation loss:  1.9789724141359328\n","Epoch time -----  1.063652515411377  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.9573381084662218\n","Validation loss:  1.9595892518758773\n","Epoch time -----  1.1208631992340088  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  15.31\n","Round:  3\n","Using entropy sampling on  38385  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  708  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2182\n","Training samples:  2182\n","Training\n","Epoch:  1\n","Train loss:  1.998585970061166\n","Validation loss:  1.916478157043457\n","Epoch time -----  0.974205732345581  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.931984485898699\n","Validation loss:  1.8631575912237168\n","Epoch time -----  0.9482722282409668  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.8784773179462977\n","Validation loss:  1.7772541493177414\n","Epoch time -----  1.0214242935180664  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.8435414280210223\n","Validation loss:  1.74264917075634\n","Epoch time -----  1.1573123931884766  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.8001805918557303\n","Validation loss:  1.7537779599428176\n","Epoch time -----  1.1587541103363037  sec\n","Epoch:  6\n","Train loss:  1.7727072715759278\n","Validation loss:  1.689125895500183\n","Epoch time -----  1.2596380710601807  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.7427911145346506\n","Validation loss:  1.6628911972045899\n","Epoch time -----  1.0545945167541504  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.7181408711842128\n","Validation loss:  1.648926678299904\n","Epoch time -----  1.049210548400879  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.706096260888236\n","Validation loss:  1.626637789607048\n","Epoch time -----  1.1751625537872314  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.6955737045833044\n","Validation loss:  1.6172111749649047\n","Epoch time -----  1.1574969291687012  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  32.68\n","Round:  4\n","Using entropy sampling on  37818  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2754\n","Training samples:  2754\n","Training\n","Epoch:  1\n","Train loss:  1.7662857960570941\n","Validation loss:  1.8954536110162734\n","Epoch time -----  1.1613225936889648  sec\n","Epoch:  2\n","Train loss:  1.7391259290955283\n","Validation loss:  1.7676239609718323\n","Epoch time -----  1.2817130088806152  sec\n","Epoch:  3\n","Train loss:  1.7030567581003362\n","Validation loss:  1.6218497604131699\n","Epoch time -----  1.4658277034759521  sec\n","Epoch:  4\n","Train loss:  1.6627257032827898\n","Validation loss:  1.5654575765132903\n","Epoch time -----  1.3476183414459229  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.6350016295909882\n","Validation loss:  1.588825550675392\n","Epoch time -----  1.370485782623291  sec\n","Epoch:  6\n","Train loss:  1.662911900065162\n","Validation loss:  1.574829536676407\n","Epoch time -----  1.350417137145996  sec\n","Epoch:  7\n","Train loss:  1.6034218858588825\n","Validation loss:  1.5227594763040542\n","Epoch time -----  1.2098050117492676  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.6318643255667253\n","Validation loss:  1.603435018658638\n","Epoch time -----  1.0707182884216309  sec\n","Epoch:  9\n","Train loss:  1.589142918586731\n","Validation loss:  1.4925271213054656\n","Epoch time -----  1.265373706817627  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.5933412909507751\n","Validation loss:  1.506557184457779\n","Epoch time -----  1.380624771118164  sec\n","Testing\n","Test accuracy:  48.42\n","Round:  5\n","Using entropy sampling on  37246  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  722  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3332\n","Training samples:  3332\n","Training\n","Epoch:  1\n","Train loss:  1.67499585196657\n","Validation loss:  1.5463776171207428\n","Epoch time -----  1.3672497272491455  sec\n","Epoch:  2\n","Train loss:  1.6190742029334015\n","Validation loss:  1.6328438639640808\n","Epoch time -----  1.2012913227081299  sec\n","Epoch:  3\n","Train loss:  1.606942912317672\n","Validation loss:  1.5718068867921828\n","Epoch time -----  1.3493902683258057  sec\n","Epoch:  4\n","Train loss:  1.6119184718941741\n","Validation loss:  1.549133363366127\n","Epoch time -----  1.5396859645843506  sec\n","Epoch:  5\n","Train loss:  1.598594750998155\n","Validation loss:  1.5022241801023484\n","Epoch time -----  1.5714869499206543  sec\n","Epoch:  6\n","Train loss:  1.559291032125365\n","Validation loss:  1.4189691692590714\n","Epoch time -----  1.341038703918457  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.5846507099439513\n","Validation loss:  1.439005297422409\n","Epoch time -----  1.2782938480377197  sec\n","Epoch:  8\n","Train loss:  1.5669705148013133\n","Validation loss:  1.4387482583522797\n","Epoch time -----  1.4648222923278809  sec\n","Epoch:  9\n","Train loss:  1.532376156662995\n","Validation loss:  1.4230909138917922\n","Epoch time -----  1.4013338088989258  sec\n","Epoch:  10\n","Train loss:  1.5335696463314992\n","Validation loss:  1.4175829529762267\n","Epoch time -----  1.5079233646392822  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.5233193860863739\n","Validation loss:  1.3989641278982163\n","Epoch time -----  1.5444846153259277  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  64.57\n","Round:  6\n","Using entropy sampling on  36668  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  730  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3916\n","Training samples:  3916\n","Training\n","Epoch:  1\n","Train loss:  1.610988438129425\n","Validation loss:  1.550642442703247\n","Epoch time -----  1.6102051734924316  sec\n","Epoch:  2\n","Train loss:  1.588955367765119\n","Validation loss:  1.4025300592184067\n","Epoch time -----  1.5577044486999512  sec\n","Epoch:  3\n","Train loss:  1.5471708370793251\n","Validation loss:  1.4454726964235305\n","Epoch time -----  1.5475983619689941  sec\n","Epoch:  4\n","Train loss:  1.5274112128442334\n","Validation loss:  1.3751444846391678\n","Epoch time -----  1.5454041957855225  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5067247709920328\n","Validation loss:  1.3466855436563492\n","Epoch time -----  1.4180712699890137  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.5023569791547713\n","Validation loss:  1.3249086529016494\n","Epoch time -----  1.577721357345581  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4821794033050537\n","Validation loss:  1.3266093730926514\n","Epoch time -----  1.6278433799743652  sec\n","Epoch:  8\n","Train loss:  1.4791613086577384\n","Validation loss:  1.3164235949516296\n","Epoch time -----  1.6012837886810303  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.461728951623363\n","Validation loss:  1.3146134689450264\n","Epoch time -----  1.5986135005950928  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.4496381705807102\n","Validation loss:  1.3142585009336472\n","Epoch time -----  1.451230764389038  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4413715831695064\n","Validation loss:  1.3062895670533181\n","Epoch time -----  1.5420055389404297  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  70.31\n","Round:  7\n","Using entropy sampling on  36084  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  738  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4507\n","Training samples:  4507\n","Training\n","Epoch:  1\n","Train loss:  1.5288993439204257\n","Validation loss:  1.3207503795623778\n","Epoch time -----  1.4527626037597656  sec\n","Epoch:  2\n","Train loss:  1.4970976617974294\n","Validation loss:  1.2989447951316833\n","Epoch time -----  1.236623764038086  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.4762501666243648\n","Validation loss:  1.2915452435612678\n","Epoch time -----  1.2411582469940186  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.4579600146119023\n","Validation loss:  1.2607212111353874\n","Epoch time -----  1.484912633895874  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4326632241128197\n","Validation loss:  1.2868880361318589\n","Epoch time -----  1.710780143737793  sec\n","Epoch:  6\n","Train loss:  1.4144202773000154\n","Validation loss:  1.2758949130773545\n","Epoch time -----  1.7047476768493652  sec\n","Epoch:  7\n","Train loss:  1.417872729435773\n","Validation loss:  1.2523545369505882\n","Epoch time -----  1.5402894020080566  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4011293683253543\n","Validation loss:  1.2398278757929801\n","Epoch time -----  1.6526498794555664  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.3998923536757348\n","Validation loss:  1.234345455467701\n","Epoch time -----  1.5036571025848389  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.38111730360649\n","Validation loss:  1.233619248867035\n","Epoch time -----  1.5290119647979736  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3689620343732163\n","Validation loss:  1.222434550523758\n","Epoch time -----  1.2714653015136719  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  80.17\n","Round:  8\n","Using entropy sampling on  35493  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  745  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5105\n","Training samples:  5105\n","Training\n","Epoch:  1\n","Train loss:  1.4749256372451782\n","Validation loss:  1.2237071260809897\n","Epoch time -----  1.7861769199371338  sec\n","Epoch:  2\n","Train loss:  1.4423613116145133\n","Validation loss:  1.2065269589424132\n","Epoch time -----  1.719402551651001  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.409632968902588\n","Validation loss:  1.1897397473454476\n","Epoch time -----  1.4792113304138184  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3936364352703094\n","Validation loss:  1.1953481078147887\n","Epoch time -----  1.6871073246002197  sec\n","Epoch:  5\n","Train loss:  1.3768868252635003\n","Validation loss:  1.188524267077446\n","Epoch time -----  1.8358428478240967  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.358094573020935\n","Validation loss:  1.2021685764193535\n","Epoch time -----  1.7684569358825684  sec\n","Epoch:  7\n","Train loss:  1.3559890776872634\n","Validation loss:  1.1753230646252633\n","Epoch time -----  1.8172428607940674  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3458375841379167\n","Validation loss:  1.1682245671749114\n","Epoch time -----  1.8068304061889648  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.32885999083519\n","Validation loss:  1.1704529061913491\n","Epoch time -----  1.5872409343719482  sec\n","Epoch:  10\n","Train loss:  1.3239233687520027\n","Validation loss:  1.1735373601317405\n","Epoch time -----  1.4700291156768799  sec\n","Epoch:  11\n","Train loss:  1.3254195228219032\n","Validation loss:  1.166071566939354\n","Epoch time -----  1.3982818126678467  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  85.78\n","Round:  9\n","Using entropy sampling on  34895  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5708\n","Training samples:  5708\n","Training\n","Epoch:  1\n","Train loss:  1.4094359397888183\n","Validation loss:  1.2192068099975586\n","Epoch time -----  1.7141776084899902  sec\n","Epoch:  2\n","Train loss:  1.3902345564630296\n","Validation loss:  1.2274916812777519\n","Epoch time -----  1.7190909385681152  sec\n","Epoch:  3\n","Train loss:  1.3743767870797052\n","Validation loss:  1.1864013001322746\n","Epoch time -----  1.7621827125549316  sec\n","Epoch:  4\n","Train loss:  1.3545489602618748\n","Validation loss:  1.1961181491613389\n","Epoch time -----  1.6662533283233643  sec\n","Epoch:  5\n","Train loss:  1.3326707111464606\n","Validation loss:  1.1757549494504929\n","Epoch time -----  1.6245558261871338  sec\n","Epoch:  6\n","Train loss:  1.3217560013135274\n","Validation loss:  1.1672821268439293\n","Epoch time -----  1.5467400550842285  sec\n","Epoch:  7\n","Train loss:  1.3038123938772412\n","Validation loss:  1.1567329496145249\n","Epoch time -----  1.518066167831421  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2919585545857748\n","Validation loss:  1.1565027847886085\n","Epoch time -----  1.6055612564086914  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2917933927641974\n","Validation loss:  1.1442122906446457\n","Epoch time -----  1.7320106029510498  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.276570083035363\n","Validation loss:  1.1437783733010292\n","Epoch time -----  1.744797945022583  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.2762622369660273\n","Validation loss:  1.1464560449123382\n","Epoch time -----  1.8337790966033936  sec\n","Testing\n","Test accuracy:  88.59\n","Round:  10\n","Using entropy sampling on  34292  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  760  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6316\n","Training samples:  6316\n","Training\n","Epoch:  1\n","Train loss:  1.3811145551276929\n","Validation loss:  1.1411950573325158\n","Epoch time -----  1.921220302581787  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.3475768042333198\n","Validation loss:  1.1310973390936852\n","Epoch time -----  2.0191707611083984  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.3381896079188647\n","Validation loss:  1.1546740904450417\n","Epoch time -----  1.5213596820831299  sec\n","Epoch:  4\n","Train loss:  1.302757649710684\n","Validation loss:  1.156533133983612\n","Epoch time -----  1.6611945629119873  sec\n","Epoch:  5\n","Train loss:  1.276370846863949\n","Validation loss:  1.1264716401696204\n","Epoch time -----  1.6388928890228271  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.2791507737805146\n","Validation loss:  1.1458712279796601\n","Epoch time -----  1.5097007751464844  sec\n","Epoch:  7\n","Train loss:  1.251443204253611\n","Validation loss:  1.1320614263415336\n","Epoch time -----  2.042187213897705  sec\n","Epoch:  8\n","Train loss:  1.248477684729027\n","Validation loss:  1.133155357837677\n","Epoch time -----  2.153909206390381  sec\n","Epoch:  9\n","Train loss:  1.2456353499431803\n","Validation loss:  1.1232253804802894\n","Epoch time -----  1.990138292312622  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.225336239795492\n","Validation loss:  1.1301774278283119\n","Epoch time -----  1.8644275665283203  sec\n","Epoch:  11\n","Train loss:  1.2155301209652063\n","Validation loss:  1.1216484218835832\n","Epoch time -----  1.6450200080871582  sec\n","validation loss minimum, saving model\n","Epoch:  12\n","Train loss:  1.220801951909306\n","Validation loss:  1.1262599408626557\n","Epoch time -----  1.9667749404907227  sec\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":[" 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [46:50<05:03, 303.78s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  89.79\n","Using CUDA\n","Test accuracy:  11.84\n","Training samples:  500\n","Epoch:  1\n","Train loss:  2.3005418181419373\n","Validation loss:  2.2840630412101746\n","Epoch time -----  0.8154516220092773  sec\n","Epoch:  2\n","Train loss:  2.2739893198013306\n","Validation loss:  2.266791695356369\n","Epoch time -----  0.8449416160583496  sec\n","Epoch:  3\n","Train loss:  2.2494556605815887\n","Validation loss:  2.2508649945259096\n","Epoch time -----  0.782001256942749  sec\n","Epoch:  4\n","Train loss:  2.229122370481491\n","Validation loss:  2.2366288006305695\n","Epoch time -----  0.898108959197998  sec\n","Epoch:  5\n","Train loss:  2.2154854238033295\n","Validation loss:  2.2254837095737456\n","Epoch time -----  0.8483095169067383  sec\n","Epoch:  6\n","Train loss:  2.2035416066646576\n","Validation loss:  2.216969001293182\n","Epoch time -----  0.8031446933746338  sec\n","Epoch:  7\n","Train loss:  2.187579780817032\n","Validation loss:  2.211004489660263\n","Epoch time -----  0.8102786540985107  sec\n","Epoch:  8\n","Train loss:  2.1782543063163757\n","Validation loss:  2.2062504470348356\n","Epoch time -----  0.8210089206695557  sec\n","Epoch:  9\n","Train loss:  2.178152084350586\n","Validation loss:  2.203250217437744\n","Epoch time -----  0.8020627498626709  sec\n","Epoch:  10\n","Train loss:  2.1693909764289856\n","Validation loss:  2.200793331861496\n","Epoch time -----  0.8059296607971191  sec\n","Test accuracy:  9.74\n","Round:  1\n","Using entropy sampling on  39500  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  867  points\n","Using loss sampling on  693  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1055\n","Training samples:  1055\n","Training\n","Epoch:  1\n","Train loss:  2.1566756332621857\n","Validation loss:  2.2117295920848847\n","Epoch time -----  0.8759288787841797  sec\n","Epoch:  2\n","Train loss:  2.097226556609659\n","Validation loss:  2.212922716140747\n","Epoch time -----  0.8424770832061768  sec\n","Epoch:  3\n","Train loss:  2.0881639929378735\n","Validation loss:  2.204477334022522\n","Epoch time -----  0.8586702346801758  sec\n","Epoch:  4\n","Train loss:  2.0676627369487988\n","Validation loss:  2.198872077465057\n","Epoch time -----  0.8916666507720947  sec\n","Epoch:  5\n","Train loss:  2.0400444058810963\n","Validation loss:  2.1950633347034456\n","Epoch time -----  0.9803071022033691  sec\n","Epoch:  6\n","Train loss:  2.018605288337259\n","Validation loss:  2.1783282995224\n","Epoch time -----  0.9281797409057617  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  2.0050676289726708\n","Validation loss:  2.1593650341033936\n","Epoch time -----  0.9188487529754639  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.9828163665883682\n","Validation loss:  2.1491042256355284\n","Epoch time -----  0.9457039833068848  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.9528030788197237\n","Validation loss:  2.135553103685379\n","Epoch time -----  0.9742846488952637  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.929462145356571\n","Validation loss:  2.1306524515151977\n","Epoch time -----  0.9351506233215332  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  14.74\n","Round:  2\n","Using entropy sampling on  38945  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  876  points\n","Using loss sampling on  700  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  1616\n","Training samples:  1616\n","Training\n","Epoch:  1\n","Train loss:  2.0021261893785915\n","Validation loss:  2.0938907861709595\n","Epoch time -----  0.9699752330780029  sec\n","validation loss minimum, saving model\n","Epoch:  2\n","Train loss:  1.892201529099391\n","Validation loss:  2.0421805679798126\n","Epoch time -----  0.9826431274414062  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.8440229571782625\n","Validation loss:  1.9874911248683929\n","Epoch time -----  0.9856040477752686  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.7693917751312256\n","Validation loss:  1.9350446254014968\n","Epoch time -----  1.0236825942993164  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.7443012916124785\n","Validation loss:  1.8956459611654282\n","Epoch time -----  1.0087339878082275  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.6705170686428363\n","Validation loss:  1.8645950257778168\n","Epoch time -----  1.0835816860198975  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.6576342720251818\n","Validation loss:  1.836998164653778\n","Epoch time -----  0.9920854568481445  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.6244054299134474\n","Validation loss:  1.8215769469738006\n","Epoch time -----  1.0012402534484863  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.6073167278216436\n","Validation loss:  1.7967933475971223\n","Epoch time -----  1.1180119514465332  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.5860125468327448\n","Validation loss:  1.7823683351278305\n","Epoch time -----  1.0402512550354004  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  34.51\n","Round:  3\n","Using entropy sampling on  38384  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  885  points\n","Using loss sampling on  708  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2183\n","Training samples:  2183\n","Training\n","Epoch:  1\n","Train loss:  1.7231053182056972\n","Validation loss:  1.786549136042595\n","Epoch time -----  1.2223567962646484  sec\n","Epoch:  2\n","Train loss:  1.6666679109845843\n","Validation loss:  1.6949160158634187\n","Epoch time -----  1.254896640777588  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.6084699528557913\n","Validation loss:  1.6624678999185563\n","Epoch time -----  1.1844563484191895  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.5647286312920707\n","Validation loss:  1.6320468217134476\n","Epoch time -----  1.1808855533599854  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.5289982114519391\n","Validation loss:  1.642940765619278\n","Epoch time -----  1.1856775283813477  sec\n","Epoch:  6\n","Train loss:  1.5271030834742956\n","Validation loss:  1.6320225089788436\n","Epoch time -----  1.189229965209961  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4889276572636196\n","Validation loss:  1.5662493795156478\n","Epoch time -----  1.2534515857696533  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4812922375542776\n","Validation loss:  1.5775015473365783\n","Epoch time -----  1.223998785018921  sec\n","Epoch:  9\n","Train loss:  1.4780163696834019\n","Validation loss:  1.5671736657619477\n","Epoch time -----  1.2227799892425537  sec\n","Epoch:  10\n","Train loss:  1.4497587135859897\n","Validation loss:  1.548706090450287\n","Epoch time -----  1.2348217964172363  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  41.11\n","Round:  4\n","Using entropy sampling on  37817  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  894  points\n","Using loss sampling on  715  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  2756\n","Training samples:  2756\n","Training\n","Epoch:  1\n","Train loss:  1.579114025289362\n","Validation loss:  1.833443558216095\n","Epoch time -----  1.433098316192627  sec\n","Epoch:  2\n","Train loss:  1.5707348097454419\n","Validation loss:  1.6992100328207016\n","Epoch time -----  1.3853633403778076  sec\n","Epoch:  3\n","Train loss:  1.5594305992126465\n","Validation loss:  1.5727800667285918\n","Epoch time -----  1.3530349731445312  sec\n","Epoch:  4\n","Train loss:  1.5184807127172297\n","Validation loss:  1.683032551407814\n","Epoch time -----  1.2823338508605957  sec\n","Epoch:  5\n","Train loss:  1.5005434209650212\n","Validation loss:  1.5212735205888748\n","Epoch time -----  1.3177595138549805  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.4874252595684745\n","Validation loss:  1.5010215789079666\n","Epoch time -----  1.233701467514038  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.4819342764941128\n","Validation loss:  1.498382392525673\n","Epoch time -----  1.310694932937622  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.465388834476471\n","Validation loss:  1.5652305006980896\n","Epoch time -----  1.4250667095184326  sec\n","Epoch:  9\n","Train loss:  1.4692044068466534\n","Validation loss:  1.4979261815547944\n","Epoch time -----  1.28629732131958  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.443336925723336\n","Validation loss:  1.4773276329040528\n","Epoch time -----  1.1875269412994385  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  45.92\n","Round:  5\n","Using entropy sampling on  37244  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  903  points\n","Using loss sampling on  722  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3337\n","Training samples:  3337\n","Training\n","Epoch:  1\n","Train loss:  1.5626501249817182\n","Validation loss:  1.49433476626873\n","Epoch time -----  1.3659451007843018  sec\n","Epoch:  2\n","Train loss:  1.530810369635528\n","Validation loss:  1.48035626411438\n","Epoch time -----  1.4697163105010986  sec\n","Epoch:  3\n","Train loss:  1.5142197181593697\n","Validation loss:  1.4834876626729965\n","Epoch time -----  1.4573173522949219  sec\n","Epoch:  4\n","Train loss:  1.5017557076688082\n","Validation loss:  1.4674598902463913\n","Epoch time -----  1.4004364013671875  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.4921770815579396\n","Validation loss:  1.4440565645694732\n","Epoch time -----  1.345076322555542  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.465111365858114\n","Validation loss:  1.4622516959905625\n","Epoch time -----  1.3927745819091797  sec\n","Epoch:  7\n","Train loss:  1.471463938929\n","Validation loss:  1.44189373254776\n","Epoch time -----  1.4852335453033447  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4519030665451627\n","Validation loss:  1.4233679294586181\n","Epoch time -----  1.3063108921051025  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.4480657577514648\n","Validation loss:  1.426224520802498\n","Epoch time -----  1.539055347442627  sec\n","Epoch:  10\n","Train loss:  1.4378716968140512\n","Validation loss:  1.4201193928718567\n","Epoch time -----  1.6487891674041748  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.4269887006507729\n","Validation loss:  1.4036271393299102\n","Epoch time -----  1.4796757698059082  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  58.04\n","Round:  6\n","Using entropy sampling on  36663  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  912  points\n","Using loss sampling on  730  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  3921\n","Training samples:  3921\n","Training\n","Epoch:  1\n","Train loss:  1.5252082232506043\n","Validation loss:  1.43567813038826\n","Epoch time -----  1.4680540561676025  sec\n","Epoch:  2\n","Train loss:  1.4997102945081648\n","Validation loss:  1.388424751162529\n","Epoch time -----  1.4120821952819824  sec\n","validation loss minimum, saving model\n","Epoch:  3\n","Train loss:  1.4924061798280286\n","Validation loss:  1.4443922340869904\n","Epoch time -----  1.4949207305908203  sec\n","Epoch:  4\n","Train loss:  1.4659341919806697\n","Validation loss:  1.366614979505539\n","Epoch time -----  1.5279228687286377  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.449765762975139\n","Validation loss:  1.3708759039640426\n","Epoch time -----  1.5272774696350098  sec\n","Epoch:  6\n","Train loss:  1.4338332260808637\n","Validation loss:  1.3784176349639892\n","Epoch time -----  1.9314680099487305  sec\n","Epoch:  7\n","Train loss:  1.4175372508264357\n","Validation loss:  1.361027616262436\n","Epoch time -----  1.4908859729766846  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.4065719900592681\n","Validation loss:  1.3458667874336243\n","Epoch time -----  1.5389893054962158  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.39988519876234\n","Validation loss:  1.3331559866666793\n","Epoch time -----  1.5152945518493652  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3881308801712529\n","Validation loss:  1.3390005201101303\n","Epoch time -----  1.6413164138793945  sec\n","Epoch:  11\n","Train loss:  1.3853481796479994\n","Validation loss:  1.3310122191905975\n","Epoch time -----  1.602679967880249  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  65.65\n","Round:  7\n","Using entropy sampling on  36079  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  921  points\n","Using loss sampling on  736  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  4510\n","Training samples:  4510\n","Training\n","Epoch:  1\n","Train loss:  1.4869399624811093\n","Validation loss:  1.3669044226408005\n","Epoch time -----  1.6259956359863281  sec\n","Epoch:  2\n","Train loss:  1.4571297789963198\n","Validation loss:  1.3519897222518922\n","Epoch time -----  1.5498316287994385  sec\n","Epoch:  3\n","Train loss:  1.435434982810222\n","Validation loss:  1.3532989919185638\n","Epoch time -----  1.550480842590332  sec\n","Epoch:  4\n","Train loss:  1.4082160835534754\n","Validation loss:  1.3263435393571854\n","Epoch time -----  1.6644961833953857  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3855937114903625\n","Validation loss:  1.2840996474027633\n","Epoch time -----  1.6317338943481445  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3687542290754722\n","Validation loss:  1.2848595201969146\n","Epoch time -----  1.6598761081695557  sec\n","Epoch:  7\n","Train loss:  1.3594916185862582\n","Validation loss:  1.268425914645195\n","Epoch time -----  1.624603033065796  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.3551429644436903\n","Validation loss:  1.2848454505205154\n","Epoch time -----  1.748605489730835  sec\n","Epoch:  9\n","Train loss:  1.337925481124663\n","Validation loss:  1.2680677115917205\n","Epoch time -----  1.6245131492614746  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.3321511258541698\n","Validation loss:  1.2646872699260712\n","Epoch time -----  1.6219902038574219  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.3292223131152945\n","Validation loss:  1.2727163314819336\n","Epoch time -----  1.6432890892028809  sec\n","Testing\n","Test accuracy:  73.79\n","Round:  8\n","Using entropy sampling on  35490  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  930  points\n","Using loss sampling on  744  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5108\n","Training samples:  5108\n","Training\n","Epoch:  1\n","Train loss:  1.4232105299830438\n","Validation loss:  1.3075665533542633\n","Epoch time -----  1.7454710006713867  sec\n","Epoch:  2\n","Train loss:  1.4033235296607018\n","Validation loss:  1.2755882501602174\n","Epoch time -----  1.850097417831421  sec\n","Epoch:  3\n","Train loss:  1.379859559983015\n","Validation loss:  1.243153092265129\n","Epoch time -----  1.7331669330596924  sec\n","validation loss minimum, saving model\n","Epoch:  4\n","Train loss:  1.3608254566788673\n","Validation loss:  1.2348717883229257\n","Epoch time -----  1.7776882648468018  sec\n","validation loss minimum, saving model\n","Epoch:  5\n","Train loss:  1.3406510382890702\n","Validation loss:  1.2213264524936676\n","Epoch time -----  1.749406099319458  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.3305624559521676\n","Validation loss:  1.2359176278114319\n","Epoch time -----  1.6135458946228027  sec\n","Epoch:  7\n","Train loss:  1.315928216278553\n","Validation loss:  1.2171990141272544\n","Epoch time -----  1.582953691482544  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2964809834957123\n","Validation loss:  1.21147833019495\n","Epoch time -----  1.7618253231048584  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.2984506100416184\n","Validation loss:  1.2088454112410545\n","Epoch time -----  1.7596733570098877  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.281295495480299\n","Validation loss:  1.207665602862835\n","Epoch time -----  1.8309330940246582  sec\n","validation loss minimum, saving model\n","Epoch:  11\n","Train loss:  1.274761052429676\n","Validation loss:  1.201664687693119\n","Epoch time -----  1.6520564556121826  sec\n","validation loss minimum, saving model\n","Testing\n","Test accuracy:  80.84\n","Round:  9\n","Using entropy sampling on  34892  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  939  points\n","Using loss sampling on  751  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  5709\n","Training samples:  5709\n","Training\n","Epoch:  1\n","Train loss:  1.3865664111243354\n","Validation loss:  1.2193462759256364\n","Epoch time -----  1.7848968505859375  sec\n","Epoch:  2\n","Train loss:  1.3559823910395303\n","Validation loss:  1.2934175223112105\n","Epoch time -----  1.7490010261535645  sec\n","Epoch:  3\n","Train loss:  1.339586811595493\n","Validation loss:  1.2273663431406021\n","Epoch time -----  1.8755130767822266  sec\n","Epoch:  4\n","Train loss:  1.3204379664527046\n","Validation loss:  1.2557183042168618\n","Epoch time -----  1.940943956375122  sec\n","Epoch:  5\n","Train loss:  1.2927745395236545\n","Validation loss:  1.1956253603100777\n","Epoch time -----  1.8891570568084717  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.2843054837650723\n","Validation loss:  1.1948105186223983\n","Epoch time -----  1.7519631385803223  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.270359973775016\n","Validation loss:  1.1807969748973846\n","Epoch time -----  1.8839330673217773  sec\n","validation loss minimum, saving model\n","Epoch:  8\n","Train loss:  1.2616690344280668\n","Validation loss:  1.1763679280877113\n","Epoch time -----  1.8069074153900146  sec\n","validation loss minimum, saving model\n","Epoch:  9\n","Train loss:  1.263312198056115\n","Validation loss:  1.179547131061554\n","Epoch time -----  1.8322861194610596  sec\n","Epoch:  10\n","Train loss:  1.2498786389827727\n","Validation loss:  1.1783378750085831\n","Epoch time -----  1.9340217113494873  sec\n","Epoch:  11\n","Train loss:  1.235918825864792\n","Validation loss:  1.1775433808565139\n","Epoch time -----  1.8146929740905762  sec\n","Testing\n","Test accuracy:  84.81\n","Round:  10\n","Using entropy sampling on  34291  points\n"]},{"name":"stderr","output_type":"stream","text":["e:\\pratik\\new_marich\\utils.py:398: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  probs = F.softmax(probs).detach().cpu().numpy()\n"]},{"name":"stdout","output_type":"stream","text":["Using gradient sampling on  949  points\n","Using loss sampling on  759  points\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n","e:\\pratik\\new_marich\\utils.py:638: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y_hat = torch.tensor(y_hat)\n","C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_28192/430659003.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  y = torch.tensor(self.Y)[idx]\n","e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  labels.append(torch.tensor(l))\n"]},{"name":"stdout","output_type":"stream","text":["Budget:  6317\n","Training samples:  6317\n","Training\n","Epoch:  1\n","Train loss:  1.351762963063789\n","Validation loss:  1.2011971279978753\n","Epoch time -----  1.9279587268829346  sec\n","Epoch:  2\n","Train loss:  1.3197738076701309\n","Validation loss:  1.1793333798646928\n","Epoch time -----  1.994072437286377  sec\n","Epoch:  3\n","Train loss:  1.3025316710423942\n","Validation loss:  1.1778341725468635\n","Epoch time -----  2.0498123168945312  sec\n","Epoch:  4\n","Train loss:  1.2867667506439517\n","Validation loss:  1.1849519416689873\n","Epoch time -----  2.0485143661499023  sec\n","Epoch:  5\n","Train loss:  1.2820292928002097\n","Validation loss:  1.1710963785648345\n","Epoch time -----  1.9947919845581055  sec\n","validation loss minimum, saving model\n","Epoch:  6\n","Train loss:  1.2642407670165554\n","Validation loss:  1.1552208170294762\n","Epoch time -----  1.9963607788085938  sec\n","validation loss minimum, saving model\n","Epoch:  7\n","Train loss:  1.2473958381498702\n","Validation loss:  1.1587947621941566\n","Epoch time -----  1.8619568347930908  sec\n","Epoch:  8\n","Train loss:  1.2405794286968732\n","Validation loss:  1.1676320135593414\n","Epoch time -----  1.9766602516174316  sec\n","Epoch:  9\n","Train loss:  1.2188437948323259\n","Validation loss:  1.1542002096772195\n","Epoch time -----  1.7972841262817383  sec\n","validation loss minimum, saving model\n","Epoch:  10\n","Train loss:  1.224380713520628\n","Validation loss:  1.15589696764946\n","Epoch time -----  2.089808702468872  sec\n","Epoch:  11\n","Train loss:  1.2186584912165246\n","Validation loss:  1.151921808719635\n","Epoch time -----  2.041701316833496  sec\n","validation loss minimum, saving model\n","Epoch:  12\n","Train loss:  1.2174353575465655\n","Validation loss:  1.1490687370300292\n","Epoch time -----  2.060671329498291  sec\n","validation loss minimum, saving model\n","Testing\n"]},{"name":"stderr","output_type":"stream","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [51:40<00:00, 310.07s/it]"]},{"name":"stdout","output_type":"stream","text":["Test accuracy:  87.04\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["acc_marich = []\n","\n","for i in tqdm(range(10)):\n","  cnn_attack = CNN()\n","  tl_cnn, vl_cnn, tal_cnn, samp_cnn = marich(cnn_attack, unlab_dataset_train, validloader, testloader, budget = 550, init_points = 500, rounds = 10, epochs = 10, LR = 0.015, model_name = \"emnist_cnn\"+str(i)+\".pt\", sampling = \"all_egl\", device = \"cuda\", model_type = \"cnn_mnist\")\n","  \n","  acc_marich.append(tal_cnn)\n","  np.save(\"./results/acc_marich_cnn_emnist.npy\", np.array(acc_marich))\n","np.save(\"./results/samp_cnn_emnist.npy\", np.array(samp_cnn))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
