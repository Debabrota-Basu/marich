{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils import marich, dataset\n",
    "from nets import *\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from torchvision import transforms,models\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "imagenet = unpickle(\"val_data\") # Valdata to be downloaded from ImageNet website. It is the validation split of ImageNet 32, containing 50k samples\n",
    "imagenet = torch.tensor(np.float32(imagenet['data'].reshape(50000,3,32,32)/255))\n",
    "train_transform = transforms.Compose([\n",
    "transforms.Normalize([0.473, 0.450, 0.401], [0.258, 0.251, 0.265])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, X, transform = None):\n",
    "        self.X = X\n",
    "        # self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            x = self.transform(self.X[idx])\n",
    "        else:\n",
    "            x = self.X[idx]\n",
    "        # y = self.Y[idx]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = dataset(imagenet, transform = train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagenet_data = torch.stack([train_transform(x) for x in imagenet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(imagenet_data, \"imagenet_resnet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(img_data, 'img_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_data = torch.load(\"img_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['base', 'drop', 'final']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        self.base = nn.Sequential(*list(base.children())[:-1])\n",
    "        in_features = base.fc.in_features\n",
    "        self.drop = nn.Dropout()\n",
    "        self.final = nn.Linear(in_features,10)\n",
    "    \n",
    "    def forward(self,x): \n",
    "        x = self.base(x)\n",
    "        x = self.drop(x.view(-1,self.final.in_features))\n",
    "        x = self.final(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x\n",
    "    \n",
    "model = Model().cuda()\n",
    "[x for x,y in model.named_children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"new_resnet18_cifar.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet().cuda()\n",
    "# model.load_state_dict(torch.load(\"cnn.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, testloader):\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct / len(testloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unlab_x = []\n",
    "# unlab_y = []\n",
    "# for j in tqdm(img_data):\n",
    "#     model.eval()\n",
    "#     j = j.to(device)\n",
    "#     # unlab_x.append(j)\n",
    "#     unlab_y.append(torch.argmax(model(j.unsqueeze(dim = 0))).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with open('./imagenet_target/imagnet_resnet_x.pkl', 'wb') as f:\n",
    "# #   pickle.dump(unlab_x, f)\n",
    "\n",
    "# with open('./imagenet_target/imagnet_resnet_small_y.pkl', 'wb') as f:\n",
    "#   pickle.dump(unlab_y, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./imagenet_target/imagnet_resnet_x.pkl', 'rb') as f:\n",
    "#   unlab_x = pickle.load(f)\n",
    "\n",
    "with open('./imagenet_target/imagnet_resnet_small_y.pkl', 'rb') as f:\n",
    "  unlab_y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basic_dataset(Dataset):\n",
    "    def __init__(self, X, Y = None, transform = None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            x = self.transform(self.X[idx])\n",
    "        else:\n",
    "            x = self.X[idx]\n",
    "        if self.Y != None:\n",
    "            y = self.Y[idx]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class dataset2(Dataset):\n",
    "    def __init__(self, X, Y = None, transform = None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            x = self.transform(self.X[idx])\n",
    "        else:\n",
    "            x = self.X[idx]\n",
    "        if self.Y != None:\n",
    "            y = self.Y[idx]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x\n",
    "    def get_data(self,idx):\n",
    "        if self.transform:\n",
    "            x = self.transform(self.X[idx])\n",
    "        else:\n",
    "            x = self.X[idx]\n",
    "        return x\n",
    "    def get_dataset(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = torch.tensor(self.Y)[idx]\n",
    "        return basic_dataset(x,y)\n",
    "    def get_label(self,idx):\n",
    "        y = torch.tensor(self.Y)[idx]\n",
    "        return y\n",
    "    def get_data_label_loader(self,idx):\n",
    "        if self.transform:\n",
    "            x = self.transform(self.X[idx])\n",
    "        else:\n",
    "            x = self.X[idx]\n",
    "        y = torch.tensor(self.Y)[idx]\n",
    "        \n",
    "        return_set = basic_dataset(x,y)\n",
    "        return torch.utils.data.DataLoader(return_set, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id, val_id = train_test_split(range(50000), test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_dataset_train = dataset2(img_data[train_id], torch.tensor(unlab_y)[train_id])\n",
    "unlab_dataset_val = dataset2(img_data[val_id], torch.tensor(unlab_y)[val_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10 = datasets.CIFAR10('./cifar10/train/', download=True, train=False, transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "    ]))\n",
    "testloader = DataLoader(cifar10, batch_size = 64)\n",
    "validloader = DataLoader(unlab_dataset_val, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10 = datasets.CIFAR10('./cifar10/train/', download=True, train=False, transform = transforms.Compose([\n",
    "#     # transforms.Resize(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "#     ]))\n",
    "# testloader = DataLoader(cifar10, batch_size = 512)\n",
    "# validloader = DataLoader(unlab_dataset_val, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.res1 = nn.Sequential(nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ), nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True))\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.res2 = nn.Sequential(nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ), nn.Sequential( \n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(4), \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.res1(x) + x\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.res2(x) + x\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  2.238125205039978\n",
      "Validation loss:  2.2730389279165086\n",
      "Epoch time -----  1.392977237701416  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  2\n",
      "Train loss:  2.1905978620052338\n",
      "Validation loss:  2.2519156067234696\n",
      "Epoch time -----  1.1179296970367432  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  2.1646809577941895\n",
      "Validation loss:  2.236851620825992\n",
      "Epoch time -----  1.1718330383300781  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  2.1627182364463806\n",
      "Validation loss:  2.2212671383171325\n",
      "Epoch time -----  1.1466987133026123  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  2.160514086484909\n",
      "Validation loss:  2.2060292192325472\n",
      "Epoch time -----  1.0821919441223145  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  2.1580896377563477\n",
      "Validation loss:  2.1947842115049907\n",
      "Epoch time -----  1.0698001384735107  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  2.1614859998226166\n",
      "Validation loss:  2.188283235404142\n",
      "Epoch time -----  1.074333906173706  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  2.160054326057434\n",
      "Validation loss:  2.185014881146182\n",
      "Epoch time -----  1.1113321781158447  sec\n",
      "validation loss minimum, saving model\n",
      "Test accuracy:  10.0\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1712\n",
      "Training samples:  1712\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.112801882955763\n",
      "Validation loss:  2.187859169237173\n",
      "Epoch time -----  1.6955645084381104  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.964995680031953\n",
      "Validation loss:  2.035746328390328\n",
      "Epoch time -----  1.507045030593872  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8993609834600378\n",
      "Validation loss:  2.0229415240561126\n",
      "Epoch time -----  1.5434093475341797  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8809415013701827\n",
      "Validation loss:  2.0207314658316835\n",
      "Epoch time -----  1.4847099781036377  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8850349717670016\n",
      "Validation loss:  2.0219600777717153\n",
      "Epoch time -----  1.4291656017303467  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.885973784658644\n",
      "Validation loss:  2.0215338202798443\n",
      "Epoch time -----  1.4075593948364258  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8808230294121637\n",
      "Validation loss:  2.0220742309169406\n",
      "Epoch time -----  1.4030003547668457  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8842191342954282\n",
      "Validation loss:  2.0214032238456094\n",
      "Epoch time -----  1.4182019233703613  sec\n",
      "Testing\n",
      "Test accuracy:  19.9\n",
      "Round:  2\n",
      "Using entropy sampling on  38288  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2936\n",
      "Training samples:  2936\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0762723891631416\n",
      "Validation loss:  2.4367230682616023\n",
      "Epoch time -----  1.6853301525115967  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.997785534547723\n",
      "Validation loss:  2.027273196323662\n",
      "Epoch time -----  1.3679049015045166  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.9101256728172302\n",
      "Validation loss:  1.9823948676419105\n",
      "Epoch time -----  1.3743822574615479  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8884747961293096\n",
      "Validation loss:  1.982060175033132\n",
      "Epoch time -----  1.4213857650756836  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8891388385192207\n",
      "Validation loss:  1.982519644081213\n",
      "Epoch time -----  1.3166069984436035  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.8891184874202893\n",
      "Validation loss:  1.9816448718878874\n",
      "Epoch time -----  1.3012855052947998  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.8863917148631553\n",
      "Validation loss:  1.9816619514659712\n",
      "Epoch time -----  1.3425664901733398  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8872701240622478\n",
      "Validation loss:  1.9816486782329097\n",
      "Epoch time -----  1.284625768661499  sec\n",
      "Testing\n",
      "Test accuracy:  24.41\n",
      "Round:  3\n",
      "Using entropy sampling on  37064  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1546  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4172\n",
      "Training samples:  4172\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.030409478779995\n",
      "Validation loss:  2.24828426853107\n",
      "Epoch time -----  1.6634204387664795  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.853077191295046\n",
      "Validation loss:  1.883919831294163\n",
      "Epoch time -----  1.4307727813720703  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.751394195990129\n",
      "Validation loss:  1.8137118618959074\n",
      "Epoch time -----  1.42002272605896  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7261392745104702\n",
      "Validation loss:  1.8065924052220241\n",
      "Epoch time -----  1.408766269683838  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7359382925611553\n",
      "Validation loss:  1.8031498953035683\n",
      "Epoch time -----  1.4162540435791016  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.7385545698079197\n",
      "Validation loss:  1.8071491262715333\n",
      "Epoch time -----  1.4858293533325195  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.731190885558273\n",
      "Validation loss:  1.8096207638455044\n",
      "Epoch time -----  1.4975643157958984  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7280963731534553\n",
      "Validation loss:  1.8116808370420128\n",
      "Epoch time -----  1.481410026550293  sec\n",
      "Testing\n",
      "Test accuracy:  32.35\n",
      "Round:  4\n",
      "Using entropy sampling on  35828  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1563  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5422\n",
      "Training samples:  5422\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.995100083070643\n",
      "Validation loss:  2.2365620143853935\n",
      "Epoch time -----  1.9124062061309814  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7724093928056606\n",
      "Validation loss:  1.7597804251749805\n",
      "Epoch time -----  1.648080825805664  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6741752105600693\n",
      "Validation loss:  1.7036673058370115\n",
      "Epoch time -----  1.7481091022491455  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6521834135055542\n",
      "Validation loss:  1.7050442543758708\n",
      "Epoch time -----  1.7543909549713135  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.651343011856079\n",
      "Validation loss:  1.706363254291996\n",
      "Epoch time -----  1.6217637062072754  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6444174514097325\n",
      "Validation loss:  1.7043698623681525\n",
      "Epoch time -----  1.6102180480957031  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6540583344066844\n",
      "Validation loss:  1.704568436950635\n",
      "Epoch time -----  1.614746332168579  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6503472412333768\n",
      "Validation loss:  1.705295663730354\n",
      "Epoch time -----  1.617293357849121  sec\n",
      "Testing\n",
      "Test accuracy:  36.58\n",
      "Round:  5\n",
      "Using entropy sampling on  34578  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6682\n",
      "Training samples:  6682\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9391900085267566\n",
      "Validation loss:  2.1313001365418645\n",
      "Epoch time -----  1.9849634170532227  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.673766439301627\n",
      "Validation loss:  1.6597733315388867\n",
      "Epoch time -----  1.7786316871643066  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5511508975710189\n",
      "Validation loss:  1.6196385060146357\n",
      "Epoch time -----  1.7181549072265625  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5274245886575608\n",
      "Validation loss:  1.6175208623242225\n",
      "Epoch time -----  1.8189821243286133  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.520145370846703\n",
      "Validation loss:  1.6154668513377002\n",
      "Epoch time -----  1.8317811489105225  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.515765651067098\n",
      "Validation loss:  1.613307585382158\n",
      "Epoch time -----  1.8017539978027344  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.519096145175752\n",
      "Validation loss:  1.6160521188359351\n",
      "Epoch time -----  1.8100862503051758  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.5192588794799078\n",
      "Validation loss:  1.6136912935099024\n",
      "Epoch time -----  1.812795639038086  sec\n",
      "Testing\n",
      "Test accuracy:  41.14\n",
      "Round:  6\n",
      "Using entropy sampling on  33318  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1593  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7956\n",
      "Training samples:  7956\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8924673395156861\n",
      "Validation loss:  2.549576747948956\n",
      "Epoch time -----  2.168717622756958  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5919093990325928\n",
      "Validation loss:  1.606336100086285\n",
      "Epoch time -----  1.9929146766662598  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.4606126260757446\n",
      "Validation loss:  1.5770214480958926\n",
      "Epoch time -----  2.002913475036621  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.4319891109466554\n",
      "Validation loss:  1.5736494656581028\n",
      "Epoch time -----  1.959761381149292  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.4289729614257813\n",
      "Validation loss:  1.5761683473161832\n",
      "Epoch time -----  2.0400896072387695  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.4285986585617065\n",
      "Validation loss:  1.5783461267781105\n",
      "Epoch time -----  2.009993314743042  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.4309175062179564\n",
      "Validation loss:  1.5780042709818312\n",
      "Epoch time -----  2.026625871658325  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.4312858066558838\n",
      "Validation loss:  1.579896903341743\n",
      "Epoch time -----  2.0059545040130615  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.4327860736846925\n",
      "Validation loss:  1.5742631714055493\n",
      "Epoch time -----  2.0400705337524414  sec\n",
      "Testing\n",
      "Test accuracy:  45.18\n",
      "Round:  7\n",
      "Using entropy sampling on  32044  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1609  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9243\n",
      "Training samples:  9243\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.829288913463724\n",
      "Validation loss:  2.473743143355011\n",
      "Epoch time -----  2.4664409160614014  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.4945428404314764\n",
      "Validation loss:  1.553833701048687\n",
      "Epoch time -----  2.1873321533203125  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.3439165345553694\n",
      "Validation loss:  1.5350494589775232\n",
      "Epoch time -----  2.25349497795105  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.320104770824827\n",
      "Validation loss:  1.5324681089941863\n",
      "Epoch time -----  2.2037882804870605  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.3152274945686604\n",
      "Validation loss:  1.5307557575262276\n",
      "Epoch time -----  2.265563726425171  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.3124528712239758\n",
      "Validation loss:  1.5325905600930476\n",
      "Epoch time -----  2.117971658706665  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3150516682657702\n",
      "Validation loss:  1.531868309731696\n",
      "Epoch time -----  2.310692071914673  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.3150155749814263\n",
      "Validation loss:  1.5328500642897978\n",
      "Epoch time -----  2.2090611457824707  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.3148251015564492\n",
      "Validation loss:  1.533937659233239\n",
      "Epoch time -----  2.2610034942626953  sec\n",
      "Testing\n",
      "Test accuracy:  48.73\n",
      "Round:  8\n",
      "Using entropy sampling on  30757  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1626  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10543\n",
      "Training samples:  10543\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7411418098391909\n",
      "Validation loss:  1.692324217717359\n",
      "Epoch time -----  3.0124948024749756  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.354088314374288\n",
      "Validation loss:  1.5124048746315537\n",
      "Epoch time -----  2.645226240158081  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.1842242566022005\n",
      "Validation loss:  1.5266581075206684\n",
      "Epoch time -----  2.3928520679473877  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.1395162011637832\n",
      "Validation loss:  1.52091702382276\n",
      "Epoch time -----  2.6494662761688232  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.1395396261504203\n",
      "Validation loss:  1.5209599353705243\n",
      "Epoch time -----  2.5618784427642822  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.1381518757704532\n",
      "Validation loss:  1.5245331074022184\n",
      "Epoch time -----  2.6193273067474365  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.1402303030996612\n",
      "Validation loss:  1.520871767952184\n",
      "Epoch time -----  2.5824778079986572  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.141353564190142\n",
      "Validation loss:  1.5193986961036732\n",
      "Epoch time -----  2.481057643890381  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.1398976383787214\n",
      "Validation loss:  1.5226505072253524\n",
      "Epoch time -----  2.2588202953338623  sec\n",
      "Testing\n",
      "Test accuracy:  52.45\n",
      "Round:  9\n",
      "Using entropy sampling on  29457  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1641  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11855\n",
      "Training samples:  11855\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6482964202921877\n",
      "Validation loss:  2.0254984919432624\n",
      "Epoch time -----  2.755009174346924  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.1955487119254244\n",
      "Validation loss:  1.5574357057832608\n",
      "Epoch time -----  2.525703191757202  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.004309203035088\n",
      "Validation loss:  1.5327060940159354\n",
      "Epoch time -----  2.481149435043335  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.9673598376653527\n",
      "Validation loss:  1.5464263243280398\n",
      "Epoch time -----  2.482992172241211  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.9584304427587858\n",
      "Validation loss:  1.5417582320559555\n",
      "Epoch time -----  2.3627707958221436  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.964802066485087\n",
      "Validation loss:  1.5400739247631874\n",
      "Epoch time -----  2.4649434089660645  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.961569611103304\n",
      "Validation loss:  1.5421426110206895\n",
      "Epoch time -----  2.5710062980651855  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.9582952087925326\n",
      "Validation loss:  1.5417724153038803\n",
      "Epoch time -----  2.674238920211792  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.9618303166922703\n",
      "Validation loss:  1.543720363052028\n",
      "Epoch time -----  2.44771146774292  sec\n",
      "Testing\n",
      "Test accuracy:  54.59\n",
      "Round:  10\n",
      "Using entropy sampling on  28145  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1657  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13180\n",
      "Training samples:  13180\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5516290340608763\n",
      "Validation loss:  1.5441463270764442\n",
      "Epoch time -----  2.9561240673065186  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.002465731599956\n",
      "Validation loss:  1.575869303600044\n",
      "Epoch time -----  2.687034845352173  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.7915526058488679\n",
      "Validation loss:  1.5926024234218963\n",
      "Epoch time -----  2.570361614227295  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.7588544163889098\n",
      "Validation loss:  1.5940177539351639\n",
      "Epoch time -----  2.7059648036956787  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.7568892469105212\n",
      "Validation loss:  1.597214070095378\n",
      "Epoch time -----  2.7411396503448486  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.7575281242143761\n",
      "Validation loss:  1.596391255308868\n",
      "Epoch time -----  2.9830002784729004  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.7537316558430496\n",
      "Validation loss:  1.6010067208557373\n",
      "Epoch time -----  2.9452338218688965  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.7531131024210198\n",
      "Validation loss:  1.5971537460187437\n",
      "Epoch time -----  2.8606953620910645  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.758024410426038\n",
      "Validation loss:  1.6001029428403089\n",
      "Epoch time -----  2.9828789234161377  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [06:19<56:57, 379.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  57.37\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.2209839522838593\n",
      "Validation loss:  2.2856864503994108\n",
      "Epoch time -----  1.277430772781372  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.2334759533405304\n",
      "Validation loss:  2.2720496624138704\n",
      "Epoch time -----  1.1256821155548096  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.2126367688179016\n",
      "Validation loss:  2.264656344796442\n",
      "Epoch time -----  1.128140926361084  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.2099960148334503\n",
      "Validation loss:  2.258013738948069\n",
      "Epoch time -----  1.0714867115020752  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.209071606397629\n",
      "Validation loss:  2.252184084266614\n",
      "Epoch time -----  1.0514483451843262  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.209518939256668\n",
      "Validation loss:  2.24781716249551\n",
      "Epoch time -----  1.108687162399292  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.2083061933517456\n",
      "Validation loss:  2.245508248638955\n",
      "Epoch time -----  1.0589442253112793  sec\n",
      "Epoch:  8\n",
      "Train loss:  2.2100842595100403\n",
      "Validation loss:  2.244337062167514\n",
      "Epoch time -----  1.0111634731292725  sec\n",
      "Test accuracy:  10.07\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1712\n",
      "Training samples:  1712\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.082558455290618\n",
      "Validation loss:  2.200358326268044\n",
      "Epoch time -----  1.360640048980713  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.9193771724347715\n",
      "Validation loss:  2.0628785684609867\n",
      "Epoch time -----  1.1337547302246094  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8405462547584817\n",
      "Validation loss:  2.0089115800371595\n",
      "Epoch time -----  1.1380178928375244  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8272521672425446\n",
      "Validation loss:  2.0100511585830882\n",
      "Epoch time -----  1.124816656112671  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.821376676912661\n",
      "Validation loss:  2.0100134315004774\n",
      "Epoch time -----  1.2163739204406738  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.8220339439533375\n",
      "Validation loss:  2.0094989135766483\n",
      "Epoch time -----  1.2192494869232178  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8222733029612788\n",
      "Validation loss:  2.009295836375777\n",
      "Epoch time -----  1.1871912479400635  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8187189234627619\n",
      "Validation loss:  2.0106223533107976\n",
      "Epoch time -----  1.2800788879394531  sec\n",
      "Testing\n",
      "Test accuracy:  23.11\n",
      "Round:  2\n",
      "Using entropy sampling on  38288  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2936\n",
      "Training samples:  2936\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0467609218929126\n",
      "Validation loss:  2.164354663745613\n",
      "Epoch time -----  1.5369350910186768  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8882139558377473\n",
      "Validation loss:  1.9962375095695446\n",
      "Epoch time -----  1.4049532413482666  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8185890472453574\n",
      "Validation loss:  1.9215402443697498\n",
      "Epoch time -----  1.4539854526519775  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8043332384980244\n",
      "Validation loss:  1.92147653801426\n",
      "Epoch time -----  1.4377915859222412  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7977714771809785\n",
      "Validation loss:  1.922110207521232\n",
      "Epoch time -----  1.4241373538970947  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7952196753543357\n",
      "Validation loss:  1.9212594753617693\n",
      "Epoch time -----  1.3256783485412598  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.7955254497735396\n",
      "Validation loss:  1.9215810298919678\n",
      "Epoch time -----  1.3946013450622559  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7959192136059636\n",
      "Validation loss:  1.922105195416007\n",
      "Epoch time -----  1.4053165912628174  sec\n",
      "Testing\n",
      "Test accuracy:  27.51\n",
      "Round:  3\n",
      "Using entropy sampling on  37064  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1546  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4172\n",
      "Training samples:  4172\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.052056498599775\n",
      "Validation loss:  2.265423470242008\n",
      "Epoch time -----  1.8092856407165527  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.861286548050967\n",
      "Validation loss:  1.9007579202105285\n",
      "Epoch time -----  1.5967206954956055  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7770070415554624\n",
      "Validation loss:  1.8110656556050488\n",
      "Epoch time -----  1.7527425289154053  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7395615035837346\n",
      "Validation loss:  1.8037854691219937\n",
      "Epoch time -----  1.8064758777618408  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7383836002060862\n",
      "Validation loss:  1.8031588565012453\n",
      "Epoch time -----  1.866792917251587  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.7413372216802654\n",
      "Validation loss:  1.8011161202837707\n",
      "Epoch time -----  2.087222099304199  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.731644904974735\n",
      "Validation loss:  1.807729219934743\n",
      "Epoch time -----  2.0173354148864746  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7377933317964727\n",
      "Validation loss:  1.8103271927803186\n",
      "Epoch time -----  2.057199239730835  sec\n",
      "Testing\n",
      "Test accuracy:  33.48\n",
      "Round:  4\n",
      "Using entropy sampling on  35828  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1561  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5420\n",
      "Training samples:  5420\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.018871075966779\n",
      "Validation loss:  1.9860569549973603\n",
      "Epoch time -----  2.053738594055176  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7961734897950117\n",
      "Validation loss:  1.7949602193893142\n",
      "Epoch time -----  1.8739244937896729  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7146276417900534\n",
      "Validation loss:  1.731690169899327\n",
      "Epoch time -----  1.8829233646392822  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.694673814493067\n",
      "Validation loss:  1.727596551749357\n",
      "Epoch time -----  2.0066752433776855  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.695210069768569\n",
      "Validation loss:  1.7286312792711198\n",
      "Epoch time -----  1.8952863216400146  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6952600282781265\n",
      "Validation loss:  1.7260267711748742\n",
      "Epoch time -----  1.9504785537719727  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.698959706811344\n",
      "Validation loss:  1.7305124906977272\n",
      "Epoch time -----  2.358746290206909  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6984034622416777\n",
      "Validation loss:  1.725777604777342\n",
      "Epoch time -----  2.5343587398529053  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  34.44\n",
      "Round:  5\n",
      "Using entropy sampling on  34580  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6682\n",
      "Training samples:  6682\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9533538772946313\n",
      "Validation loss:  2.842649888081156\n",
      "Epoch time -----  2.5740339756011963  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.732686610448928\n",
      "Validation loss:  1.6791385321100807\n",
      "Epoch time -----  2.374455690383911  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6136228481928507\n",
      "Validation loss:  1.649460267109476\n",
      "Epoch time -----  2.590928792953491  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6009201424462454\n",
      "Validation loss:  1.6466515656489475\n",
      "Epoch time -----  2.3823931217193604  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.5944383496329897\n",
      "Validation loss:  1.6460161406523104\n",
      "Epoch time -----  2.9044463634490967  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.5971623125530425\n",
      "Validation loss:  1.645061978868618\n",
      "Epoch time -----  2.9466774463653564  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.5998321589969453\n",
      "Validation loss:  1.646999061487283\n",
      "Epoch time -----  2.627375841140747  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.598811251776559\n",
      "Validation loss:  1.6456063970638688\n",
      "Epoch time -----  2.2764899730682373  sec\n",
      "Testing\n",
      "Test accuracy:  38.3\n",
      "Round:  6\n",
      "Using entropy sampling on  33318  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7955\n",
      "Training samples:  7955\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8967922334671021\n",
      "Validation loss:  2.637177418751322\n",
      "Epoch time -----  3.190985679626465  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.637465968132019\n",
      "Validation loss:  1.6388381096967466\n",
      "Epoch time -----  3.0779292583465576  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5252393865585328\n",
      "Validation loss:  1.5759774400929736\n",
      "Epoch time -----  3.129905939102173  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5047067613601686\n",
      "Validation loss:  1.5727117805723931\n",
      "Epoch time -----  3.108309507369995  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.5037194938659668\n",
      "Validation loss:  1.575940550512569\n",
      "Epoch time -----  2.425313711166382  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.4994519748687745\n",
      "Validation loss:  1.5756350034361433\n",
      "Epoch time -----  2.4846010208129883  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.4999825592041016\n",
      "Validation loss:  1.5743283618027997\n",
      "Epoch time -----  3.003213405609131  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.5002354316711426\n",
      "Validation loss:  1.5746777133577188\n",
      "Epoch time -----  3.1037089824676514  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.500950189590454\n",
      "Validation loss:  1.5744411315128302\n",
      "Epoch time -----  2.9761874675750732  sec\n",
      "Testing\n",
      "Test accuracy:  41.53\n",
      "Round:  7\n",
      "Using entropy sampling on  32045  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9241\n",
      "Training samples:  9241\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8305944697610264\n",
      "Validation loss:  1.8495089521833286\n",
      "Epoch time -----  3.2523064613342285  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.531398423786821\n",
      "Validation loss:  1.5964375498947825\n",
      "Epoch time -----  2.6894588470458984  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.4203784178043235\n",
      "Validation loss:  1.5187268629195585\n",
      "Epoch time -----  3.1522226333618164  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3899003793453348\n",
      "Validation loss:  1.5189696451660935\n",
      "Epoch time -----  3.48654842376709  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.3842526863361226\n",
      "Validation loss:  1.5197552321063486\n",
      "Epoch time -----  3.3088037967681885  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.389973208822053\n",
      "Validation loss:  1.5184588318417787\n",
      "Epoch time -----  3.34128737449646  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.3865207252831295\n",
      "Validation loss:  1.5179998236856642\n",
      "Epoch time -----  2.8980541229248047  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.3868840299803635\n",
      "Validation loss:  1.5206864973542038\n",
      "Epoch time -----  2.697758436203003  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.3820487548565041\n",
      "Validation loss:  1.5181538952384026\n",
      "Epoch time -----  3.1456539630889893  sec\n",
      "Testing\n",
      "Test accuracy:  44.81\n",
      "Round:  8\n",
      "Using entropy sampling on  30759  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1624  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10540\n",
      "Training samples:  10540\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7666682084401448\n",
      "Validation loss:  1.6962651371196578\n",
      "Epoch time -----  3.8359153270721436  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.4105459986311017\n",
      "Validation loss:  1.5125221761928243\n",
      "Epoch time -----  3.610607385635376  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.2809327671022126\n",
      "Validation loss:  1.4951151768872692\n",
      "Epoch time -----  3.388913631439209  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.261434131680113\n",
      "Validation loss:  1.4967524542170725\n",
      "Epoch time -----  2.9847676753997803  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.2580465067516673\n",
      "Validation loss:  1.4965113720316796\n",
      "Epoch time -----  3.123335838317871  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.262809531616442\n",
      "Validation loss:  1.4979515003550583\n",
      "Epoch time -----  3.6584630012512207  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.2636423241008412\n",
      "Validation loss:  1.4977976254596832\n",
      "Epoch time -----  3.5138001441955566  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.2584772644620954\n",
      "Validation loss:  1.4985586085896583\n",
      "Epoch time -----  2.8666062355041504  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.2584552876877062\n",
      "Validation loss:  1.49862319572716\n",
      "Epoch time -----  2.935609817504883  sec\n",
      "Testing\n",
      "Test accuracy:  48.67\n",
      "Round:  9\n",
      "Using entropy sampling on  29460  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1641  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11852\n",
      "Training samples:  11852\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6943306538366503\n",
      "Validation loss:  3.6000761909849324\n",
      "Epoch time -----  4.076054811477661  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3264550262240953\n",
      "Validation loss:  1.5117972307144456\n",
      "Epoch time -----  3.8092093467712402  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.1419944484387674\n",
      "Validation loss:  1.4949669260887584\n",
      "Epoch time -----  3.8541345596313477  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.1085748954485821\n",
      "Validation loss:  1.4946070765234103\n",
      "Epoch time -----  3.3191213607788086  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.104214362239325\n",
      "Validation loss:  1.497780348085294\n",
      "Epoch time -----  3.1941897869110107  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.1077285540360275\n",
      "Validation loss:  1.4980838648073234\n",
      "Epoch time -----  4.0134711265563965  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.1081190298321426\n",
      "Validation loss:  1.4962956635815323\n",
      "Epoch time -----  3.6889657974243164  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.1044854797342771\n",
      "Validation loss:  1.494755056253664\n",
      "Epoch time -----  3.1012704372406006  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.1095999363929994\n",
      "Validation loss:  1.4999536385961398\n",
      "Epoch time -----  3.073861837387085  sec\n",
      "Testing\n",
      "Test accuracy:  50.85\n",
      "Round:  10\n",
      "Using entropy sampling on  28148  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1657  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13178\n",
      "Training samples:  13178\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5857145097649212\n",
      "Validation loss:  1.902276128720326\n",
      "Epoch time -----  4.347326040267944  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.1038766957602455\n",
      "Validation loss:  1.528860269838078\n",
      "Epoch time -----  3.920931577682495  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8830575673904234\n",
      "Validation loss:  1.552720835634098\n",
      "Epoch time -----  3.379091739654541  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.8444129943268971\n",
      "Validation loss:  1.556488667703738\n",
      "Epoch time -----  3.3122332096099854  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.842031554979028\n",
      "Validation loss:  1.5578437588017457\n",
      "Epoch time -----  3.7927756309509277  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.8380062441224033\n",
      "Validation loss:  1.5512748797228382\n",
      "Epoch time -----  4.1111650466918945  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.8358155156223519\n",
      "Validation loss:  1.5585934288182837\n",
      "Epoch time -----  3.5536105632781982  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.8347486679993786\n",
      "Validation loss:  1.5543625593944719\n",
      "Epoch time -----  3.407909870147705  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.8403138330260527\n",
      "Validation loss:  1.5531324698666857\n",
      "Epoch time -----  3.6212007999420166  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [13:40<55:24, 415.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  54.82\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.253809243440628\n",
      "Validation loss:  2.267951048103867\n",
      "Epoch time -----  1.3908345699310303  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.1336938440799713\n",
      "Validation loss:  2.2509355712088808\n",
      "Epoch time -----  1.1541833877563477  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.1091230511665344\n",
      "Validation loss:  2.233140779908296\n",
      "Epoch time -----  1.1282424926757812  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.1063641905784607\n",
      "Validation loss:  2.2091432893352145\n",
      "Epoch time -----  1.1335666179656982  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.104549467563629\n",
      "Validation loss:  2.1841464407125097\n",
      "Epoch time -----  1.178431749343872  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  2.1130998134613037\n",
      "Validation loss:  2.1681249642827707\n",
      "Epoch time -----  1.1845269203186035  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  2.109214127063751\n",
      "Validation loss:  2.1616431877111935\n",
      "Epoch time -----  1.3530805110931396  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  2.1056958436965942\n",
      "Validation loss:  2.159035943875647\n",
      "Epoch time -----  1.5022656917572021  sec\n",
      "validation loss minimum, saving model\n",
      "Test accuracy:  10.12\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1712\n",
      "Training samples:  1712\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0850799039558128\n",
      "Validation loss:  2.1474687384951645\n",
      "Epoch time -----  1.9312400817871094  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  2\n",
      "Train loss:  1.930149586112411\n",
      "Validation loss:  2.09393094907141\n",
      "Epoch time -----  1.7916934490203857  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8684979323987607\n",
      "Validation loss:  2.042330031182356\n",
      "Epoch time -----  1.7932541370391846  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8535270381856848\n",
      "Validation loss:  2.037222152302979\n",
      "Epoch time -----  1.6384267807006836  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8468075681615759\n",
      "Validation loss:  2.0364871389546972\n",
      "Epoch time -----  1.3722052574157715  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.8504493324844926\n",
      "Validation loss:  2.0373895593509554\n",
      "Epoch time -----  1.417891502380371  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8492141123171206\n",
      "Validation loss:  2.036518687655212\n",
      "Epoch time -----  1.3676373958587646  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8435324871981587\n",
      "Validation loss:  2.0360000923181034\n",
      "Epoch time -----  1.3184318542480469  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  19.84\n",
      "Round:  2\n",
      "Using entropy sampling on  38288  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2936\n",
      "Training samples:  2936\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.048182192056075\n",
      "Validation loss:  2.142388733329287\n",
      "Epoch time -----  2.2329492568969727  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8704686501751775\n",
      "Validation loss:  1.9486586622371795\n",
      "Epoch time -----  2.101773977279663  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.809603390486344\n",
      "Validation loss:  1.9093941882917076\n",
      "Epoch time -----  2.0436742305755615  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7927319537038389\n",
      "Validation loss:  1.903316208511401\n",
      "Epoch time -----  1.7099976539611816  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7900550080382305\n",
      "Validation loss:  1.9044486565195071\n",
      "Epoch time -----  1.5637381076812744  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7951950949171316\n",
      "Validation loss:  1.9043304753151669\n",
      "Epoch time -----  1.613912582397461  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7928801852723826\n",
      "Validation loss:  1.903726648373209\n",
      "Epoch time -----  1.644958734512329  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7923323330671892\n",
      "Validation loss:  1.9028712959046576\n",
      "Epoch time -----  1.710235357284546  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  27.9\n",
      "Round:  3\n",
      "Using entropy sampling on  37064  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1545  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4174\n",
      "Training samples:  4174\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0404612096873196\n",
      "Validation loss:  3.2095646417824324\n",
      "Epoch time -----  2.5064151287078857  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.885102851824327\n",
      "Validation loss:  1.9124242317904332\n",
      "Epoch time -----  2.232255458831787  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.7801834814476245\n",
      "Validation loss:  1.8415561360158739\n",
      "Epoch time -----  2.3076930046081543  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7782843474185828\n",
      "Validation loss:  1.84123772116983\n",
      "Epoch time -----  2.2402267456054688  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7693556095614578\n",
      "Validation loss:  1.8398078459842948\n",
      "Epoch time -----  2.1265430450439453  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.7674639821052551\n",
      "Validation loss:  1.840016451610881\n",
      "Epoch time -----  1.773179054260254  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7724534833070003\n",
      "Validation loss:  1.84059846932721\n",
      "Epoch time -----  2.0266053676605225  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7741796645251187\n",
      "Validation loss:  1.8391699585944983\n",
      "Epoch time -----  2.3438425064086914  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  30.87\n",
      "Round:  4\n",
      "Using entropy sampling on  35826  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1562  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5423\n",
      "Training samples:  5423\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.997311514966628\n",
      "Validation loss:  2.1367869126568935\n",
      "Epoch time -----  2.4781532287597656  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7959089447470273\n",
      "Validation loss:  1.7967688042646761\n",
      "Epoch time -----  1.9278512001037598  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.694221105295069\n",
      "Validation loss:  1.7387775547185522\n",
      "Epoch time -----  2.0049805641174316  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6784082581015194\n",
      "Validation loss:  1.7324882054784496\n",
      "Epoch time -----  2.0229952335357666  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.67110293192022\n",
      "Validation loss:  1.7295304506447664\n",
      "Epoch time -----  2.2191545963287354  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.6698964413474588\n",
      "Validation loss:  1.732376373497544\n",
      "Epoch time -----  2.5332541465759277  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6747695684432984\n",
      "Validation loss:  1.7355807715920126\n",
      "Epoch time -----  2.4548261165618896  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.666707730293274\n",
      "Validation loss:  1.7302207848069016\n",
      "Epoch time -----  2.3717453479766846  sec\n",
      "Testing\n",
      "Test accuracy:  35.65\n",
      "Round:  5\n",
      "Using entropy sampling on  34577  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6683\n",
      "Training samples:  6683\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0078180744534446\n",
      "Validation loss:  2.3214670860084\n",
      "Epoch time -----  2.4271326065063477  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7459044240769885\n",
      "Validation loss:  1.673563626161806\n",
      "Epoch time -----  2.2144603729248047  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6321549131756736\n",
      "Validation loss:  1.6551042104222973\n",
      "Epoch time -----  2.617053508758545  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.614500956308274\n",
      "Validation loss:  1.6551533352797199\n",
      "Epoch time -----  2.841681957244873  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.612248274258205\n",
      "Validation loss:  1.6560476054051878\n",
      "Epoch time -----  2.7988173961639404  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6150121700196038\n",
      "Validation loss:  1.65407800598509\n",
      "Epoch time -----  2.4286351203918457  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.6094608023053123\n",
      "Validation loss:  1.65423715190523\n",
      "Epoch time -----  2.225175619125366  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6112623464493525\n",
      "Validation loss:  1.6545488583813808\n",
      "Epoch time -----  2.2880923748016357  sec\n",
      "Testing\n",
      "Test accuracy:  39.3\n",
      "Round:  6\n",
      "Using entropy sampling on  33317  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7957\n",
      "Training samples:  7957\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9027363176345826\n",
      "Validation loss:  2.2251261814384704\n",
      "Epoch time -----  3.2011637687683105  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6595620889663696\n",
      "Validation loss:  1.6388803021922993\n",
      "Epoch time -----  3.0568933486938477  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5379272079467774\n",
      "Validation loss:  1.5933572137431733\n",
      "Epoch time -----  3.0500710010528564  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5131284008026122\n",
      "Validation loss:  1.5897808826653061\n",
      "Epoch time -----  2.750323534011841  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.5120752782821656\n",
      "Validation loss:  1.5917725380818555\n",
      "Epoch time -----  2.5830891132354736  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.5140602684020996\n",
      "Validation loss:  1.5901748367175934\n",
      "Epoch time -----  2.566121816635132  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.5138121557235718\n",
      "Validation loss:  1.5874931523754339\n",
      "Epoch time -----  2.7681150436401367  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.5132098903656006\n",
      "Validation loss:  1.5911575646916771\n",
      "Epoch time -----  3.141342878341675  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.5095680985450746\n",
      "Validation loss:  1.590694526957858\n",
      "Epoch time -----  3.081226110458374  sec\n",
      "Testing\n",
      "Test accuracy:  43.7\n",
      "Round:  7\n",
      "Using entropy sampling on  32043  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9243\n",
      "Training samples:  9243\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8315191112715623\n",
      "Validation loss:  3.730190746343819\n",
      "Epoch time -----  2.9043219089508057  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5144841432571412\n",
      "Validation loss:  1.5689480737516075\n",
      "Epoch time -----  2.8813161849975586  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.3705378951697513\n",
      "Validation loss:  1.5405692477135142\n",
      "Epoch time -----  3.445626974105835  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3520078839926883\n",
      "Validation loss:  1.5379083809579255\n",
      "Epoch time -----  3.237293243408203  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.3447810131928017\n",
      "Validation loss:  1.5367392779915197\n",
      "Epoch time -----  3.3319640159606934  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.3488124165041693\n",
      "Validation loss:  1.5370632129110349\n",
      "Epoch time -----  2.753140926361084  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3476512284114444\n",
      "Validation loss:  1.5398129961293214\n",
      "Epoch time -----  2.697000026702881  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.3410516615571646\n",
      "Validation loss:  1.5387401968050913\n",
      "Epoch time -----  3.1538658142089844  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.3483477715788217\n",
      "Validation loss:  1.5388373075776798\n",
      "Epoch time -----  3.377779722213745  sec\n",
      "Testing\n",
      "Test accuracy:  48.08\n",
      "Round:  8\n",
      "Using entropy sampling on  30757  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1624  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10544\n",
      "Training samples:  10544\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7522576303193063\n",
      "Validation loss:  2.16955751446402\n",
      "Epoch time -----  3.094628095626831  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3758902701464566\n",
      "Validation loss:  1.5269598934301145\n",
      "Epoch time -----  2.819451093673706  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.2194642128366413\n",
      "Validation loss:  1.522027486828482\n",
      "Epoch time -----  2.7572996616363525  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.1858907388918327\n",
      "Validation loss:  1.5188480368845023\n",
      "Epoch time -----  3.6838200092315674  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.1817582495284804\n",
      "Validation loss:  1.5192625184727322\n",
      "Epoch time -----  3.6206297874450684  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.185304829568574\n",
      "Validation loss:  1.5226595044895341\n",
      "Epoch time -----  2.905168056488037  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.1803859602321278\n",
      "Validation loss:  1.5210260042719022\n",
      "Epoch time -----  2.769146680831909  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.1864686994841604\n",
      "Validation loss:  1.5233259136509743\n",
      "Epoch time -----  2.829432249069214  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.1835647355426442\n",
      "Validation loss:  1.522599971598121\n",
      "Epoch time -----  3.548271894454956  sec\n",
      "Testing\n",
      "Test accuracy:  51.01\n",
      "Round:  9\n",
      "Using entropy sampling on  29456  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1640  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11856\n",
      "Training samples:  11856\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6654922173869224\n",
      "Validation loss:  7.203094883329549\n",
      "Epoch time -----  3.9967212677001953  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3240005056704245\n",
      "Validation loss:  1.630395554433203\n",
      "Epoch time -----  3.1024646759033203  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.0875810830182926\n",
      "Validation loss:  1.5163935479844453\n",
      "Epoch time -----  3.0115199089050293  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.049542224214923\n",
      "Validation loss:  1.5249947533485995\n",
      "Epoch time -----  3.017496109008789  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.048435849848614\n",
      "Validation loss:  1.523769147077184\n",
      "Epoch time -----  3.838106155395508  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.0407680365988004\n",
      "Validation loss:  1.524167337615019\n",
      "Epoch time -----  3.8090686798095703  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.0452125296797803\n",
      "Validation loss:  1.5192040470755024\n",
      "Epoch time -----  3.123276948928833  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.0433143338849467\n",
      "Validation loss:  1.5227491358283218\n",
      "Epoch time -----  2.9810781478881836  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.0465101852852812\n",
      "Validation loss:  1.5235819224339382\n",
      "Epoch time -----  2.9317054748535156  sec\n",
      "Testing\n",
      "Test accuracy:  53.37\n",
      "Round:  10\n",
      "Using entropy sampling on  28144  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1658  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13182\n",
      "Training samples:  13182\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5677941635395716\n",
      "Validation loss:  1.6041213759950772\n",
      "Epoch time -----  4.320271015167236  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.0742386012401395\n",
      "Validation loss:  1.5467505584097212\n",
      "Epoch time -----  4.104639768600464  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8740371361519527\n",
      "Validation loss:  1.5653338538613288\n",
      "Epoch time -----  3.2641115188598633  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.8532265690923895\n",
      "Validation loss:  1.5680070056277475\n",
      "Epoch time -----  3.2493698596954346  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.8490365211246083\n",
      "Validation loss:  1.5794186406074815\n",
      "Epoch time -----  3.082937240600586  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.8470886552218094\n",
      "Validation loss:  1.56922208807271\n",
      "Epoch time -----  4.09445333480835  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.8510266646598149\n",
      "Validation loss:  1.576138353271849\n",
      "Epoch time -----  4.025179386138916  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.8535402738353581\n",
      "Validation loss:  1.5723671932129344\n",
      "Epoch time -----  3.225036859512329  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.850289262035518\n",
      "Validation loss:  1.5717736850878237\n",
      "Epoch time -----  3.1605165004730225  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [21:15<50:34, 433.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  55.56\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.1837692260742188\n",
      "Validation loss:  2.2647664334364\n",
      "Epoch time -----  1.1154272556304932  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.094023436307907\n",
      "Validation loss:  2.243589402763707\n",
      "Epoch time -----  1.128852367401123  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.057073339819908\n",
      "Validation loss:  2.2233285660956317\n",
      "Epoch time -----  1.1135509014129639  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.065007984638214\n",
      "Validation loss:  2.1987097901143846\n",
      "Epoch time -----  1.0854175090789795  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.059248924255371\n",
      "Validation loss:  2.1746957089490953\n",
      "Epoch time -----  1.0745623111724854  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.0616399347782135\n",
      "Validation loss:  2.160684215035408\n",
      "Epoch time -----  1.111323595046997  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.059902161359787\n",
      "Validation loss:  2.1559547664253573\n",
      "Epoch time -----  1.1331164836883545  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  2.0566975474357605\n",
      "Validation loss:  2.1548403995052263\n",
      "Epoch time -----  1.475132942199707  sec\n",
      "validation loss minimum, saving model\n",
      "Test accuracy:  10.0\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1713\n",
      "Training samples:  1713\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.056770885432208\n",
      "Validation loss:  2.125855522550595\n",
      "Epoch time -----  1.963489294052124  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  2\n",
      "Train loss:  1.8834170721195362\n",
      "Validation loss:  2.0241280338566776\n",
      "Epoch time -----  1.6585545539855957  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.813161920618128\n",
      "Validation loss:  2.0359125182886793\n",
      "Epoch time -----  1.3540968894958496  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.8008299756933142\n",
      "Validation loss:  2.0293569147207173\n",
      "Epoch time -----  1.3505396842956543  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.799750288327535\n",
      "Validation loss:  2.0293486528335865\n",
      "Epoch time -----  1.3593084812164307  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7978152522334345\n",
      "Validation loss:  2.029725353429272\n",
      "Epoch time -----  1.324575662612915  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7979541840376678\n",
      "Validation loss:  2.0287536602870673\n",
      "Epoch time -----  1.29593825340271  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8014101231539692\n",
      "Validation loss:  2.0309314014046054\n",
      "Epoch time -----  1.2808856964111328  sec\n",
      "Testing\n",
      "Test accuracy:  19.07\n",
      "Round:  2\n",
      "Using entropy sampling on  38287  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2937\n",
      "Training samples:  2937\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0390608232954275\n",
      "Validation loss:  2.030092237861293\n",
      "Epoch time -----  2.277186393737793  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8480541887490645\n",
      "Validation loss:  1.9772948102586587\n",
      "Epoch time -----  2.0366320610046387  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.784679519093555\n",
      "Validation loss:  1.9335311355104872\n",
      "Epoch time -----  1.7930934429168701  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.76870684520058\n",
      "Validation loss:  1.9305084510973305\n",
      "Epoch time -----  1.517627477645874  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7669861135275469\n",
      "Validation loss:  1.9310676968021758\n",
      "Epoch time -----  1.5066092014312744  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.765128677305968\n",
      "Validation loss:  1.931034550545322\n",
      "Epoch time -----  1.5421431064605713  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.769736269245977\n",
      "Validation loss:  1.9290055332669787\n",
      "Epoch time -----  1.6065232753753662  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.7621708926947222\n",
      "Validation loss:  1.9305862332605253\n",
      "Epoch time -----  1.6221582889556885  sec\n",
      "Testing\n",
      "Test accuracy:  28.51\n",
      "Round:  3\n",
      "Using entropy sampling on  37063  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1545  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4174\n",
      "Training samples:  4174\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.027264640186772\n",
      "Validation loss:  2.3474753381340365\n",
      "Epoch time -----  2.523573637008667  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8550474047660828\n",
      "Validation loss:  1.9600613512051333\n",
      "Epoch time -----  2.303145408630371  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.7800279494487878\n",
      "Validation loss:  1.8421553783356004\n",
      "Epoch time -----  2.0380115509033203  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7691688483411616\n",
      "Validation loss:  1.8423465832023864\n",
      "Epoch time -----  1.7534692287445068  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.7622323162627942\n",
      "Validation loss:  1.84312538508397\n",
      "Epoch time -----  1.752729892730713  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.756785806381341\n",
      "Validation loss:  1.8419137707181796\n",
      "Epoch time -----  1.6850569248199463  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.767254782445503\n",
      "Validation loss:  1.8412186119966447\n",
      "Epoch time -----  1.7599611282348633  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.761329811630827\n",
      "Validation loss:  1.840684227123382\n",
      "Epoch time -----  1.8426258563995361  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  30.65\n",
      "Round:  4\n",
      "Using entropy sampling on  35826  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1561  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5422\n",
      "Training samples:  5422\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9922028134850895\n",
      "Validation loss:  2.2074883872536337\n",
      "Epoch time -----  2.8170738220214844  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8065959495656632\n",
      "Validation loss:  1.803688911875342\n",
      "Epoch time -----  2.532017946243286  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.703374664923724\n",
      "Validation loss:  1.7744445724851767\n",
      "Epoch time -----  2.1100070476531982  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6852540058248184\n",
      "Validation loss:  1.7721817273243217\n",
      "Epoch time -----  1.9704318046569824  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.6794173703474158\n",
      "Validation loss:  1.771962382990843\n",
      "Epoch time -----  1.9122576713562012  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.6790891591240378\n",
      "Validation loss:  1.7719009530012775\n",
      "Epoch time -----  1.927661418914795  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.6794976921642528\n",
      "Validation loss:  1.7731817201444298\n",
      "Epoch time -----  1.9547224044799805  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6814009413999669\n",
      "Validation loss:  1.7722593318125246\n",
      "Epoch time -----  2.4818220138549805  sec\n",
      "Testing\n",
      "Test accuracy:  35.74\n",
      "Round:  5\n",
      "Using entropy sampling on  34578  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6682\n",
      "Training samples:  6682\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9909144560496013\n",
      "Validation loss:  1.989067015374542\n",
      "Epoch time -----  2.9166274070739746  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7443216812042963\n",
      "Validation loss:  1.735439864693174\n",
      "Epoch time -----  2.397318124771118  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6328599316733223\n",
      "Validation loss:  1.68719081893848\n",
      "Epoch time -----  2.122908115386963  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6206852629071191\n",
      "Validation loss:  1.682948556675273\n",
      "Epoch time -----  2.131614923477173  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.6185702743984405\n",
      "Validation loss:  1.6832698712683027\n",
      "Epoch time -----  2.2128376960754395  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.614040646098909\n",
      "Validation loss:  1.6837566711340741\n",
      "Epoch time -----  2.2058558464050293  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6164320832207089\n",
      "Validation loss:  1.6825083144910775\n",
      "Epoch time -----  2.162518262863159  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.6143461636134557\n",
      "Validation loss:  1.683750745597159\n",
      "Epoch time -----  2.111299514770508  sec\n",
      "Testing\n",
      "Test accuracy:  40.2\n",
      "Round:  6\n",
      "Using entropy sampling on  33318  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7955\n",
      "Training samples:  7955\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9138268365859985\n",
      "Validation loss:  2.3673287356735035\n",
      "Epoch time -----  2.451984405517578  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6314995288848877\n",
      "Validation loss:  1.748222583418439\n",
      "Epoch time -----  2.8057124614715576  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.5032484502792358\n",
      "Validation loss:  1.5946833677352614\n",
      "Epoch time -----  3.1069376468658447  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.471474006652832\n",
      "Validation loss:  1.5951170032950723\n",
      "Epoch time -----  2.9472150802612305  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.474179307937622\n",
      "Validation loss:  1.594891155601307\n",
      "Epoch time -----  2.3790805339813232  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.4733967666625976\n",
      "Validation loss:  1.5965498723801534\n",
      "Epoch time -----  2.376192808151245  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.469284065246582\n",
      "Validation loss:  1.595056494330145\n",
      "Epoch time -----  2.352137804031372  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.4690136079788207\n",
      "Validation loss:  1.594637346875136\n",
      "Epoch time -----  2.8149311542510986  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  9\n",
      "Train loss:  1.4737065620422363\n",
      "Validation loss:  1.5955156839577256\n",
      "Epoch time -----  3.09155011177063  sec\n",
      "Testing\n",
      "Test accuracy:  45.55\n",
      "Round:  7\n",
      "Using entropy sampling on  32045  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9241\n",
      "Training samples:  9241\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8204666696745775\n",
      "Validation loss:  2.085500276012785\n",
      "Epoch time -----  2.736661195755005  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5015561967060485\n",
      "Validation loss:  1.6780730182198202\n",
      "Epoch time -----  2.5311672687530518  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.3432762803702518\n",
      "Validation loss:  1.547127249134574\n",
      "Epoch time -----  2.5559945106506348  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3043241245993253\n",
      "Validation loss:  1.551566617504047\n",
      "Epoch time -----  3.079977512359619  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.3005912316256556\n",
      "Validation loss:  1.5473622463311358\n",
      "Epoch time -----  3.3324978351593018  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.2994609273713211\n",
      "Validation loss:  1.5480894017371403\n",
      "Epoch time -----  2.998352527618408  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3020655130517893\n",
      "Validation loss:  1.5441781980976177\n",
      "Epoch time -----  2.5500950813293457  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.300909831195042\n",
      "Validation loss:  1.543288149271801\n",
      "Epoch time -----  2.525721788406372  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  9\n",
      "Train loss:  1.301847975007419\n",
      "Validation loss:  1.547823079452393\n",
      "Epoch time -----  2.577418565750122  sec\n",
      "Testing\n",
      "Test accuracy:  48.43\n",
      "Round:  8\n",
      "Using entropy sampling on  30759  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1624  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10540\n",
      "Training samples:  10540\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.737602468692895\n",
      "Validation loss:  1.8868782763268537\n",
      "Epoch time -----  3.787148952484131  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3557933189652183\n",
      "Validation loss:  1.5325486189240862\n",
      "Epoch time -----  3.6417155265808105  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.1880923628807067\n",
      "Validation loss:  1.5314018490967478\n",
      "Epoch time -----  3.0177102088928223  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.1609242009394096\n",
      "Validation loss:  1.5356927233137143\n",
      "Epoch time -----  2.758683443069458  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.1602602330121128\n",
      "Validation loss:  1.5362767858110415\n",
      "Epoch time -----  2.7422831058502197  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.1618474909753511\n",
      "Validation loss:  1.5325770328758628\n",
      "Epoch time -----  3.13398814201355  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.1576663317102374\n",
      "Validation loss:  1.5294716160768156\n",
      "Epoch time -----  3.529371738433838  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.1558263276562546\n",
      "Validation loss:  1.5358736511248692\n",
      "Epoch time -----  3.341737985610962  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.1587796135382218\n",
      "Validation loss:  1.5315593207717701\n",
      "Epoch time -----  2.8522300720214844  sec\n",
      "Testing\n",
      "Test accuracy:  52.38\n",
      "Round:  9\n",
      "Using entropy sampling on  29460  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1640  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11852\n",
      "Training samples:  11852\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.665832863059095\n",
      "Validation loss:  4.133537046468941\n",
      "Epoch time -----  3.240158796310425  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.2299358908848097\n",
      "Validation loss:  1.5790025800656362\n",
      "Epoch time -----  3.137917995452881  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.051748618964226\n",
      "Validation loss:  1.5553477919025787\n",
      "Epoch time -----  3.672590970993042  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.0219355638950103\n",
      "Validation loss:  1.5545740560361534\n",
      "Epoch time -----  3.431241512298584  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.020402015857799\n",
      "Validation loss:  1.5517934329190832\n",
      "Epoch time -----  3.008575916290283  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.0203203401898826\n",
      "Validation loss:  1.5533240107214374\n",
      "Epoch time -----  3.008939743041992  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.0149446805959106\n",
      "Validation loss:  1.5478704332546065\n",
      "Epoch time -----  2.9891839027404785  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.0144830320471077\n",
      "Validation loss:  1.552569102329813\n",
      "Epoch time -----  3.0143444538116455  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.0181813060596425\n",
      "Validation loss:  1.5575019846296614\n",
      "Epoch time -----  3.019871473312378  sec\n",
      "Testing\n",
      "Test accuracy:  53.76\n",
      "Round:  10\n",
      "Using entropy sampling on  28148  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1658  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13178\n",
      "Training samples:  13178\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5484655649916639\n",
      "Validation loss:  1.6927284435102135\n",
      "Epoch time -----  3.4150609970092773  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.0303802481554087\n",
      "Validation loss:  1.6063927738529862\n",
      "Epoch time -----  4.131956100463867  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8254456919373818\n",
      "Validation loss:  1.611231281119547\n",
      "Epoch time -----  3.7573366165161133  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.7955766739775834\n",
      "Validation loss:  1.6125004473765185\n",
      "Epoch time -----  3.263681650161743  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.7954685711166234\n",
      "Validation loss:  1.6115213101077233\n",
      "Epoch time -----  3.240065336227417  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.7951449769214519\n",
      "Validation loss:  1.6137660973390955\n",
      "Epoch time -----  3.989048957824707  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.7914107415861297\n",
      "Validation loss:  1.6145353100861712\n",
      "Epoch time -----  3.9874842166900635  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.7942567108904274\n",
      "Validation loss:  1.611406436391697\n",
      "Epoch time -----  3.4645419120788574  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.7998048307247532\n",
      "Validation loss:  1.6095428535133411\n",
      "Epoch time -----  3.239555597305298  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [28:32<43:31, 435.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  57.23\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.213493227958679\n",
      "Validation loss:  2.2665897554652705\n",
      "Epoch time -----  1.6035444736480713  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.1281228363513947\n",
      "Validation loss:  2.2292071375877236\n",
      "Epoch time -----  1.547544002532959  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.0846216082572937\n",
      "Validation loss:  2.2055372493282244\n",
      "Epoch time -----  1.4999067783355713  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.08567014336586\n",
      "Validation loss:  2.18671872205795\n",
      "Epoch time -----  1.2145271301269531  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.0852614790201187\n",
      "Validation loss:  2.173388068083745\n",
      "Epoch time -----  1.1211051940917969  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.086714416742325\n",
      "Validation loss:  2.167528560966443\n",
      "Epoch time -----  1.1824297904968262  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.086961418390274\n",
      "Validation loss:  2.1664731973295757\n",
      "Epoch time -----  1.253429651260376  sec\n",
      "Epoch:  8\n",
      "Train loss:  2.0862695276737213\n",
      "Validation loss:  2.16677690159743\n",
      "Epoch time -----  1.2073745727539062  sec\n",
      "Test accuracy:  10.0\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1517  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1713\n",
      "Training samples:  1713\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0879810960204512\n",
      "Validation loss:  2.2040397855126934\n",
      "Epoch time -----  2.0894885063171387  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.90398371219635\n",
      "Validation loss:  2.1263104411447125\n",
      "Epoch time -----  1.7459161281585693  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8488221212669655\n",
      "Validation loss:  2.089072177364568\n",
      "Epoch time -----  1.9197754859924316  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8362095091078017\n",
      "Validation loss:  2.0898724915874993\n",
      "Epoch time -----  1.8703432083129883  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.839446195849666\n",
      "Validation loss:  2.0890195400092253\n",
      "Epoch time -----  1.848275899887085  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.8367157777150471\n",
      "Validation loss:  2.0887632711677795\n",
      "Epoch time -----  1.6574554443359375  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.8391644557317097\n",
      "Validation loss:  2.0891231867917783\n",
      "Epoch time -----  1.5348477363586426  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8362522743366383\n",
      "Validation loss:  2.0895422628730724\n",
      "Epoch time -----  1.5343961715698242  sec\n",
      "Testing\n",
      "Test accuracy:  17.52\n",
      "Round:  2\n",
      "Using entropy sampling on  38287  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2937\n",
      "Training samples:  2937\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0455975428871485\n",
      "Validation loss:  2.162184083537691\n",
      "Epoch time -----  2.0741007328033447  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8975475093592769\n",
      "Validation loss:  2.0011490431560834\n",
      "Epoch time -----  2.0995914936065674  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8214895258779111\n",
      "Validation loss:  1.98042694398552\n",
      "Epoch time -----  2.0382497310638428  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.807369097419407\n",
      "Validation loss:  1.97028199198899\n",
      "Epoch time -----  2.038472890853882  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8097257173579673\n",
      "Validation loss:  1.970531546386184\n",
      "Epoch time -----  1.9996702671051025  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.8085881212483281\n",
      "Validation loss:  1.9717428744978207\n",
      "Epoch time -----  2.0738370418548584  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.806707809800687\n",
      "Validation loss:  1.9685986269811155\n",
      "Epoch time -----  2.135202646255493  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.809038475803707\n",
      "Validation loss:  1.9697813889023605\n",
      "Epoch time -----  1.7813501358032227  sec\n",
      "Testing\n",
      "Test accuracy:  24.27\n",
      "Round:  3\n",
      "Using entropy sampling on  37063  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1546  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4174\n",
      "Training samples:  4174\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.045079245711818\n",
      "Validation loss:  2.275171811413613\n",
      "Epoch time -----  2.6393067836761475  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.879886471863949\n",
      "Validation loss:  1.9060331476721795\n",
      "Epoch time -----  2.533313751220703  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7759002699996487\n",
      "Validation loss:  1.8679660224610832\n",
      "Epoch time -----  2.6443564891815186  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7487785870378667\n",
      "Validation loss:  1.8559496000314215\n",
      "Epoch time -----  2.677438974380493  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7532745202382405\n",
      "Validation loss:  1.8578061700626542\n",
      "Epoch time -----  2.5335521697998047  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7441940145059065\n",
      "Validation loss:  1.8578017699490688\n",
      "Epoch time -----  2.560412883758545  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.742587391174201\n",
      "Validation loss:  1.8573499796496835\n",
      "Epoch time -----  2.533501386642456  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7451247681270947\n",
      "Validation loss:  1.8581090246795848\n",
      "Epoch time -----  2.5627737045288086  sec\n",
      "Testing\n",
      "Test accuracy:  31.28\n",
      "Round:  4\n",
      "Using entropy sampling on  35826  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1561  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5422\n",
      "Training samples:  5422\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.041990240882425\n",
      "Validation loss:  2.0305056647889934\n",
      "Epoch time -----  2.617288589477539  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8100252277710858\n",
      "Validation loss:  2.1071763934603163\n",
      "Epoch time -----  2.6511940956115723  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.7126796862658333\n",
      "Validation loss:  1.7579455368078438\n",
      "Epoch time -----  2.7674527168273926  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6888046475017773\n",
      "Validation loss:  1.7576805960600543\n",
      "Epoch time -----  2.600425958633423  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.6865917514352238\n",
      "Validation loss:  1.7569286223429783\n",
      "Epoch time -----  2.322136878967285  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.683110401209663\n",
      "Validation loss:  1.7583075192323916\n",
      "Epoch time -----  2.407583236694336  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6863010897355921\n",
      "Validation loss:  1.7576812444978458\n",
      "Epoch time -----  2.5634593963623047  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6813203432980706\n",
      "Validation loss:  1.7568150242422795\n",
      "Epoch time -----  2.636714458465576  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  33.96\n",
      "Round:  5\n",
      "Using entropy sampling on  34578  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1577  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6683\n",
      "Training samples:  6683\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9511002676827567\n",
      "Validation loss:  2.445374767491772\n",
      "Epoch time -----  2.964839458465576  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7387268713542394\n",
      "Validation loss:  1.6899749564517075\n",
      "Epoch time -----  2.9059908390045166  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6236994243803478\n",
      "Validation loss:  1.6720419309701129\n",
      "Epoch time -----  2.932569980621338  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5992040316263834\n",
      "Validation loss:  1.6701331237319168\n",
      "Epoch time -----  3.156348943710327  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.5991285834993636\n",
      "Validation loss:  1.6697168183174862\n",
      "Epoch time -----  3.234955072402954  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.6028367405846005\n",
      "Validation loss:  1.6704577116449928\n",
      "Epoch time -----  3.0514798164367676  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.598237337384905\n",
      "Validation loss:  1.6702243211163077\n",
      "Epoch time -----  2.7338075637817383  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.600192361786252\n",
      "Validation loss:  1.6685011546323254\n",
      "Epoch time -----  3.0503485202789307  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  40.83\n",
      "Round:  6\n",
      "Using entropy sampling on  33317  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7956\n",
      "Training samples:  7956\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8828456897735595\n",
      "Validation loss:  2.148061995293684\n",
      "Epoch time -----  3.364656448364258  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6316818265914916\n",
      "Validation loss:  1.6348516136218028\n",
      "Epoch time -----  3.735596179962158  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5168952302932739\n",
      "Validation loss:  1.598401357413857\n",
      "Epoch time -----  3.4820680618286133  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.4890204935073852\n",
      "Validation loss:  1.5943642292812372\n",
      "Epoch time -----  3.077176570892334  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.4851062135696411\n",
      "Validation loss:  1.5935702240391143\n",
      "Epoch time -----  3.302276372909546  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.4848180599212646\n",
      "Validation loss:  1.593293702526457\n",
      "Epoch time -----  3.242335557937622  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.4824538431167602\n",
      "Validation loss:  1.593676229191434\n",
      "Epoch time -----  3.096590042114258  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.4824468584060668\n",
      "Validation loss:  1.5945436521700234\n",
      "Epoch time -----  3.1538681983947754  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.4910044898986816\n",
      "Validation loss:  1.5952643672372127\n",
      "Epoch time -----  3.1454644203186035  sec\n",
      "Testing\n",
      "Test accuracy:  44.8\n",
      "Round:  7\n",
      "Using entropy sampling on  32044  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9242\n",
      "Training samples:  9242\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8273478286019686\n",
      "Validation loss:  1.8581301763558844\n",
      "Epoch time -----  3.345278263092041  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5160324129565008\n",
      "Validation loss:  1.5412797495058388\n",
      "Epoch time -----  3.6825132369995117  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.4021015537196193\n",
      "Validation loss:  1.533754277381168\n",
      "Epoch time -----  3.4387738704681396  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.389670362143681\n",
      "Validation loss:  1.5374786481735812\n",
      "Epoch time -----  3.465200185775757  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.386066119424228\n",
      "Validation loss:  1.5374034339455283\n",
      "Epoch time -----  2.815107583999634  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.3832559166283442\n",
      "Validation loss:  1.53739721911728\n",
      "Epoch time -----  3.396375894546509  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.387411039451073\n",
      "Validation loss:  1.537901178287093\n",
      "Epoch time -----  3.3173892498016357  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.3834804033410961\n",
      "Validation loss:  1.5358385584156984\n",
      "Epoch time -----  3.384000062942505  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.3857180891365841\n",
      "Validation loss:  1.5375238041968862\n",
      "Epoch time -----  3.5022506713867188  sec\n",
      "Testing\n",
      "Test accuracy:  47.05\n",
      "Round:  8\n",
      "Using entropy sampling on  30758  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1624  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10541\n",
      "Training samples:  10541\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7625629244428693\n",
      "Validation loss:  1.7357154014004263\n",
      "Epoch time -----  3.4980812072753906  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.4137010155302105\n",
      "Validation loss:  1.554266984295693\n",
      "Epoch time -----  3.0301172733306885  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.2570299025737879\n",
      "Validation loss:  1.5215855282583055\n",
      "Epoch time -----  3.256901979446411  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.2314355842994922\n",
      "Validation loss:  1.5230319184862124\n",
      "Epoch time -----  3.1516811847686768  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.2211812033797755\n",
      "Validation loss:  1.5215604012938821\n",
      "Epoch time -----  3.544433116912842  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.2269339713183316\n",
      "Validation loss:  1.5218116724567048\n",
      "Epoch time -----  3.4644365310668945  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.2231673005855446\n",
      "Validation loss:  1.5224799350568443\n",
      "Epoch time -----  3.578808069229126  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.2238697705846844\n",
      "Validation loss:  1.5221186105612736\n",
      "Epoch time -----  3.582603693008423  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.2237674384406119\n",
      "Validation loss:  1.519875782310583\n",
      "Epoch time -----  3.847294569015503  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  50.97\n",
      "Round:  9\n",
      "Using entropy sampling on  29459  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1640  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11853\n",
      "Training samples:  11853\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.682654450016637\n",
      "Validation loss:  2.2287325251633954\n",
      "Epoch time -----  3.5823588371276855  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3148829667798934\n",
      "Validation loss:  1.534165522854799\n",
      "Epoch time -----  3.841878890991211  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.1281210200120044\n",
      "Validation loss:  1.520439729948712\n",
      "Epoch time -----  3.517390251159668  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.094477617932904\n",
      "Validation loss:  1.5266066497298563\n",
      "Epoch time -----  3.4147531986236572  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.0905178368732493\n",
      "Validation loss:  1.5199054365704774\n",
      "Epoch time -----  3.9111335277557373  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.089419496636237\n",
      "Validation loss:  1.5193524990871454\n",
      "Epoch time -----  3.839259147644043  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.0912030236695403\n",
      "Validation loss:  1.5238910287049166\n",
      "Epoch time -----  3.915968418121338  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.0853226546959212\n",
      "Validation loss:  1.5191656973711245\n",
      "Epoch time -----  3.907625913619995  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  9\n",
      "Train loss:  1.0881530591236648\n",
      "Validation loss:  1.521151070382185\n",
      "Epoch time -----  3.558128595352173  sec\n",
      "Testing\n",
      "Test accuracy:  52.63\n",
      "Round:  10\n",
      "Using entropy sampling on  28147  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1657  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13178\n",
      "Training samples:  13178\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5713849727389881\n",
      "Validation loss:  1.59277737216585\n",
      "Epoch time -----  4.198760986328125  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.1116917058102136\n",
      "Validation loss:  1.5319125276462289\n",
      "Epoch time -----  4.504289627075195  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.9102499542884457\n",
      "Validation loss:  1.5691182161592374\n",
      "Epoch time -----  4.014357805252075  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.8804641406512955\n",
      "Validation loss:  1.5727544392749762\n",
      "Epoch time -----  4.244069576263428  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.8799567442495846\n",
      "Validation loss:  1.5798402990505194\n",
      "Epoch time -----  4.3225483894348145  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.8816495702683347\n",
      "Validation loss:  1.5719647198725657\n",
      "Epoch time -----  4.3393495082855225  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.8769922030782237\n",
      "Validation loss:  1.5712665110636668\n",
      "Epoch time -----  4.393970727920532  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.8761130386185878\n",
      "Validation loss:  1.5799354341379397\n",
      "Epoch time -----  3.568608522415161  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.8780103820620231\n",
      "Validation loss:  1.569669408023737\n",
      "Epoch time -----  3.3524835109710693  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [37:04<38:34, 462.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  55.67\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.167005628347397\n",
      "Validation loss:  2.254892236867528\n",
      "Epoch time -----  1.515573263168335  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.0952612459659576\n",
      "Validation loss:  2.2259038314697848\n",
      "Epoch time -----  1.4345958232879639  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.066608279943466\n",
      "Validation loss:  2.2029110701980104\n",
      "Epoch time -----  1.486572504043579  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.059494435787201\n",
      "Validation loss:  2.1814826719320504\n",
      "Epoch time -----  1.5738725662231445  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.0544442534446716\n",
      "Validation loss:  2.1669893978507657\n",
      "Epoch time -----  1.4053514003753662  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.059943839907646\n",
      "Validation loss:  2.1618776306225236\n",
      "Epoch time -----  1.2554280757904053  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.055853635072708\n",
      "Validation loss:  2.1620303172214776\n",
      "Epoch time -----  1.215019941329956  sec\n",
      "Epoch:  8\n",
      "Train loss:  2.0587626844644547\n",
      "Validation loss:  2.163016870522955\n",
      "Epoch time -----  1.2838258743286133  sec\n",
      "Test accuracy:  10.0\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1713\n",
      "Training samples:  1713\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0508684847089977\n",
      "Validation loss:  2.2394733945275567\n",
      "Epoch time -----  1.5176808834075928  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8512644856064409\n",
      "Validation loss:  2.0449401178177755\n",
      "Epoch time -----  1.6066546440124512  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7880417770809598\n",
      "Validation loss:  2.0385490906466344\n",
      "Epoch time -----  1.6673924922943115  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.775162246492174\n",
      "Validation loss:  2.037897502540783\n",
      "Epoch time -----  1.4414405822753906  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.782778232185929\n",
      "Validation loss:  2.0344047804546963\n",
      "Epoch time -----  1.5553746223449707  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.7859572834438748\n",
      "Validation loss:  2.036531747526424\n",
      "Epoch time -----  1.7094533443450928  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.777459979057312\n",
      "Validation loss:  2.038796096091058\n",
      "Epoch time -----  1.765554666519165  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7775799874906186\n",
      "Validation loss:  2.03600720615144\n",
      "Epoch time -----  1.6993145942687988  sec\n",
      "Testing\n",
      "Test accuracy:  18.33\n",
      "Round:  2\n",
      "Using entropy sampling on  38287  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2937\n",
      "Training samples:  2937\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0350472123726555\n",
      "Validation loss:  2.05674447223639\n",
      "Epoch time -----  1.9825890064239502  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8631302403367085\n",
      "Validation loss:  1.9393752699445008\n",
      "Epoch time -----  1.992595911026001  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.791500529517298\n",
      "Validation loss:  1.8984718740366067\n",
      "Epoch time -----  1.8735630512237549  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7721318447071572\n",
      "Validation loss:  1.8981616823536576\n",
      "Epoch time -----  1.5667521953582764  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.768262997917507\n",
      "Validation loss:  1.8993879541469987\n",
      "Epoch time -----  1.9587419033050537  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7700385062590889\n",
      "Validation loss:  1.9003907571173018\n",
      "Epoch time -----  1.9518768787384033  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7674531185108682\n",
      "Validation loss:  1.8976106112170372\n",
      "Epoch time -----  1.9520187377929688  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.7708635770756265\n",
      "Validation loss:  1.8991211812207653\n",
      "Epoch time -----  1.7349424362182617  sec\n",
      "Testing\n",
      "Test accuracy:  27.79\n",
      "Round:  3\n",
      "Using entropy sampling on  37063  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1545  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4173\n",
      "Training samples:  4173\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0382299838644085\n",
      "Validation loss:  2.147833218240434\n",
      "Epoch time -----  1.7471418380737305  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.942270784667044\n",
      "Validation loss:  1.9532497566976366\n",
      "Epoch time -----  2.001404047012329  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.844329873720805\n",
      "Validation loss:  1.8772814167532952\n",
      "Epoch time -----  1.8732008934020996  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8151738571398186\n",
      "Validation loss:  1.8671384366454593\n",
      "Epoch time -----  1.76955246925354  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8117176926497258\n",
      "Validation loss:  1.8683353746013276\n",
      "Epoch time -----  1.7441773414611816  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.8063315658858328\n",
      "Validation loss:  1.8679145134178696\n",
      "Epoch time -----  1.6818251609802246  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8117227301453098\n",
      "Validation loss:  1.8659554059338417\n",
      "Epoch time -----  1.8191397190093994  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.805508022958582\n",
      "Validation loss:  1.8682489281247376\n",
      "Epoch time -----  2.225355625152588  sec\n",
      "Testing\n",
      "Test accuracy:  30.96\n",
      "Round:  4\n",
      "Using entropy sampling on  35827  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1562  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5422\n",
      "Training samples:  5422\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0076477864209346\n",
      "Validation loss:  1.9463915490800408\n",
      "Epoch time -----  2.7407166957855225  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7794932898353129\n",
      "Validation loss:  1.768609431898518\n",
      "Epoch time -----  2.325880527496338  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6972800226772533\n",
      "Validation loss:  1.7449034680226805\n",
      "Epoch time -----  2.3930704593658447  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6752507181728586\n",
      "Validation loss:  1.7400602648971946\n",
      "Epoch time -----  2.4376180171966553  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.673867508944343\n",
      "Validation loss:  1.7399293510777176\n",
      "Epoch time -----  2.390165328979492  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.6772841930389404\n",
      "Validation loss:  1.7408237555983719\n",
      "Epoch time -----  2.3956222534179688  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6730324100045597\n",
      "Validation loss:  1.741056738385729\n",
      "Epoch time -----  2.045109272003174  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6744457609513226\n",
      "Validation loss:  1.7393608526059776\n",
      "Epoch time -----  1.964900255203247  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  35.87\n",
      "Round:  5\n",
      "Using entropy sampling on  34578  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6682\n",
      "Training samples:  6682\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9490969930376325\n",
      "Validation loss:  2.1247521274408716\n",
      "Epoch time -----  2.5600249767303467  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7266787267866588\n",
      "Validation loss:  1.961118362511799\n",
      "Epoch time -----  2.792991876602173  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.6172423385438466\n",
      "Validation loss:  1.6607649326324463\n",
      "Epoch time -----  2.7246079444885254  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5904371681667508\n",
      "Validation loss:  1.6546784100259186\n",
      "Epoch time -----  2.747101068496704  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.586126753262111\n",
      "Validation loss:  1.6549510447083005\n",
      "Epoch time -----  2.6801843643188477  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.583229923248291\n",
      "Validation loss:  1.6580167705086386\n",
      "Epoch time -----  2.449719190597534  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.5857090609414237\n",
      "Validation loss:  1.656539947363981\n",
      "Epoch time -----  2.3507070541381836  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.5835687750861758\n",
      "Validation loss:  1.6567451232557844\n",
      "Epoch time -----  2.3697049617767334  sec\n",
      "Testing\n",
      "Test accuracy:  38.43\n",
      "Round:  6\n",
      "Using entropy sampling on  33318  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1594  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7958\n",
      "Training samples:  7958\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9074404020309448\n",
      "Validation loss:  1.9902485457195598\n",
      "Epoch time -----  2.6028075218200684  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6276187877655028\n",
      "Validation loss:  1.621961352931466\n",
      "Epoch time -----  2.4490859508514404  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5156594705581665\n",
      "Validation loss:  1.5882834818712466\n",
      "Epoch time -----  2.8565869331359863  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.4944762353897094\n",
      "Validation loss:  1.5851972232199019\n",
      "Epoch time -----  2.7337353229522705  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.4969154577255248\n",
      "Validation loss:  1.583768190092342\n",
      "Epoch time -----  2.893238067626953  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.4970202817916871\n",
      "Validation loss:  1.5851386079363003\n",
      "Epoch time -----  2.875523090362549  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.4985852375030517\n",
      "Validation loss:  1.5835174413243676\n",
      "Epoch time -----  2.8103654384613037  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.4986796255111694\n",
      "Validation loss:  1.587245859158267\n",
      "Epoch time -----  2.584843397140503  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.4912149982452392\n",
      "Validation loss:  1.5862957770657387\n",
      "Epoch time -----  2.4896814823150635  sec\n",
      "Testing\n",
      "Test accuracy:  42.06\n",
      "Round:  7\n",
      "Using entropy sampling on  32042  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1609  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9245\n",
      "Training samples:  9245\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8491551144369718\n",
      "Validation loss:  2.1525139482158004\n",
      "Epoch time -----  2.5718047618865967  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5353969878163831\n",
      "Validation loss:  1.5772327359314937\n",
      "Epoch time -----  3.2734298706054688  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.4056256031167917\n",
      "Validation loss:  1.5470610219202223\n",
      "Epoch time -----  3.114536762237549  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3831651079243628\n",
      "Validation loss:  1.547259759751095\n",
      "Epoch time -----  3.0080039501190186  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.380761611872706\n",
      "Validation loss:  1.5488316784998415\n",
      "Epoch time -----  3.345616102218628  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.3835787066097918\n",
      "Validation loss:  1.5455847606537447\n",
      "Epoch time -----  3.1948790550231934  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.382086521181567\n",
      "Validation loss:  1.5477511784073654\n",
      "Epoch time -----  2.727466106414795  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.383800614291224\n",
      "Validation loss:  1.5495149671651756\n",
      "Epoch time -----  2.9996721744537354  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.381264750710849\n",
      "Validation loss:  1.5455374801234834\n",
      "Epoch time -----  3.128181219100952  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  45.5\n",
      "Round:  8\n",
      "Using entropy sampling on  30755  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1625  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10546\n",
      "Training samples:  10546\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7548375534288811\n",
      "Validation loss:  1.7720613509986052\n",
      "Epoch time -----  3.2987496852874756  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3953150322943022\n",
      "Validation loss:  1.5305141058697063\n",
      "Epoch time -----  3.6478958129882812  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.259328845053008\n",
      "Validation loss:  1.5294097441776542\n",
      "Epoch time -----  3.138000965118408  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.2328716704339693\n",
      "Validation loss:  1.5270671457242055\n",
      "Epoch time -----  3.020346164703369  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.2338289065794512\n",
      "Validation loss:  1.530612892406002\n",
      "Epoch time -----  2.8334312438964844  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.234162415157665\n",
      "Validation loss:  1.5313504638185926\n",
      "Epoch time -----  3.297210454940796  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.2276282631989681\n",
      "Validation loss:  1.5298938515839304\n",
      "Epoch time -----  3.3983330726623535  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.2282193173061717\n",
      "Validation loss:  1.5279338701515441\n",
      "Epoch time -----  2.9601950645446777  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.2352344671885171\n",
      "Validation loss:  1.5281337757778775\n",
      "Epoch time -----  3.190913677215576  sec\n",
      "Testing\n",
      "Test accuracy:  48.63\n",
      "Round:  9\n",
      "Using entropy sampling on  29454  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1640  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11858\n",
      "Training samples:  11858\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6836679891873432\n",
      "Validation loss:  2.2276079890075002\n",
      "Epoch time -----  3.023547887802124  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.2740676098613328\n",
      "Validation loss:  1.5847813574371823\n",
      "Epoch time -----  3.42342209815979  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.0476244889920758\n",
      "Validation loss:  1.561861318387803\n",
      "Epoch time -----  3.895235538482666  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.0055461468235138\n",
      "Validation loss:  1.5626637552194536\n",
      "Epoch time -----  3.740346670150757  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.9979654307006508\n",
      "Validation loss:  1.563181031281781\n",
      "Epoch time -----  3.9732329845428467  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.9963801099408057\n",
      "Validation loss:  1.5664239628299785\n",
      "Epoch time -----  3.39079213142395  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.9941696111233004\n",
      "Validation loss:  1.5673043545643994\n",
      "Epoch time -----  3.3215763568878174  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.9939172473005069\n",
      "Validation loss:  1.5621863922495751\n",
      "Epoch time -----  3.9545085430145264  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.9943718224443415\n",
      "Validation loss:  1.5655993640802468\n",
      "Epoch time -----  3.5447611808776855  sec\n",
      "Testing\n",
      "Test accuracy:  50.83\n",
      "Round:  10\n",
      "Using entropy sampling on  28142  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1658  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13184\n",
      "Training samples:  13184\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.56082114143279\n",
      "Validation loss:  1.7833102645388075\n",
      "Epoch time -----  4.0994250774383545  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.0474482774734497\n",
      "Validation loss:  1.6313435173338386\n",
      "Epoch time -----  3.726369619369507  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8086746855846887\n",
      "Validation loss:  1.627133790095141\n",
      "Epoch time -----  3.5078721046447754  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.7683650395534571\n",
      "Validation loss:  1.634447935660174\n",
      "Epoch time -----  4.112666606903076  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.7611934580270526\n",
      "Validation loss:  1.6273482897479064\n",
      "Epoch time -----  4.097229242324829  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.7622824994105737\n",
      "Validation loss:  1.6332449279013712\n",
      "Epoch time -----  4.026915550231934  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.7630669571531629\n",
      "Validation loss:  1.6273370939455214\n",
      "Epoch time -----  3.960878610610962  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.7658459981089657\n",
      "Validation loss:  1.6329239720751525\n",
      "Epoch time -----  3.5289034843444824  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.7670064461462706\n",
      "Validation loss:  1.635079912319305\n",
      "Epoch time -----  3.2826385498046875  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [44:35<30:34, 458.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  53.45\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.221104681491852\n",
      "Validation loss:  2.259842711649123\n",
      "Epoch time -----  1.5800487995147705  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.1290893852710724\n",
      "Validation loss:  2.2405310785694486\n",
      "Epoch time -----  1.483032464981079  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.102239489555359\n",
      "Validation loss:  2.216689776463114\n",
      "Epoch time -----  1.4906198978424072  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.1034827828407288\n",
      "Validation loss:  2.1909555295470415\n",
      "Epoch time -----  1.4161019325256348  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.1022523939609528\n",
      "Validation loss:  2.1676718201606895\n",
      "Epoch time -----  1.4710593223571777  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.0997027456760406\n",
      "Validation loss:  2.153139090082448\n",
      "Epoch time -----  1.3259334564208984  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  2.1015413999557495\n",
      "Validation loss:  2.1464987909717923\n",
      "Epoch time -----  1.1108121871948242  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  2.0993093252182007\n",
      "Validation loss:  2.1436516297091344\n",
      "Epoch time -----  1.2148406505584717  sec\n",
      "validation loss minimum, saving model\n",
      "Test accuracy:  10.0\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1712\n",
      "Training samples:  1712\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.169700101569847\n",
      "Validation loss:  2.1891386144480127\n",
      "Epoch time -----  1.5292859077453613  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.0264101955625744\n",
      "Validation loss:  2.083340382120412\n",
      "Epoch time -----  1.30647611618042  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.9613621764712863\n",
      "Validation loss:  2.064409201312217\n",
      "Epoch time -----  1.3578050136566162  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.9600049787097507\n",
      "Validation loss:  2.062422204169498\n",
      "Epoch time -----  1.7379717826843262  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.9593571380332664\n",
      "Validation loss:  2.0628997823994633\n",
      "Epoch time -----  1.7212576866149902  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.9572347976543285\n",
      "Validation loss:  2.063617417007495\n",
      "Epoch time -----  1.7316615581512451  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.9600451213342172\n",
      "Validation loss:  2.0635047604323953\n",
      "Epoch time -----  1.6943552494049072  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.9530911180708144\n",
      "Validation loss:  2.0632368546382636\n",
      "Epoch time -----  1.3590543270111084  sec\n",
      "Testing\n",
      "Test accuracy:  22.37\n",
      "Round:  2\n",
      "Using entropy sampling on  38288  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2936\n",
      "Training samples:  2936\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.102189973644588\n",
      "Validation loss:  2.1195888921713375\n",
      "Epoch time -----  2.0205600261688232  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.9345248263815176\n",
      "Validation loss:  2.0212312883632197\n",
      "Epoch time -----  1.730970859527588  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8721946840700896\n",
      "Validation loss:  1.9190922626264535\n",
      "Epoch time -----  1.751277208328247  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.85444322358007\n",
      "Validation loss:  1.916643321893777\n",
      "Epoch time -----  1.705263614654541  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8556234188701795\n",
      "Validation loss:  1.9149865906709318\n",
      "Epoch time -----  1.9766101837158203  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.851444140724514\n",
      "Validation loss:  1.9159536589482786\n",
      "Epoch time -----  2.0133140087127686  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8544803805973218\n",
      "Validation loss:  1.9156266944423603\n",
      "Epoch time -----  1.8874485492706299  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.851493415625199\n",
      "Validation loss:  1.9171321012411908\n",
      "Epoch time -----  1.9794456958770752  sec\n",
      "Testing\n",
      "Test accuracy:  28.88\n",
      "Round:  3\n",
      "Using entropy sampling on  37064  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1546  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4172\n",
      "Training samples:  4172\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.1114941401915117\n",
      "Validation loss:  2.1722915499073685\n",
      "Epoch time -----  2.3750836849212646  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.9522813811446682\n",
      "Validation loss:  1.9100162770338118\n",
      "Epoch time -----  2.2465929985046387  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.865500246033524\n",
      "Validation loss:  1.854334339214738\n",
      "Epoch time -----  2.2150166034698486  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8430341735030666\n",
      "Validation loss:  1.8551503624885706\n",
      "Epoch time -----  1.9800732135772705  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.8414725209727432\n",
      "Validation loss:  1.8533353517009954\n",
      "Epoch time -----  1.938248634338379  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.840098874135451\n",
      "Validation loss:  1.858212563642271\n",
      "Epoch time -----  2.0231072902679443  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8396003661733684\n",
      "Validation loss:  1.853753086108311\n",
      "Epoch time -----  2.076503038406372  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8389648849313909\n",
      "Validation loss:  1.8544778003814115\n",
      "Epoch time -----  2.108948230743408  sec\n",
      "Testing\n",
      "Test accuracy:  32.71\n",
      "Round:  4\n",
      "Using entropy sampling on  35828  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1561  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5420\n",
      "Training samples:  5420\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.017395896070144\n",
      "Validation loss:  2.4830145501786736\n",
      "Epoch time -----  2.7860052585601807  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8104296109255622\n",
      "Validation loss:  1.7559539611172523\n",
      "Epoch time -----  2.408750534057617  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7128466914681828\n",
      "Validation loss:  1.739675919721081\n",
      "Epoch time -----  2.3251492977142334  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6960107046015123\n",
      "Validation loss:  1.7313732903474455\n",
      "Epoch time -----  2.1055402755737305  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.6928548223832074\n",
      "Validation loss:  1.7315197643960358\n",
      "Epoch time -----  2.012838125228882  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6993963325724881\n",
      "Validation loss:  1.7313012302301491\n",
      "Epoch time -----  1.9993641376495361  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.6938197893254898\n",
      "Validation loss:  1.7337183716950144\n",
      "Epoch time -----  1.7804527282714844  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6910793935551363\n",
      "Validation loss:  1.7309384383973043\n",
      "Epoch time -----  2.387352705001831  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  37.6\n",
      "Round:  5\n",
      "Using entropy sampling on  34580  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6680\n",
      "Training samples:  6680\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9886206025169009\n",
      "Validation loss:  2.2586666611349506\n",
      "Epoch time -----  2.8292324542999268  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7538462252843947\n",
      "Validation loss:  1.6853795203433675\n",
      "Epoch time -----  2.3996965885162354  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6427007323219662\n",
      "Validation loss:  1.6728925697363106\n",
      "Epoch time -----  2.215731620788574  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6241338752564929\n",
      "Validation loss:  1.6675665750625028\n",
      "Epoch time -----  2.1127657890319824  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.6196890240623838\n",
      "Validation loss:  1.6693891415930098\n",
      "Epoch time -----  2.6577975749969482  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.622636712165106\n",
      "Validation loss:  1.6691525923977992\n",
      "Epoch time -----  2.667663097381592  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6150608153570265\n",
      "Validation loss:  1.6707081825110563\n",
      "Epoch time -----  2.601094961166382  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6153662772405715\n",
      "Validation loss:  1.6688309718089498\n",
      "Epoch time -----  2.6446897983551025  sec\n",
      "Testing\n",
      "Test accuracy:  39.7\n",
      "Round:  6\n",
      "Using entropy sampling on  33320  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7953\n",
      "Training samples:  7953\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8978566417694092\n",
      "Validation loss:  2.2081866765477853\n",
      "Epoch time -----  3.2571980953216553  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6401127281188965\n",
      "Validation loss:  1.640883009904509\n",
      "Epoch time -----  2.634880304336548  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.512279109954834\n",
      "Validation loss:  1.5893871085658955\n",
      "Epoch time -----  2.5622401237487793  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.4829981336593627\n",
      "Validation loss:  1.5815377668210655\n",
      "Epoch time -----  2.51531982421875  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.4781790132522583\n",
      "Validation loss:  1.583529473869664\n",
      "Epoch time -----  2.977031707763672  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.4795364904403687\n",
      "Validation loss:  1.5841629710167078\n",
      "Epoch time -----  2.9209187030792236  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.4733475584983826\n",
      "Validation loss:  1.5865915079785\n",
      "Epoch time -----  2.805756092071533  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.4761534786224366\n",
      "Validation loss:  1.58256201683336\n",
      "Epoch time -----  2.981638193130493  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.4738327693939208\n",
      "Validation loss:  1.582568626494924\n",
      "Epoch time -----  2.6951935291290283  sec\n",
      "Testing\n",
      "Test accuracy:  45.03\n",
      "Round:  7\n",
      "Using entropy sampling on  32047  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9240\n",
      "Training samples:  9240\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8356544190439685\n",
      "Validation loss:  2.3479261869078227\n",
      "Epoch time -----  2.7082180976867676  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5356592901821795\n",
      "Validation loss:  1.5512429263181746\n",
      "Epoch time -----  2.8832168579101562  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.3770079440083998\n",
      "Validation loss:  1.5138536144973367\n",
      "Epoch time -----  2.5055317878723145  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3469113966514323\n",
      "Validation loss:  1.513999642839857\n",
      "Epoch time -----  2.8019444942474365  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.3403509230449282\n",
      "Validation loss:  1.5164185223306061\n",
      "Epoch time -----  3.0509066581726074  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.3372867140276679\n",
      "Validation loss:  1.514517583664815\n",
      "Epoch time -----  3.127596378326416  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3386747943943944\n",
      "Validation loss:  1.5157943128780196\n",
      "Epoch time -----  3.0255894660949707  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.337246588180805\n",
      "Validation loss:  1.5139114522630241\n",
      "Epoch time -----  2.8408355712890625  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.342869939475224\n",
      "Validation loss:  1.5131047903352481\n",
      "Epoch time -----  3.125263214111328  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  49.26\n",
      "Round:  8\n",
      "Using entropy sampling on  30760  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1625  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10541\n",
      "Training samples:  10541\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.74885332439885\n",
      "Validation loss:  1.8327812495504974\n",
      "Epoch time -----  3.069314956665039  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3746933684204563\n",
      "Validation loss:  1.5021820106324117\n",
      "Epoch time -----  2.904200792312622  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.2184487722136759\n",
      "Validation loss:  1.4960790811830265\n",
      "Epoch time -----  2.6800642013549805  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.1867277130936131\n",
      "Validation loss:  1.49798251413236\n",
      "Epoch time -----  2.978518009185791  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.1786740906310804\n",
      "Validation loss:  1.4980391901769456\n",
      "Epoch time -----  3.4339988231658936  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.1802682244416438\n",
      "Validation loss:  1.4950629784043428\n",
      "Epoch time -----  3.182373523712158  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.1777503288153446\n",
      "Validation loss:  1.4963656792974775\n",
      "Epoch time -----  2.78782320022583  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.1796145504171198\n",
      "Validation loss:  1.4981497571726514\n",
      "Epoch time -----  3.349702835083008  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.1816134904370164\n",
      "Validation loss:  1.496585352405621\n",
      "Epoch time -----  3.506521701812744  sec\n",
      "Testing\n",
      "Test accuracy:  52.74\n",
      "Round:  9\n",
      "Using entropy sampling on  29459  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1642  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11855\n",
      "Training samples:  11855\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.677234882949501\n",
      "Validation loss:  3.157155096151267\n",
      "Epoch time -----  3.4326391220092773  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.2531376618851897\n",
      "Validation loss:  1.4971682668491533\n",
      "Epoch time -----  3.422790288925171  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.0403334902178856\n",
      "Validation loss:  1.5113474867146486\n",
      "Epoch time -----  3.4071037769317627  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.9963977609270362\n",
      "Validation loss:  1.5134122124902762\n",
      "Epoch time -----  3.189174175262451  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.9868921153647925\n",
      "Validation loss:  1.5185307070707819\n",
      "Epoch time -----  3.4813060760498047  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.9849052961154651\n",
      "Validation loss:  1.5124782475696248\n",
      "Epoch time -----  3.453141689300537  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.9832098830130792\n",
      "Validation loss:  1.5081401566031631\n",
      "Epoch time -----  3.254018783569336  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.9849458346443791\n",
      "Validation loss:  1.5096430243200558\n",
      "Epoch time -----  3.1975555419921875  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.9900057761258977\n",
      "Validation loss:  1.5114408583398078\n",
      "Epoch time -----  3.1808102130889893  sec\n",
      "Testing\n",
      "Test accuracy:  55.51\n",
      "Round:  10\n",
      "Using entropy sampling on  28145  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1657  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13180\n",
      "Training samples:  13180\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5911200633905467\n",
      "Validation loss:  1.8200091571564887\n",
      "Epoch time -----  3.7208609580993652  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.0481931740797839\n",
      "Validation loss:  1.5796304390688611\n",
      "Epoch time -----  3.7648792266845703  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8337308084501803\n",
      "Validation loss:  1.577974020675489\n",
      "Epoch time -----  3.8171255588531494  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.7911554835375073\n",
      "Validation loss:  1.574493939329864\n",
      "Epoch time -----  3.787540912628174  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.7880856406341479\n",
      "Validation loss:  1.5745692340431698\n",
      "Epoch time -----  3.1949334144592285  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.7904277662339719\n",
      "Validation loss:  1.5806311771368524\n",
      "Epoch time -----  3.1621978282928467  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.7877701370461473\n",
      "Validation loss:  1.5777655558980954\n",
      "Epoch time -----  3.883270263671875  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.7861763453020633\n",
      "Validation loss:  1.5771528558366616\n",
      "Epoch time -----  3.657635450363159  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.7885771957994665\n",
      "Validation loss:  1.5767078183259173\n",
      "Epoch time -----  4.215801000595093  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [52:03<22:45, 455.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  57.64\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.202015519142151\n",
      "Validation loss:  2.264537727756865\n",
      "Epoch time -----  1.204230785369873  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.0867367684841156\n",
      "Validation loss:  2.229306019035874\n",
      "Epoch time -----  1.1575710773468018  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.0645262598991394\n",
      "Validation loss:  2.2020818260824604\n",
      "Epoch time -----  1.3126866817474365  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.061665490269661\n",
      "Validation loss:  2.1767049109100536\n",
      "Epoch time -----  1.484788417816162  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.0641864091157913\n",
      "Validation loss:  2.1574265835391486\n",
      "Epoch time -----  1.4649312496185303  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.0588610470294952\n",
      "Validation loss:  2.147281505499676\n",
      "Epoch time -----  1.458390712738037  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.065975472331047\n",
      "Validation loss:  2.143473916752323\n",
      "Epoch time -----  1.4274687767028809  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  2.064251720905304\n",
      "Validation loss:  2.142371865594463\n",
      "Epoch time -----  1.4461724758148193  sec\n",
      "validation loss minimum, saving model\n",
      "Test accuracy:  10.0\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1714\n",
      "Training samples:  1714\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0324445256480463\n",
      "Validation loss:  2.182879600555274\n",
      "Epoch time -----  1.7512264251708984  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8370628665994715\n",
      "Validation loss:  2.0755178738551536\n",
      "Epoch time -----  1.7534749507904053  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7649573661662914\n",
      "Validation loss:  2.0153995410651917\n",
      "Epoch time -----  1.5803823471069336  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7500968685856573\n",
      "Validation loss:  2.014662925604802\n",
      "Epoch time -----  1.405794382095337  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7519116710733484\n",
      "Validation loss:  2.0193711337010574\n",
      "Epoch time -----  1.289379358291626  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7580308870032981\n",
      "Validation loss:  2.015754213758335\n",
      "Epoch time -----  1.4197707176208496  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.747921387354533\n",
      "Validation loss:  2.0146365530171972\n",
      "Epoch time -----  1.3665223121643066  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.758051421907213\n",
      "Validation loss:  2.014833265808737\n",
      "Epoch time -----  1.343874216079712  sec\n",
      "Testing\n",
      "Test accuracy:  17.16\n",
      "Round:  2\n",
      "Using entropy sampling on  38286  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1531  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2939\n",
      "Training samples:  2939\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.040668837402178\n",
      "Validation loss:  2.3482463693922493\n",
      "Epoch time -----  1.805370807647705  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.0301736282265703\n",
      "Validation loss:  2.036680034771087\n",
      "Epoch time -----  1.5423624515533447  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.891438243181809\n",
      "Validation loss:  2.0069612674652393\n",
      "Epoch time -----  1.5126476287841797  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8691317957380544\n",
      "Validation loss:  2.0049429729485966\n",
      "Epoch time -----  1.985541820526123  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8658762833346492\n",
      "Validation loss:  2.0060862340744894\n",
      "Epoch time -----  1.9310939311981201  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.8627303812814795\n",
      "Validation loss:  2.0041283080532293\n",
      "Epoch time -----  1.847182035446167  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.8701357789661572\n",
      "Validation loss:  2.0075156749433773\n",
      "Epoch time -----  1.7936277389526367  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8652735533921614\n",
      "Validation loss:  2.0046000822334533\n",
      "Epoch time -----  1.8977015018463135  sec\n",
      "Testing\n",
      "Test accuracy:  18.44\n",
      "Round:  3\n",
      "Using entropy sampling on  37061  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1545  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4175\n",
      "Training samples:  4175\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.018338660399119\n",
      "Validation loss:  2.3971135631488387\n",
      "Epoch time -----  2.3794031143188477  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.86278041565057\n",
      "Validation loss:  2.1352203233986145\n",
      "Epoch time -----  2.2202677726745605  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.7618651101083467\n",
      "Validation loss:  1.8419476671583335\n",
      "Epoch time -----  2.098520278930664  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7448071024634622\n",
      "Validation loss:  1.8350428805989065\n",
      "Epoch time -----  1.806190013885498  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7451653516653813\n",
      "Validation loss:  1.8395102532805911\n",
      "Epoch time -----  2.2236123085021973  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7413280028285403\n",
      "Validation loss:  1.839998618812318\n",
      "Epoch time -----  2.255356550216675  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7453045122551196\n",
      "Validation loss:  1.8430046139249376\n",
      "Epoch time -----  2.2261500358581543  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7373107400807468\n",
      "Validation loss:  1.8465041916841154\n",
      "Epoch time -----  1.9680781364440918  sec\n",
      "Testing\n",
      "Test accuracy:  32.12\n",
      "Round:  4\n",
      "Using entropy sampling on  35825  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1561  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5423\n",
      "Training samples:  5423\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.983671265489915\n",
      "Validation loss:  2.0048444164786368\n",
      "Epoch time -----  2.0580251216888428  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.764823902354521\n",
      "Validation loss:  1.7611674442412748\n",
      "Epoch time -----  2.268521785736084  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6983905960531795\n",
      "Validation loss:  1.7327229976654053\n",
      "Epoch time -----  2.1149404048919678  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6804296886219698\n",
      "Validation loss:  1.7337345294891648\n",
      "Epoch time -----  2.202192544937134  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.6779839641907637\n",
      "Validation loss:  1.7333726313463442\n",
      "Epoch time -----  2.3178491592407227  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6722004764220293\n",
      "Validation loss:  1.7319294821684528\n",
      "Epoch time -----  2.3891549110412598  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.6742360577863806\n",
      "Validation loss:  1.732413260800064\n",
      "Epoch time -----  2.331789493560791  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6804103234234977\n",
      "Validation loss:  1.73285888790325\n",
      "Epoch time -----  2.5125865936279297  sec\n",
      "Testing\n",
      "Test accuracy:  36.84\n",
      "Round:  5\n",
      "Using entropy sampling on  34577  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6683\n",
      "Training samples:  6683\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9381813934871128\n",
      "Validation loss:  2.4688355968256666\n",
      "Epoch time -----  2.5988481044769287  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6968556370053973\n",
      "Validation loss:  1.703514856138047\n",
      "Epoch time -----  2.7060964107513428  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5980186326163155\n",
      "Validation loss:  1.6456201919324838\n",
      "Epoch time -----  2.6833925247192383  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5758665357317243\n",
      "Validation loss:  1.645925114109258\n",
      "Epoch time -----  2.458242416381836  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.5696603173301333\n",
      "Validation loss:  1.6463775209560516\n",
      "Epoch time -----  2.8043019771575928  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.5697315499896094\n",
      "Validation loss:  1.6441551386171085\n",
      "Epoch time -----  2.9479026794433594  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.5731955902917045\n",
      "Validation loss:  1.6459293934949644\n",
      "Epoch time -----  2.6153883934020996  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.566001956803458\n",
      "Validation loss:  1.6480008029634026\n",
      "Epoch time -----  2.376826763153076  sec\n",
      "Testing\n",
      "Test accuracy:  40.75\n",
      "Round:  6\n",
      "Using entropy sampling on  33317  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7957\n",
      "Training samples:  7957\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8843553047180175\n",
      "Validation loss:  2.687875831203096\n",
      "Epoch time -----  2.519986391067505  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6439611806869507\n",
      "Validation loss:  1.7147246811799943\n",
      "Epoch time -----  2.9289004802703857  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.5297993183135987\n",
      "Validation loss:  1.592386190299016\n",
      "Epoch time -----  2.8842623233795166  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.502852056503296\n",
      "Validation loss:  1.5914246648739858\n",
      "Epoch time -----  2.5596818923950195  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.5049002828598022\n",
      "Validation loss:  1.5926476458834995\n",
      "Epoch time -----  2.8279836177825928  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.5027376251220703\n",
      "Validation loss:  1.5952429475298353\n",
      "Epoch time -----  2.8798928260803223  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.5066989803314208\n",
      "Validation loss:  1.5946962772660953\n",
      "Epoch time -----  2.7078781127929688  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.5032294988632202\n",
      "Validation loss:  1.5929059473572262\n",
      "Epoch time -----  2.4541852474212646  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.506584285736084\n",
      "Validation loss:  1.5908758093597024\n",
      "Epoch time -----  2.9056873321533203  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  43.67\n",
      "Round:  7\n",
      "Using entropy sampling on  32043  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9243\n",
      "Training samples:  9243\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8240964527787833\n",
      "Validation loss:  2.5066285763576532\n",
      "Epoch time -----  3.2158637046813965  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5392990901552397\n",
      "Validation loss:  1.5634438915617148\n",
      "Epoch time -----  3.193236827850342  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.4121301872976895\n",
      "Validation loss:  1.5387996382014766\n",
      "Epoch time -----  2.5064756870269775  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3908490345395845\n",
      "Validation loss:  1.5436300221522143\n",
      "Epoch time -----  2.960146427154541  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.3921035651502938\n",
      "Validation loss:  1.545881424739862\n",
      "Epoch time -----  3.2377846240997314  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.389676389200934\n",
      "Validation loss:  1.5424326392495709\n",
      "Epoch time -----  2.924795627593994  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3869641073818864\n",
      "Validation loss:  1.5437461972995927\n",
      "Epoch time -----  2.9935195446014404  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.3872714782583302\n",
      "Validation loss:  1.5480062824905299\n",
      "Epoch time -----  3.281834840774536  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.3902224877784992\n",
      "Validation loss:  1.5430597241517086\n",
      "Epoch time -----  3.1683287620544434  sec\n",
      "Testing\n",
      "Test accuracy:  47.15\n",
      "Round:  8\n",
      "Using entropy sampling on  30757  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1624  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10543\n",
      "Training samples:  10543\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7661133954019257\n",
      "Validation loss:  1.747058677065904\n",
      "Epoch time -----  3.673736095428467  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.4096855055202138\n",
      "Validation loss:  1.5468678983153812\n",
      "Epoch time -----  3.0408084392547607  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.2681162198384603\n",
      "Validation loss:  1.5193083870942425\n",
      "Epoch time -----  2.9730160236358643  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.245684352426818\n",
      "Validation loss:  1.5293829274025692\n",
      "Epoch time -----  3.078568696975708  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.2378815441420583\n",
      "Validation loss:  1.5237962766817421\n",
      "Epoch time -----  2.6564667224884033  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.2394592971512766\n",
      "Validation loss:  1.5251926958181297\n",
      "Epoch time -----  3.1539084911346436  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.2421903324849677\n",
      "Validation loss:  1.5263916140149354\n",
      "Epoch time -----  3.213179349899292  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.2395797740329395\n",
      "Validation loss:  1.5241236884123202\n",
      "Epoch time -----  3.3677146434783936  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.242450110840075\n",
      "Validation loss:  1.5257235241543716\n",
      "Epoch time -----  3.4207260608673096  sec\n",
      "Testing\n",
      "Test accuracy:  50.17\n",
      "Round:  9\n",
      "Using entropy sampling on  29457  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1640  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11855\n",
      "Training samples:  11855\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6944827764264998\n",
      "Validation loss:  2.470598911783498\n",
      "Epoch time -----  3.7534823417663574  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3462264598697744\n",
      "Validation loss:  1.6967958568767378\n",
      "Epoch time -----  3.5680675506591797  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.133880990487273\n",
      "Validation loss:  1.5142671052058032\n",
      "Epoch time -----  4.1997761726379395  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.0899804686346362\n",
      "Validation loss:  1.5175605397315541\n",
      "Epoch time -----  3.825251817703247  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.0879376469760813\n",
      "Validation loss:  1.5159004600184738\n",
      "Epoch time -----  3.7201027870178223  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.0858440379942618\n",
      "Validation loss:  1.5126141841244545\n",
      "Epoch time -----  4.013512134552002  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.0921235257579434\n",
      "Validation loss:  1.5202344542096375\n",
      "Epoch time -----  3.5213797092437744  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.0849126096694701\n",
      "Validation loss:  1.5173127446204993\n",
      "Epoch time -----  4.192095518112183  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.0866880929598244\n",
      "Validation loss:  1.5191653845416513\n",
      "Epoch time -----  3.9092092514038086  sec\n",
      "Testing\n",
      "Test accuracy:  53.39\n",
      "Round:  10\n",
      "Using entropy sampling on  28145  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1657  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13180\n",
      "Training samples:  13180\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5807547395669141\n",
      "Validation loss:  1.7248657934225289\n",
      "Epoch time -----  4.022750377655029  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.1144128381048592\n",
      "Validation loss:  1.5455049397839102\n",
      "Epoch time -----  4.116843938827515  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8936111374387463\n",
      "Validation loss:  1.5774461562466469\n",
      "Epoch time -----  3.9831461906433105  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.853296872770902\n",
      "Validation loss:  1.5770479311608965\n",
      "Epoch time -----  4.102794408798218  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.8455895474813517\n",
      "Validation loss:  1.5783134023095393\n",
      "Epoch time -----  4.096193552017212  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.8463667634042721\n",
      "Validation loss:  1.579386488647218\n",
      "Epoch time -----  3.8503289222717285  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.8477630794626995\n",
      "Validation loss:  1.5804261158985697\n",
      "Epoch time -----  4.166893720626831  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.8486565496157674\n",
      "Validation loss:  1.5782285875575557\n",
      "Epoch time -----  4.011190414428711  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.8481434372443597\n",
      "Validation loss:  1.583871293979086\n",
      "Epoch time -----  4.506884336471558  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [59:39<15:11, 455.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  56.0\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.2118634581565857\n",
      "Validation loss:  2.260362945544492\n",
      "Epoch time -----  1.1965301036834717  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.1170172095298767\n",
      "Validation loss:  2.233053937839095\n",
      "Epoch time -----  1.2543339729309082  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.0935187190771103\n",
      "Validation loss:  2.21297620360259\n",
      "Epoch time -----  1.2196593284606934  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.0918032824993134\n",
      "Validation loss:  2.192677593534919\n",
      "Epoch time -----  1.2757511138916016  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.0901928395032883\n",
      "Validation loss:  2.175097717601023\n",
      "Epoch time -----  1.1887335777282715  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.0901505053043365\n",
      "Validation loss:  2.166179722281778\n",
      "Epoch time -----  1.106201410293579  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.085939198732376\n",
      "Validation loss:  2.1638498124043655\n",
      "Epoch time -----  1.3891961574554443  sec\n",
      "Epoch:  8\n",
      "Train loss:  2.091522663831711\n",
      "Validation loss:  2.1638459460750505\n",
      "Epoch time -----  1.533277988433838  sec\n",
      "Test accuracy:  12.59\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1712\n",
      "Training samples:  1712\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0769650671217175\n",
      "Validation loss:  2.1375161682724193\n",
      "Epoch time -----  1.8608732223510742  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  2\n",
      "Train loss:  1.9609276762715093\n",
      "Validation loss:  2.069090669322166\n",
      "Epoch time -----  1.6927952766418457  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.871917269848011\n",
      "Validation loss:  2.0542451257159\n",
      "Epoch time -----  1.6506540775299072  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8725146761646978\n",
      "Validation loss:  2.0530075222063977\n",
      "Epoch time -----  1.7813303470611572  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8718518371935244\n",
      "Validation loss:  2.0529032565985514\n",
      "Epoch time -----  1.7961959838867188  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.86554929945204\n",
      "Validation loss:  2.052743124354417\n",
      "Epoch time -----  1.4764137268066406  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.8656048995477181\n",
      "Validation loss:  2.0556387392578612\n",
      "Epoch time -----  1.5231742858886719  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8679077801881012\n",
      "Validation loss:  2.0538329326423113\n",
      "Epoch time -----  1.5284881591796875  sec\n",
      "Testing\n",
      "Test accuracy:  18.19\n",
      "Round:  2\n",
      "Using entropy sampling on  38288  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2936\n",
      "Training samples:  2936\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.078767317792644\n",
      "Validation loss:  2.126917255152563\n",
      "Epoch time -----  1.8649396896362305  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.910510521868001\n",
      "Validation loss:  1.9592561668651118\n",
      "Epoch time -----  1.7460072040557861  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8351722074591594\n",
      "Validation loss:  1.9334084592807066\n",
      "Epoch time -----  1.8019182682037354  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.8230861814125725\n",
      "Validation loss:  1.9329125418025217\n",
      "Epoch time -----  1.7247419357299805  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8212669414022695\n",
      "Validation loss:  1.9328386016712067\n",
      "Epoch time -----  2.0078682899475098  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.8166806775590647\n",
      "Validation loss:  1.9329546219224383\n",
      "Epoch time -----  2.006279468536377  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8158576566240061\n",
      "Validation loss:  1.9324527492948398\n",
      "Epoch time -----  2.018625497817993  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.8201669558234836\n",
      "Validation loss:  1.932820776465592\n",
      "Epoch time -----  1.9746365547180176  sec\n",
      "Testing\n",
      "Test accuracy:  29.37\n",
      "Round:  3\n",
      "Using entropy sampling on  37064  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1545  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4172\n",
      "Training samples:  4172\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.08658648259712\n",
      "Validation loss:  2.0694062109965428\n",
      "Epoch time -----  2.4623422622680664  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.868972032359152\n",
      "Validation loss:  1.8823094808371963\n",
      "Epoch time -----  1.7829792499542236  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7775844931602478\n",
      "Validation loss:  1.8031407632645529\n",
      "Epoch time -----  1.9580769538879395  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7497058637214429\n",
      "Validation loss:  1.8018246334829149\n",
      "Epoch time -----  2.004556655883789  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7601012262431057\n",
      "Validation loss:  1.8021095459628258\n",
      "Epoch time -----  2.410043478012085  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7417763598037488\n",
      "Validation loss:  1.8024629794867935\n",
      "Epoch time -----  2.3824315071105957  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7436159740794788\n",
      "Validation loss:  1.801311356246851\n",
      "Epoch time -----  2.353180170059204  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.7444285425272854\n",
      "Validation loss:  1.8005305551419593\n",
      "Epoch time -----  2.3024277687072754  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  33.58\n",
      "Round:  4\n",
      "Using entropy sampling on  35828  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1561  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5420\n",
      "Training samples:  5420\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.002430765769061\n",
      "Validation loss:  2.6125674505901944\n",
      "Epoch time -----  1.9893927574157715  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7915245406767901\n",
      "Validation loss:  1.7817669742426294\n",
      "Epoch time -----  2.446763038635254  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7101136305752922\n",
      "Validation loss:  1.7407593210791326\n",
      "Epoch time -----  2.4907710552215576  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.6871110144783468\n",
      "Validation loss:  1.7445336944738012\n",
      "Epoch time -----  2.4859490394592285  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.6820925572339227\n",
      "Validation loss:  1.7412101561856117\n",
      "Epoch time -----  2.509183645248413  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.686049783931059\n",
      "Validation loss:  1.7424772294463626\n",
      "Epoch time -----  2.4743525981903076  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6872058714137357\n",
      "Validation loss:  1.7437481333495706\n",
      "Epoch time -----  2.405395746231079  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6825770293965059\n",
      "Validation loss:  1.7433002708823817\n",
      "Epoch time -----  2.367629051208496  sec\n",
      "Testing\n",
      "Test accuracy:  36.3\n",
      "Round:  5\n",
      "Using entropy sampling on  34580  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6680\n",
      "Training samples:  6680\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9550107399622598\n",
      "Validation loss:  1.9536149281605033\n",
      "Epoch time -----  2.6406171321868896  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.7135463385354905\n",
      "Validation loss:  1.7614143821084576\n",
      "Epoch time -----  2.5347747802734375  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.6274161747523717\n",
      "Validation loss:  1.65292311549946\n",
      "Epoch time -----  2.7589914798736572  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5993371225538708\n",
      "Validation loss:  1.6485579135311637\n",
      "Epoch time -----  2.8977086544036865  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.601055603935605\n",
      "Validation loss:  1.6497892710813291\n",
      "Epoch time -----  2.7838056087493896  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6034261033648536\n",
      "Validation loss:  1.652706676987326\n",
      "Epoch time -----  2.8811514377593994  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.6043293998354957\n",
      "Validation loss:  1.6500823027009417\n",
      "Epoch time -----  2.8914906978607178  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.6012291874204363\n",
      "Validation loss:  1.6515935537921396\n",
      "Epoch time -----  2.7459635734558105  sec\n",
      "Testing\n",
      "Test accuracy:  40.29\n",
      "Round:  6\n",
      "Using entropy sampling on  33320  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1593  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7956\n",
      "Training samples:  7956\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8873547983169556\n",
      "Validation loss:  2.2943042653381447\n",
      "Epoch time -----  3.2834508419036865  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.6433022966384887\n",
      "Validation loss:  1.6887976189327847\n",
      "Epoch time -----  3.214465856552124  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.5102239837646485\n",
      "Validation loss:  1.59214254473425\n",
      "Epoch time -----  2.974837064743042  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.4933354053497314\n",
      "Validation loss:  1.5735190818264226\n",
      "Epoch time -----  3.4047114849090576  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.4827615480422973\n",
      "Validation loss:  1.5750109352123964\n",
      "Epoch time -----  3.3053810596466064  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.4857654800415039\n",
      "Validation loss:  1.5755296816491777\n",
      "Epoch time -----  3.156769037246704  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.4848383779525758\n",
      "Validation loss:  1.5759153920374098\n",
      "Epoch time -----  3.0163400173187256  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.4829667224884033\n",
      "Validation loss:  1.5787539444151957\n",
      "Epoch time -----  2.888498544692993  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.4772160701751709\n",
      "Validation loss:  1.5746742859008207\n",
      "Epoch time -----  2.5284345149993896  sec\n",
      "Testing\n",
      "Test accuracy:  44.5\n",
      "Round:  7\n",
      "Using entropy sampling on  32044  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9242\n",
      "Training samples:  9242\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8282525021454383\n",
      "Validation loss:  2.2362180902699755\n",
      "Epoch time -----  3.1837055683135986  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.531185794698781\n",
      "Validation loss:  1.6846204176070585\n",
      "Epoch time -----  3.4176175594329834  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.3881047289946984\n",
      "Validation loss:  1.5158487421691798\n",
      "Epoch time -----  3.5210392475128174  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3562907169605123\n",
      "Validation loss:  1.515362173888334\n",
      "Epoch time -----  3.063004970550537  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.35877334331644\n",
      "Validation loss:  1.5150847321103333\n",
      "Epoch time -----  3.4208996295928955  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.3504269287503998\n",
      "Validation loss:  1.5160360017399879\n",
      "Epoch time -----  3.5221121311187744  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3551536321640014\n",
      "Validation loss:  1.5137593503210955\n",
      "Epoch time -----  3.166733980178833  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.3506233461971942\n",
      "Validation loss:  1.5158551726371619\n",
      "Epoch time -----  3.0451860427856445  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.3529727746700417\n",
      "Validation loss:  1.5139750067595463\n",
      "Epoch time -----  2.8371143341064453  sec\n",
      "Testing\n",
      "Test accuracy:  48.61\n",
      "Round:  8\n",
      "Using entropy sampling on  30758  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1625  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10542\n",
      "Training samples:  10542\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.760521091114391\n",
      "Validation loss:  1.9234935872873682\n",
      "Epoch time -----  3.292146682739258  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.4030264529314909\n",
      "Validation loss:  1.5279744696465267\n",
      "Epoch time -----  3.465557098388672  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.2420356837185946\n",
      "Validation loss:  1.50679190599235\n",
      "Epoch time -----  3.617734432220459  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.2148700136126893\n",
      "Validation loss:  1.501576805570323\n",
      "Epoch time -----  3.5467348098754883  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.2068285616961392\n",
      "Validation loss:  1.50187075289951\n",
      "Epoch time -----  3.6669187545776367  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.19947893149925\n",
      "Validation loss:  1.5016977035315933\n",
      "Epoch time -----  3.3651649951934814  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.2016414259419297\n",
      "Validation loss:  1.499717997137908\n",
      "Epoch time -----  3.349383592605591  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.203695916407036\n",
      "Validation loss:  1.49822433663022\n",
      "Epoch time -----  3.210432767868042  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  9\n",
      "Train loss:  1.2042825745813774\n",
      "Validation loss:  1.500621021932857\n",
      "Epoch time -----  3.402256488800049  sec\n",
      "Testing\n",
      "Test accuracy:  51.9\n",
      "Round:  9\n",
      "Using entropy sampling on  29458  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1640  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11854\n",
      "Training samples:  11854\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6673511837118415\n",
      "Validation loss:  3.169206620781285\n",
      "Epoch time -----  3.8652660846710205  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.2690897202619942\n",
      "Validation loss:  1.5761333248417848\n",
      "Epoch time -----  3.8789665699005127  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.0831078303757535\n",
      "Validation loss:  1.5079713566288067\n",
      "Epoch time -----  3.727884292602539  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.0473421837693901\n",
      "Validation loss:  1.5174214297039494\n",
      "Epoch time -----  3.658883571624756  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.0447355739531978\n",
      "Validation loss:  1.5148644940868305\n",
      "Epoch time -----  3.8202662467956543  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.0453311323478658\n",
      "Validation loss:  1.5195251680483484\n",
      "Epoch time -----  4.021595001220703  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.0401178656085845\n",
      "Validation loss:  1.5149994663372162\n",
      "Epoch time -----  3.6693482398986816  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.046468444408909\n",
      "Validation loss:  1.5119662300036971\n",
      "Epoch time -----  4.026430130004883  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.0444130279043669\n",
      "Validation loss:  1.517868455807874\n",
      "Epoch time -----  3.9362518787384033  sec\n",
      "Testing\n",
      "Test accuracy:  53.67\n",
      "Round:  10\n",
      "Using entropy sampling on  28146  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1658  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13181\n",
      "Training samples:  13181\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.5852526608601356\n",
      "Validation loss:  1.668805508097266\n",
      "Epoch time -----  4.569810628890991  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.088931941002318\n",
      "Validation loss:  1.627010155635275\n",
      "Epoch time -----  4.260867357254028  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8655358743899076\n",
      "Validation loss:  1.5743800899025742\n",
      "Epoch time -----  4.677125930786133  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.8257493813639706\n",
      "Validation loss:  1.5796305601763878\n",
      "Epoch time -----  4.28048038482666  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.8243582882348773\n",
      "Validation loss:  1.585642901195842\n",
      "Epoch time -----  4.156646490097046  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.8246782766383829\n",
      "Validation loss:  1.5789416774063354\n",
      "Epoch time -----  4.251120090484619  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.8210026506081368\n",
      "Validation loss:  1.5797193976724224\n",
      "Epoch time -----  4.4031288623809814  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.8234892420977065\n",
      "Validation loss:  1.581403943763417\n",
      "Epoch time -----  4.450354099273682  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.8242763795898956\n",
      "Validation loss:  1.5772221912244322\n",
      "Epoch time -----  4.3736371994018555  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [1:07:33<07:41, 461.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  55.47\n",
      "Using CUDA\n",
      "Test accuracy:  10.0\n",
      "Training samples:  500\n",
      "Epoch:  1\n",
      "Train loss:  2.235523223876953\n",
      "Validation loss:  2.259222884087046\n",
      "Epoch time -----  1.2982869148254395  sec\n",
      "Epoch:  2\n",
      "Train loss:  2.141802579164505\n",
      "Validation loss:  2.2384363967142287\n",
      "Epoch time -----  1.1870031356811523  sec\n",
      "Epoch:  3\n",
      "Train loss:  2.112857908010483\n",
      "Validation loss:  2.2150325213268305\n",
      "Epoch time -----  1.436584234237671  sec\n",
      "Epoch:  4\n",
      "Train loss:  2.1055480986833572\n",
      "Validation loss:  2.192189836198357\n",
      "Epoch time -----  1.4850375652313232  sec\n",
      "Epoch:  5\n",
      "Train loss:  2.1095860451459885\n",
      "Validation loss:  2.1746254969554344\n",
      "Epoch time -----  1.4497079849243164  sec\n",
      "Epoch:  6\n",
      "Train loss:  2.107419013977051\n",
      "Validation loss:  2.1655352343419554\n",
      "Epoch time -----  1.5066468715667725  sec\n",
      "Epoch:  7\n",
      "Train loss:  2.1046688854694366\n",
      "Validation loss:  2.162829286733251\n",
      "Epoch time -----  1.6078369617462158  sec\n",
      "Epoch:  8\n",
      "Train loss:  2.1091699600219727\n",
      "Validation loss:  2.1623422522453746\n",
      "Epoch time -----  1.424556016921997  sec\n",
      "Test accuracy:  10.89\n",
      "Round:  1\n",
      "Using entropy sampling on  39500  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1893  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1515  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  1713\n",
      "Training samples:  1713\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.059611920957212\n",
      "Validation loss:  2.1017349138381376\n",
      "Epoch time -----  1.735898494720459  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  2\n",
      "Train loss:  1.8575005928675334\n",
      "Validation loss:  2.0355431205907446\n",
      "Epoch time -----  1.3866965770721436  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.8081186789053458\n",
      "Validation loss:  2.0200227461043436\n",
      "Epoch time -----  1.48752760887146  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.803642471631368\n",
      "Validation loss:  2.0189691387164364\n",
      "Epoch time -----  1.3582661151885986  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.8049590278554846\n",
      "Validation loss:  2.0186800341697255\n",
      "Epoch time -----  1.2657272815704346  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  6\n",
      "Train loss:  1.8115574342233163\n",
      "Validation loss:  2.0189517842736215\n",
      "Epoch time -----  1.3692972660064697  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.8023572188836556\n",
      "Validation loss:  2.018996862848853\n",
      "Epoch time -----  1.3644218444824219  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.8088800244861178\n",
      "Validation loss:  2.0196001066523754\n",
      "Epoch time -----  1.4745662212371826  sec\n",
      "Testing\n",
      "Test accuracy:  20.05\n",
      "Round:  2\n",
      "Using entropy sampling on  38287  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1912  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1530  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  2937\n",
      "Training samples:  2937\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.046629716520724\n",
      "Validation loss:  2.1261496467954792\n",
      "Epoch time -----  2.0650696754455566  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.863511412040047\n",
      "Validation loss:  1.9462110464739952\n",
      "Epoch time -----  1.9449396133422852  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7869321418845134\n",
      "Validation loss:  1.8969541218630068\n",
      "Epoch time -----  1.9937636852264404  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.773951126181561\n",
      "Validation loss:  1.891955074231336\n",
      "Epoch time -----  1.917076587677002  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7663000666576882\n",
      "Validation loss:  1.894537789047144\n",
      "Epoch time -----  1.4869027137756348  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.770048351391502\n",
      "Validation loss:  1.893685952872987\n",
      "Epoch time -----  1.4285728931427002  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7664026384768279\n",
      "Validation loss:  1.8920288594665042\n",
      "Epoch time -----  1.4750418663024902  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7670979033345762\n",
      "Validation loss:  1.8928701224600433\n",
      "Epoch time -----  1.4280996322631836  sec\n",
      "Testing\n",
      "Test accuracy:  29.86\n",
      "Round:  3\n",
      "Using entropy sampling on  37063  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1931  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1546  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  4173\n",
      "Training samples:  4173\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0572889772328464\n",
      "Validation loss:  3.0764524055894014\n",
      "Epoch time -----  1.9650921821594238  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.9085446072347236\n",
      "Validation loss:  1.886547902587113\n",
      "Epoch time -----  1.733964443206787  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.7925888805678396\n",
      "Validation loss:  1.8160451202635552\n",
      "Epoch time -----  1.5827069282531738  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7650809197714834\n",
      "Validation loss:  1.8120465673458803\n",
      "Epoch time -----  2.1077640056610107  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7634219111818257\n",
      "Validation loss:  1.8121174801686766\n",
      "Epoch time -----  2.236597776412964  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.7592048861763694\n",
      "Validation loss:  1.81187960068891\n",
      "Epoch time -----  2.3182740211486816  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.765744185808933\n",
      "Validation loss:  1.8152170052194292\n",
      "Epoch time -----  2.1669766902923584  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.7737582488493486\n",
      "Validation loss:  1.814789221544934\n",
      "Epoch time -----  1.8712685108184814  sec\n",
      "Testing\n",
      "Test accuracy:  32.16\n",
      "Round:  4\n",
      "Using entropy sampling on  35827  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1951  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1564  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  5424\n",
      "Training samples:  5424\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  2.0284756786683027\n",
      "Validation loss:  2.0053431365140684\n",
      "Epoch time -----  2.3055994510650635  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.8126173720640295\n",
      "Validation loss:  1.8686592358692435\n",
      "Epoch time -----  2.3284943103790283  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.725440904673408\n",
      "Validation loss:  1.7256929259391347\n",
      "Epoch time -----  2.5153138637542725  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.7062216520309448\n",
      "Validation loss:  1.7245730617243773\n",
      "Epoch time -----  2.7403807640075684  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.7031104382346658\n",
      "Validation loss:  1.725807837619903\n",
      "Epoch time -----  2.7847135066986084  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.6997011240790871\n",
      "Validation loss:  1.7250992264717249\n",
      "Epoch time -----  2.463944435119629  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.7044321775436402\n",
      "Validation loss:  1.7245588355762944\n",
      "Epoch time -----  2.689391613006592  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  8\n",
      "Train loss:  1.7050657244289622\n",
      "Validation loss:  1.7244757968149367\n",
      "Epoch time -----  2.829867124557495  sec\n",
      "validation loss minimum, saving model\n",
      "Testing\n",
      "Test accuracy:  35.69\n",
      "Round:  5\n",
      "Using entropy sampling on  34576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1970  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1576  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  6684\n",
      "Training samples:  6684\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.9634116184143793\n",
      "Validation loss:  2.488555130685211\n",
      "Epoch time -----  2.958263635635376  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.701571974300203\n",
      "Validation loss:  1.6793370262073104\n",
      "Epoch time -----  2.7039451599121094  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.6084274632590159\n",
      "Validation loss:  1.6462087775491605\n",
      "Epoch time -----  2.726689100265503  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.5918504851205009\n",
      "Validation loss:  1.645235397253826\n",
      "Epoch time -----  2.6051762104034424  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.5955232211521693\n",
      "Validation loss:  1.645357922383934\n",
      "Epoch time -----  2.610363245010376  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.596809282756987\n",
      "Validation loss:  1.6464473996192786\n",
      "Epoch time -----  2.6379096508026123  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.5922701483681088\n",
      "Validation loss:  1.646280518762625\n",
      "Epoch time -----  3.0502517223358154  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.5966370434988113\n",
      "Validation loss:  1.6486526446737302\n",
      "Epoch time -----  2.9915387630462646  sec\n",
      "Testing\n",
      "Test accuracy:  39.71\n",
      "Round:  6\n",
      "Using entropy sampling on  33316  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  1990  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1592  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  7957\n",
      "Training samples:  7957\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8996018943786621\n",
      "Validation loss:  2.353936032125145\n",
      "Epoch time -----  3.0500144958496094  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.618823410987854\n",
      "Validation loss:  1.6413604370348014\n",
      "Epoch time -----  2.8451361656188965  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  3\n",
      "Train loss:  1.5101703367233277\n",
      "Validation loss:  1.5753666967343374\n",
      "Epoch time -----  2.8531360626220703  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.4848987712860107\n",
      "Validation loss:  1.5741555250374375\n",
      "Epoch time -----  3.143373727798462  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.4833750886917114\n",
      "Validation loss:  1.576081596362363\n",
      "Epoch time -----  3.222235679626465  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.483942720413208\n",
      "Validation loss:  1.5732662943518085\n",
      "Epoch time -----  3.0714595317840576  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  7\n",
      "Train loss:  1.4780028772354126\n",
      "Validation loss:  1.5745373197421906\n",
      "Epoch time -----  2.959806203842163  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.4858055982589722\n",
      "Validation loss:  1.5728455789529594\n",
      "Epoch time -----  2.862719774246216  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  9\n",
      "Train loss:  1.4810338439941406\n",
      "Validation loss:  1.5733216423897227\n",
      "Epoch time -----  3.3502068519592285  sec\n",
      "Testing\n",
      "Test accuracy:  42.05\n",
      "Round:  7\n",
      "Using entropy sampling on  32043  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2010  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1608  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  9243\n",
      "Training samples:  9243\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.8219962235154776\n",
      "Validation loss:  2.062392156594878\n",
      "Epoch time -----  3.5270044803619385  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.5341114315493354\n",
      "Validation loss:  1.6062795447695786\n",
      "Epoch time -----  3.574300765991211  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.3899068569314892\n",
      "Validation loss:  1.5315675317861472\n",
      "Epoch time -----  3.1820054054260254  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.3674792322619207\n",
      "Validation loss:  1.5303781176828275\n",
      "Epoch time -----  3.4556825160980225  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  5\n",
      "Train loss:  1.367029906141347\n",
      "Validation loss:  1.5340269629363041\n",
      "Epoch time -----  3.510225772857666  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.369664743850971\n",
      "Validation loss:  1.533078995859547\n",
      "Epoch time -----  3.3205246925354004  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.3678426545241784\n",
      "Validation loss:  1.5329271368919664\n",
      "Epoch time -----  3.450538158416748  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.3609693856074891\n",
      "Validation loss:  1.533127280936879\n",
      "Epoch time -----  3.191056489944458  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.363423415710186\n",
      "Validation loss:  1.530852901707789\n",
      "Epoch time -----  2.8044605255126953  sec\n",
      "Testing\n",
      "Test accuracy:  47.41\n",
      "Round:  8\n",
      "Using entropy sampling on  30757  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n",
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2030  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1624  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  10542\n",
      "Training samples:  10542\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.7450460144967743\n",
      "Validation loss:  1.7197379010498144\n",
      "Epoch time -----  3.57364821434021  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.3782028472784793\n",
      "Validation loss:  1.549386917405827\n",
      "Epoch time -----  3.403594732284546  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.226671987952608\n",
      "Validation loss:  1.4930236878668426\n",
      "Epoch time -----  3.201404094696045  sec\n",
      "validation loss minimum, saving model\n",
      "Epoch:  4\n",
      "Train loss:  1.2020338878487096\n",
      "Validation loss:  1.4964298161731404\n",
      "Epoch time -----  2.988095998764038  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.1953597816553982\n",
      "Validation loss:  1.5003958955691878\n",
      "Epoch time -----  2.947810411453247  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.195791894016844\n",
      "Validation loss:  1.4979405110808695\n",
      "Epoch time -----  3.3196730613708496  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.1962551109718553\n",
      "Validation loss:  1.496794699103969\n",
      "Epoch time -----  3.42933988571167  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.1943908117034219\n",
      "Validation loss:  1.498063154660972\n",
      "Epoch time -----  3.252676248550415  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.1966017043951787\n",
      "Validation loss:  1.4978510938632261\n",
      "Epoch time -----  3.0060830116271973  sec\n",
      "Testing\n",
      "Test accuracy:  51.57\n",
      "Round:  9\n",
      "Using entropy sampling on  29458  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2050  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1641  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  11854\n",
      "Training samples:  11854\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.6861491722445334\n",
      "Validation loss:  2.4949603354095653\n",
      "Epoch time -----  3.762394666671753  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.2725515282282265\n",
      "Validation loss:  1.6152235280935932\n",
      "Epoch time -----  3.916788101196289  sec\n",
      "Epoch:  3\n",
      "Train loss:  1.0606033885350792\n",
      "Validation loss:  1.5265311014120746\n",
      "Epoch time -----  3.431165933609009  sec\n",
      "Epoch:  4\n",
      "Train loss:  1.0142354577459314\n",
      "Validation loss:  1.5362961747843749\n",
      "Epoch time -----  3.151883602142334  sec\n",
      "Epoch:  5\n",
      "Train loss:  1.0043994963810008\n",
      "Validation loss:  1.5328832731884756\n",
      "Epoch time -----  3.426260471343994  sec\n",
      "Epoch:  6\n",
      "Train loss:  1.001227983864405\n",
      "Validation loss:  1.529956262962074\n",
      "Epoch time -----  3.7931716442108154  sec\n",
      "Epoch:  7\n",
      "Train loss:  1.0021267728779906\n",
      "Validation loss:  1.5323422452446762\n",
      "Epoch time -----  3.734879493713379  sec\n",
      "Epoch:  8\n",
      "Train loss:  1.0027128458023071\n",
      "Validation loss:  1.5331647274600473\n",
      "Epoch time -----  3.228029489517212  sec\n",
      "Epoch:  9\n",
      "Train loss:  1.0043519485381343\n",
      "Validation loss:  1.5339360620565474\n",
      "Epoch time -----  3.2127203941345215  sec\n",
      "Testing\n",
      "Test accuracy:  55.23\n",
      "Round:  10\n",
      "Using entropy sampling on  28146  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:383: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(probs).detach().cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using loss sampling on  2071  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "e:\\pratik\\new_marich\\utils.py:652: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_hat = torch.tensor(y_hat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gradient sampling on  1657  points\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pkpra\\AppData\\Local\\Temp/ipykernel_23384/108530465.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(self.Y)[idx]\n",
      "e:\\pratik\\new_marich\\utils.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels.append(torch.tensor(l))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budget:  13179\n",
      "Training samples:  13179\n",
      "Training\n",
      "Epoch:  1\n",
      "Train loss:  1.583406371399037\n",
      "Validation loss:  1.749295481450998\n",
      "Epoch time -----  4.444397211074829  sec\n",
      "Epoch:  2\n",
      "Train loss:  1.0606752584860162\n",
      "Validation loss:  1.5725448693439459\n",
      "Epoch time -----  4.002802848815918  sec\n",
      "Epoch:  3\n",
      "Train loss:  0.8110090019633469\n",
      "Validation loss:  1.5934539429701058\n",
      "Epoch time -----  4.067033529281616  sec\n",
      "Epoch:  4\n",
      "Train loss:  0.7518638488158439\n",
      "Validation loss:  1.6004276264245343\n",
      "Epoch time -----  3.419981002807617  sec\n",
      "Epoch:  5\n",
      "Train loss:  0.7525113702399059\n",
      "Validation loss:  1.6041358789061284\n",
      "Epoch time -----  3.818267583847046  sec\n",
      "Epoch:  6\n",
      "Train loss:  0.7529081728273225\n",
      "Validation loss:  1.60389397971949\n",
      "Epoch time -----  4.2278289794921875  sec\n",
      "Epoch:  7\n",
      "Train loss:  0.7516017576444496\n",
      "Validation loss:  1.5998064389654025\n",
      "Epoch time -----  4.122826099395752  sec\n",
      "Epoch:  8\n",
      "Train loss:  0.7503706566917087\n",
      "Validation loss:  1.6029897578962289\n",
      "Epoch time -----  3.8903682231903076  sec\n",
      "Epoch:  9\n",
      "Train loss:  0.7532986644112948\n",
      "Validation loss:  1.6051708714217896\n",
      "Epoch time -----  3.3594908714294434  sec\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [1:15:21<00:00, 452.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  57.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_marich = []\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "  cnn_img_attack = CNN_img()\n",
    "  tl_cnn_img, vl_cnn_img, tal_cnn_img, samp_cnn_img = marich(cnn_img_attack, unlab_dataset_train, validloader, testloader, budget = 1200, init_points = 500, rounds = 10, epochs = 8, LR = 0.2, gamma1 = 0.8, gamma2 = 0.8, model_name = \"resnet_cnn_attack\"+str(i)+\".pt\", sampling = \"all_elg\", device = \"cuda\", model_type = \"cnn_3c_small\")\n",
    "  \n",
    "  acc_marich.append(tal_cnn_img)\n",
    "\n",
    "  np.save(\"./results/acc_marich_resnet_cnn_img.npy\", np.array(acc_marich))\n",
    "  # np.save(\"/content/drive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7253"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(cnn_img_attack, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./results/samp_resnet_cnn_img.npy\", np.array(samp_cnn_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 500, 1257, 2022, 2794, 3577, 4366, 5162, 5967, 6781, 7601, 8429]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_cnn_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
